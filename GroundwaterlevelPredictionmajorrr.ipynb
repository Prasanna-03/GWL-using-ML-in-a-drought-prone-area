{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_89KCojuvket"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rzluh_Aaw9Bf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FiaZC1XkxBE9"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jpE_SUxXxjJQ",
        "outputId": "2bc2df58-0f21-4b30-cfaa-a3dd5995c90a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Year  Month    Irrigation     Rainfall        Tem   Evaporation       Depth\n",
              "0  2000      1   1992.508320   314.195717  49.295408   12040.44764   80.972729\n",
              "1  2000      2  -2042.251709 -1633.766775  48.449836   18045.51683   87.837238\n",
              "2  2000      3  -1374.450691   868.263711  46.962377   90248.59869  100.716838\n",
              "3  2000      4  29951.326600   309.857143  63.165645  141672.95100   86.904410\n",
              "4  2000      5  43748.371150  -291.325005  59.602103  188789.21330   60.858177"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd17e6fd-f91e-44ef-b59a-2bba3cacec34\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Irrigation</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Tem</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1992.508320</td>\n",
              "      <td>314.195717</td>\n",
              "      <td>49.295408</td>\n",
              "      <td>12040.44764</td>\n",
              "      <td>80.972729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>-2042.251709</td>\n",
              "      <td>-1633.766775</td>\n",
              "      <td>48.449836</td>\n",
              "      <td>18045.51683</td>\n",
              "      <td>87.837238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>-1374.450691</td>\n",
              "      <td>868.263711</td>\n",
              "      <td>46.962377</td>\n",
              "      <td>90248.59869</td>\n",
              "      <td>100.716838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>4</td>\n",
              "      <td>29951.326600</td>\n",
              "      <td>309.857143</td>\n",
              "      <td>63.165645</td>\n",
              "      <td>141672.95100</td>\n",
              "      <td>86.904410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000</td>\n",
              "      <td>5</td>\n",
              "      <td>43748.371150</td>\n",
              "      <td>-291.325005</td>\n",
              "      <td>59.602103</td>\n",
              "      <td>188789.21330</td>\n",
              "      <td>60.858177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd17e6fd-f91e-44ef-b59a-2bba3cacec34')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd17e6fd-f91e-44ef-b59a-2bba3cacec34 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd17e6fd-f91e-44ef-b59a-2bba3cacec34');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/demo.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IWuNG72x7L-",
        "outputId": "0f45e529-1dd3-41a8-cdaf-7ed4c058a4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252 entries, 0 to 251\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Year         252 non-null    int64  \n",
            " 1   Month        252 non-null    int64  \n",
            " 2   Irrigation   252 non-null    float64\n",
            " 3   Rainfall     252 non-null    float64\n",
            " 4   Tem          252 non-null    float64\n",
            " 5   Evaporation  252 non-null    float64\n",
            " 6   Depth        252 non-null    float64\n",
            "dtypes: float64(5), int64(2)\n",
            "memory usage: 13.9 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()   #this shows the size of dataset and no entry contains null value\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-qg3-gdx-Tm",
        "outputId": "b1772fc8-d053-4e1c-b4af-07b062ece4a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Year             2020.000000\n",
              "Month              12.000000\n",
              "Irrigation      69045.535660\n",
              "Rainfall        74516.370880\n",
              "Tem               110.797848\n",
              "Evaporation    205855.274400\n",
              "Depth              18.837238\n",
              "dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpFfERTNyGLg",
        "outputId": "d6ed800d-ebb4-439a-80d8-3ff71e4ccb65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Year           2000.000000\n",
              "Month             1.000000\n",
              "Irrigation    -3822.751642\n",
              "Rainfall      -1956.052536\n",
              "Tem             -57.791476\n",
              "Evaporation      21.308487\n",
              "Depth             3.949962\n",
              "dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "oqq0RHzLyJCx",
        "outputId": "83e9a1ae-e8af-4aed-9216-031afbbe5436"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-938687ab-3fe0-47dc-9487-c97b27c19409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Irrigation</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Tem</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1992.508320</td>\n",
              "      <td>314.195717</td>\n",
              "      <td>-19.295408</td>\n",
              "      <td>12040.44764</td>\n",
              "      <td>8.972729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>-2042.251709</td>\n",
              "      <td>-1633.766775</td>\n",
              "      <td>-38.449836</td>\n",
              "      <td>18045.51683</td>\n",
              "      <td>8.837238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>-1374.450691</td>\n",
              "      <td>868.263711</td>\n",
              "      <td>-36.962377</td>\n",
              "      <td>90248.59869</td>\n",
              "      <td>10.716839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>4</td>\n",
              "      <td>29951.326600</td>\n",
              "      <td>309.857143</td>\n",
              "      <td>-13.165645</td>\n",
              "      <td>141672.95100</td>\n",
              "      <td>8.904410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000</td>\n",
              "      <td>5</td>\n",
              "      <td>43748.371150</td>\n",
              "      <td>-291.325005</td>\n",
              "      <td>19.602103</td>\n",
              "      <td>188789.21330</td>\n",
              "      <td>6.858177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2000</td>\n",
              "      <td>6</td>\n",
              "      <td>34502.648660</td>\n",
              "      <td>17799.096830</td>\n",
              "      <td>57.737034</td>\n",
              "      <td>149223.64210</td>\n",
              "      <td>5.284515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2000</td>\n",
              "      <td>7</td>\n",
              "      <td>30296.987390</td>\n",
              "      <td>14179.731050</td>\n",
              "      <td>91.136063</td>\n",
              "      <td>173045.99630</td>\n",
              "      <td>6.096910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2000</td>\n",
              "      <td>8</td>\n",
              "      <td>19459.005160</td>\n",
              "      <td>29671.991290</td>\n",
              "      <td>106.061944</td>\n",
              "      <td>125595.39410</td>\n",
              "      <td>7.886008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2000</td>\n",
              "      <td>9</td>\n",
              "      <td>17758.697580</td>\n",
              "      <td>21215.182310</td>\n",
              "      <td>110.797848</td>\n",
              "      <td>93648.56533</td>\n",
              "      <td>7.917243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2000</td>\n",
              "      <td>10</td>\n",
              "      <td>62539.841420</td>\n",
              "      <td>4294.421332</td>\n",
              "      <td>86.914527</td>\n",
              "      <td>55423.35440</td>\n",
              "      <td>7.545082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2000</td>\n",
              "      <td>11</td>\n",
              "      <td>235.967333</td>\n",
              "      <td>529.263816</td>\n",
              "      <td>59.757121</td>\n",
              "      <td>32169.49525</td>\n",
              "      <td>4.432534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2000</td>\n",
              "      <td>12</td>\n",
              "      <td>2605.785658</td>\n",
              "      <td>738.620982</td>\n",
              "      <td>14.319978</td>\n",
              "      <td>20927.46470</td>\n",
              "      <td>7.324597</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-938687ab-3fe0-47dc-9487-c97b27c19409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-938687ab-3fe0-47dc-9487-c97b27c19409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-938687ab-3fe0-47dc-9487-c97b27c19409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Year  Month    Irrigation      Rainfall         Tem   Evaporation  \\\n",
              "0   2000      1   1992.508320    314.195717  -19.295408   12040.44764   \n",
              "1   2000      2  -2042.251709  -1633.766775  -38.449836   18045.51683   \n",
              "2   2000      3  -1374.450691    868.263711  -36.962377   90248.59869   \n",
              "3   2000      4  29951.326600    309.857143  -13.165645  141672.95100   \n",
              "4   2000      5  43748.371150   -291.325005   19.602103  188789.21330   \n",
              "5   2000      6  34502.648660  17799.096830   57.737034  149223.64210   \n",
              "6   2000      7  30296.987390  14179.731050   91.136063  173045.99630   \n",
              "7   2000      8  19459.005160  29671.991290  106.061944  125595.39410   \n",
              "8   2000      9  17758.697580  21215.182310  110.797848   93648.56533   \n",
              "9   2000     10  62539.841420   4294.421332   86.914527   55423.35440   \n",
              "10  2000     11    235.967333    529.263816   59.757121   32169.49525   \n",
              "11  2000     12   2605.785658    738.620982   14.319978   20927.46470   \n",
              "\n",
              "        Depth  \n",
              "0    8.972729  \n",
              "1    8.837238  \n",
              "2   10.716839  \n",
              "3    8.904410  \n",
              "4    6.858177  \n",
              "5    5.284515  \n",
              "6    6.096910  \n",
              "7    7.886008  \n",
              "8    7.917243  \n",
              "9    7.545082  \n",
              "10   4.432534  \n",
              "11   7.324597  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = data[:12] #dataset for year 2000\n",
        "new_df\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "3r0P4urwyNYg",
        "outputId": "08769351-1f20-4367-f36e-6fba70fc212f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6023685910>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "plt.xlabel('year 2000')\n",
        "plt.ylabel('depth')\n",
        "plt.scatter(new_df['Month'],new_df['Depth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "satPkc3IyTd-",
        "outputId": "685d56de-2d78-43c9-a1e4-f0f26724f558"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-050828dc-b5c2-406c-a1a8-4a2aa6ad643e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Irrigation</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Tem</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2001</td>\n",
              "      <td>1</td>\n",
              "      <td>-1446.375486</td>\n",
              "      <td>457.590909</td>\n",
              "      <td>-11.694435</td>\n",
              "      <td>16903.900810</td>\n",
              "      <td>7.546799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2001</td>\n",
              "      <td>2</td>\n",
              "      <td>1994.960902</td>\n",
              "      <td>78.495378</td>\n",
              "      <td>-32.958229</td>\n",
              "      <td>43792.840110</td>\n",
              "      <td>8.835951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2001</td>\n",
              "      <td>3</td>\n",
              "      <td>-267.364365</td>\n",
              "      <td>-577.814915</td>\n",
              "      <td>-44.369236</td>\n",
              "      <td>83874.316060</td>\n",
              "      <td>10.207740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2001</td>\n",
              "      <td>4</td>\n",
              "      <td>26117.153690</td>\n",
              "      <td>156.311211</td>\n",
              "      <td>-5.742582</td>\n",
              "      <td>131993.693700</td>\n",
              "      <td>8.404850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2001</td>\n",
              "      <td>5</td>\n",
              "      <td>44438.827240</td>\n",
              "      <td>7482.362433</td>\n",
              "      <td>34.828554</td>\n",
              "      <td>187135.718800</td>\n",
              "      <td>6.610253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2001</td>\n",
              "      <td>6</td>\n",
              "      <td>40444.506300</td>\n",
              "      <td>1747.636448</td>\n",
              "      <td>68.822504</td>\n",
              "      <td>184055.273500</td>\n",
              "      <td>6.081911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2001</td>\n",
              "      <td>7</td>\n",
              "      <td>40209.040550</td>\n",
              "      <td>8124.129400</td>\n",
              "      <td>78.514305</td>\n",
              "      <td>188270.500200</td>\n",
              "      <td>7.310332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2001</td>\n",
              "      <td>8</td>\n",
              "      <td>23856.460210</td>\n",
              "      <td>26413.036280</td>\n",
              "      <td>100.759264</td>\n",
              "      <td>158303.293200</td>\n",
              "      <td>6.953447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2001</td>\n",
              "      <td>9</td>\n",
              "      <td>15448.599310</td>\n",
              "      <td>41288.384650</td>\n",
              "      <td>90.377547</td>\n",
              "      <td>90812.445620</td>\n",
              "      <td>7.282063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2001</td>\n",
              "      <td>10</td>\n",
              "      <td>64213.734410</td>\n",
              "      <td>36381.062050</td>\n",
              "      <td>77.856884</td>\n",
              "      <td>65292.571320</td>\n",
              "      <td>7.714108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2001</td>\n",
              "      <td>11</td>\n",
              "      <td>-1613.064149</td>\n",
              "      <td>382.108248</td>\n",
              "      <td>48.051257</td>\n",
              "      <td>41973.584630</td>\n",
              "      <td>7.339437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2001</td>\n",
              "      <td>12</td>\n",
              "      <td>-600.526269</td>\n",
              "      <td>165.709437</td>\n",
              "      <td>19.748207</td>\n",
              "      <td>9449.166729</td>\n",
              "      <td>7.213382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-050828dc-b5c2-406c-a1a8-4a2aa6ad643e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-050828dc-b5c2-406c-a1a8-4a2aa6ad643e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-050828dc-b5c2-406c-a1a8-4a2aa6ad643e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    Year  Month    Irrigation      Rainfall         Tem    Evaporation  \\\n",
              "12  2001      1  -1446.375486    457.590909  -11.694435   16903.900810   \n",
              "13  2001      2   1994.960902     78.495378  -32.958229   43792.840110   \n",
              "14  2001      3   -267.364365   -577.814915  -44.369236   83874.316060   \n",
              "15  2001      4  26117.153690    156.311211   -5.742582  131993.693700   \n",
              "16  2001      5  44438.827240   7482.362433   34.828554  187135.718800   \n",
              "17  2001      6  40444.506300   1747.636448   68.822504  184055.273500   \n",
              "18  2001      7  40209.040550   8124.129400   78.514305  188270.500200   \n",
              "19  2001      8  23856.460210  26413.036280  100.759264  158303.293200   \n",
              "20  2001      9  15448.599310  41288.384650   90.377547   90812.445620   \n",
              "21  2001     10  64213.734410  36381.062050   77.856884   65292.571320   \n",
              "22  2001     11  -1613.064149    382.108248   48.051257   41973.584630   \n",
              "23  2001     12   -600.526269    165.709437   19.748207    9449.166729   \n",
              "\n",
              "        Depth  \n",
              "12   7.546799  \n",
              "13   8.835951  \n",
              "14  10.207740  \n",
              "15   8.404850  \n",
              "16   6.610253  \n",
              "17   6.081911  \n",
              "18   7.310332  \n",
              "19   6.953447  \n",
              "20   7.282063  \n",
              "21   7.714108  \n",
              "22   7.339437  \n",
              "23   7.213382  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df1 = data[12:24] #dataset for year 2000\n",
        "new_df1\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gwzlJrWgyXPx",
        "outputId": "dc4cfccf-d519-4ea5-b6cf-7702bd87ff3f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title(\"water_table_depth in 2001\")\n",
        "y = np.array(new_df['Depth'])\n",
        "plt.pie(y, labels=[\"jan\",\"feb\",\"mar\",\"apr\",\"may\",\"jun\",\"jul\",\"aug\",\"sep\",\"oct\",\"nov\",\"dec\"],autopct='%1.0f%%', pctdistance=1.1, labeldistance=1.2)\n",
        "# plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "O619Lq8GycT0",
        "outputId": "7bf60631-a778-4a78-eed5-74357423d831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6020dde850>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Evaporation vs Depth')\n",
        "plt.xlabel('Evaporation')\n",
        "plt.ylabel('Depth')\n",
        "plt.scatter(data['Evaporation'],data['Depth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "0LrLXx7lyh97",
        "outputId": "971bcf6e-cb0d-4941-f8ba-4c3d080cd0ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6020ceb550>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Irrigation vs Depth')\n",
        "plt.xlabel('Irrigation')\n",
        "plt.ylabel('Depth')\n",
        "plt.scatter(data['Irrigation'],data['Depth'])\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "8lk94yLqym_K",
        "outputId": "a45fe561-8c3c-41f8-f7e4-8b40880129d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6020c04e50>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Temperature vs Depth')\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Depth')\n",
        "plt.scatter(data['Tem'],data['Depth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "DSqnkTATysKc",
        "outputId": "e003e7ab-8752-4489-ad1f-da4b1e7627b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f6020b94040>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Rainfall vs Depth')\n",
        "plt.xlabel('Rainfall')\n",
        "plt.ylabel('Depth')\n",
        "plt.scatter(data['Rainfall'],data['Depth'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2ZU4xLgywkb",
        "outputId": "d39b546d-5e0c-40eb-b77c-c21770f451f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,\n",
              "       2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " year = data['Year'].unique()\n",
        "year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo-rca4iy0zJ",
        "outputId": "9719345e-9b72-456e-df0d-c66627000a34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "max_irr_in_year  [62539.84142, 64213.73441, 61894.08515, 57565.7323, 61542.49211, 58558.64057, 59893.63724, 69045.53566, 58444.21467, 67470.52289, 62627.98953, 64553.88055, 62843.35727, 68788.71489]\n",
            "max_irr_in_year  [62539.84142, 64213.73441, 61894.08515, 57565.7323, 61542.49211, 58558.64057, 59893.63724, 69045.53566, 58444.21467, 67470.52289, 62627.98953, 64553.88055, 62843.35727, 68788.71489]\n",
            "max_rain_in_year  [29671.99129, 41288.38465, 53415.09485, 71274.74763, 53622.39141, 40482.81123, 21044.88091, 61360.26218, 50614.67379, 29843.88512, 40134.86798, 12553.10549, 74516.37088, 32804.27424]\n",
            "max_tem_in_year  [110.7978477, 100.7592639, 102.8578299, 93.95210377, 109.5552109, 96.83133314, 106.6081167, 103.6746017, 92.17978293, 108.6809709, 102.4820452, 108.2367539, 90.60726361, 96.19095033]\n",
            "max_dep_in_year  [10.71683851, 10.2077399, 9.319732986, 9.91492158, 9.002629495, 10.04892381, 10.46812924, 9.707285928, 9.567090048, 8.536242202, 9.47452401, 10.05136104, 9.735723355, 9.19472987]\n",
            "\n",
            "min_irr_in_year  [-2042.251709, -1613.064149, -2182.725371, -3800.045423, 36.61342025, -3822.751642, 450.6792621, -1949.382362, -1786.736009, -3694.468188, -3342.697255, -2315.468761, -1395.340264, -2342.067247]\n",
            "min_irr_in_year  [-2042.251709, -1613.064149, -2182.725371, -3800.045423, 36.61342025, -3822.751642, 450.6792621, -1949.382362, -1786.736009, -3694.468188, -3342.697255, -2315.468761, -1395.340264, -2342.067247]\n",
            "min_rain_in_year  [-1633.766775, -577.8149148, -1050.505385, -688.0205006, -1956.052536, -955.6499554, -539.7593045, -613.769595, -305.9038928, -360.3685496, -1566.529414, -1490.692064, -512.8763799, -889.7145878]\n",
            "min_tem_in_year  [-38.44983642, -44.36923616, -24.06033982, -29.08654122, -28.65067007, -44.29459822, -34.82116715, -41.57859187, -39.68999151, -35.36293208, -57.79147621, -52.94682407, -48.12066664, -44.17102672]\n",
            "min_dep_in_year  [4.432534163, 6.081910968, 4.263080886, 6.18253906, 4.741248325, 4.834708728, 4.509390233, 3.949961989, 5.273589638, 4.502933239, 4.66771197, 3.974915145, 4.639453133, 4.679069387]\n"
          ]
        }
      ],
      "source": [
        "max_irr_in_year=[]\n",
        "max_rain_in_year=[]\n",
        "max_tem_in_year=[]\n",
        "max_evp_in_year=[]\n",
        "max_dep_in_year=[]\n",
        "\n",
        "min_irr_in_year=[]\n",
        "min_rain_in_year=[]\n",
        "min_tem_in_year=[]\n",
        "min_evp_in_year=[]\n",
        "min_dep_in_year=[]\n",
        "\n",
        "avg_irr_in_year=[]\n",
        "avg_rain_in_year=[]\n",
        "avg_tem_in_year=[]\n",
        "avg_evp_in_year=[]\n",
        "avg_dep_in_year=[]\n",
        "\n",
        "k=0\n",
        "i=0\n",
        "j=12\n",
        "\n",
        "for k in range(14):\n",
        "  max_irr_in_year.append(data['Irrigation'][i:j].max())\n",
        "  max_rain_in_year.append(data['Rainfall'][i:j].max())\n",
        "  max_tem_in_year.append(data['Tem'][i:j].max())\n",
        "  max_evp_in_year.append(data['Evaporation'][i:j].max())\n",
        "  max_dep_in_year.append(data['Depth'][i:j].max())\n",
        "\n",
        "  min_irr_in_year.append(data['Irrigation'][i:j].min())\n",
        "  min_rain_in_year.append(data['Rainfall'][i:j].min())\n",
        "  min_tem_in_year.append(data['Tem'][i:j].min())\n",
        "  min_evp_in_year.append(data['Evaporation'][i:j].min())\n",
        "  min_dep_in_year.append(data['Depth'][i:j].min())\n",
        "\n",
        "  avg_irr_in_year.append(data['Irrigation'][i:j].mean())\n",
        "  avg_rain_in_year.append(data['Rainfall'][i:j].mean())\n",
        "  avg_tem_in_year.append(data['Tem'][i:j].mean())\n",
        "  avg_evp_in_year.append(data['Evaporation'][i:j].mean())\n",
        "  avg_dep_in_year.append(data['Depth'][i:j].mean())\n",
        "  i+=12\n",
        "  j+=12\n",
        "\n",
        "print('max_irr_in_year ',max_irr_in_year)\n",
        "print('max_irr_in_year ',max_irr_in_year)\n",
        "print('max_rain_in_year ',max_rain_in_year)\n",
        "print('max_tem_in_year ',max_tem_in_year)\n",
        "print('max_dep_in_year ',max_dep_in_year)\n",
        "print()\n",
        "print('min_irr_in_year ',min_irr_in_year)\n",
        "print('min_irr_in_year ',min_irr_in_year)\n",
        "print('min_rain_in_year ',min_rain_in_year)\n",
        "print('min_tem_in_year ',min_tem_in_year)\n",
        "print('min_dep_in_year ',min_dep_in_year)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1jbXq0ozc4f"
      },
      "outputs": [],
      "source": [
        "ss_X_dep = StandardScaler()\n",
        "ss_y_dep = StandardScaler()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLHA8hlszjb8"
      },
      "outputs": [],
      "source": [
        "def rmse(y1, y2):\n",
        "    return np.sqrt(mean_squared_error(y1, y2))\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_O-V1OczqCx"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/demo.csv\")\n",
        "\n",
        "# Spliting the dataset into two parts @inputs and @output\n",
        "# input has all the column except Year & Depth\n",
        "# output has Year & Depht\n",
        "# dropping the year and Depth column\n",
        "Inputs = data.drop('Year', axis=1).drop('Depth', axis=1)\n",
        "Outputs = data['Depth']\n",
        "\n",
        "Inputs = Inputs.values\n",
        "Outputs = Outputs.values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zY9UIXkAz3f6",
        "outputId": "6f258f3f-db0f-417c-a3aa-39717ac6afd9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9a1ca124-b742-4208-a871-e07d9979bce0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Irrigation</th>\n",
              "      <th>Rainfall</th>\n",
              "      <th>Tem</th>\n",
              "      <th>Evaporation</th>\n",
              "      <th>Depth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>1</td>\n",
              "      <td>1992.508320</td>\n",
              "      <td>314.195717</td>\n",
              "      <td>-19.295408</td>\n",
              "      <td>12040.44764</td>\n",
              "      <td>8.972729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>2</td>\n",
              "      <td>-2042.251709</td>\n",
              "      <td>-1633.766775</td>\n",
              "      <td>-38.449836</td>\n",
              "      <td>18045.51683</td>\n",
              "      <td>8.837238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>-1374.450691</td>\n",
              "      <td>868.263711</td>\n",
              "      <td>-36.962377</td>\n",
              "      <td>90248.59869</td>\n",
              "      <td>10.716839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>4</td>\n",
              "      <td>29951.326600</td>\n",
              "      <td>309.857143</td>\n",
              "      <td>-13.165645</td>\n",
              "      <td>141672.95100</td>\n",
              "      <td>8.904410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000</td>\n",
              "      <td>5</td>\n",
              "      <td>43748.371150</td>\n",
              "      <td>-291.325005</td>\n",
              "      <td>19.602103</td>\n",
              "      <td>188789.21330</td>\n",
              "      <td>6.858177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a1ca124-b742-4208-a871-e07d9979bce0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a1ca124-b742-4208-a871-e07d9979bce0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a1ca124-b742-4208-a871-e07d9979bce0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Year  Month    Irrigation     Rainfall        Tem   Evaporation      Depth\n",
              "0  2000      1   1992.508320   314.195717 -19.295408   12040.44764   8.972729\n",
              "1  2000      2  -2042.251709 -1633.766775 -38.449836   18045.51683   8.837238\n",
              "2  2000      3  -1374.450691   868.263711 -36.962377   90248.59869  10.716839\n",
              "3  2000      4  29951.326600   309.857143 -13.165645  141672.95100   8.904410\n",
              "4  2000      5  43748.371150  -291.325005  19.602103  188789.21330   6.858177"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_yT2Yihz-b8",
        "outputId": "39883f0f-4f29-493f-f015-fa05dc441c2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.00000000e+00,  1.99250832e+03,  3.14195717e+02,\n",
              "        -1.92954078e+01,  1.20404476e+04],\n",
              "       [ 2.00000000e+00, -2.04225171e+03, -1.63376678e+03,\n",
              "        -3.84498364e+01,  1.80455168e+04],\n",
              "       [ 3.00000000e+00, -1.37445069e+03,  8.68263711e+02,\n",
              "        -3.69623765e+01,  9.02485987e+04],\n",
              "       ...,\n",
              "       [ 1.00000000e+01,  5.98936372e+04,  1.07594176e+03,\n",
              "         8.50284281e+01,  8.88099543e+04],\n",
              "       [ 1.10000000e+01,  4.50679262e+02,  3.99303086e+03,\n",
              "         6.46761010e+01,  5.43683063e+04],\n",
              "       [ 1.20000000e+01,  1.63669514e+03, -2.69105809e+02,\n",
              "         2.17779008e+01,  9.42707951e+03]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btQkAr2Kz_5g",
        "outputId": "4570fff3-e81a-4d88-f95c-39b315ce9812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_dep shape (144, 5)\n",
            "y_train_dep shape (144, 1)\n",
            "X_test_dep shape (108, 5)\n",
            "y_test_dep shape (108, 1)\n"
          ]
        }
      ],
      "source": [
        "X_train_dep = Inputs[0:144]\n",
        "y_train_dep = Outputs[0:144]\n",
        "\n",
        "# Last 2 years of data\n",
        "X_test_dep = Inputs[144:]\n",
        "y_test_dep = Outputs[144:]\n",
        "\n",
        "print(\"X_train_dep shape\", X_train_dep.shape)\n",
        "print(\"y_train_dep shape\", y_train_dep.shape)\n",
        "print(\"X_test_dep shape\", X_test_dep.shape)\n",
        "print(\"y_test_dep shape\", y_test_dep.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZ5hdAM0G6q",
        "outputId": "24117484-dfa7-4d44-9142-91e7c8dc68c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.16937208086512484\n",
            "33.19692784956447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score \n",
        " \n",
        "\n",
        " \n",
        "model_SVR = svm.SVR()\n",
        "model_SVR.fit(X_train_dep,y_train_dep)\n",
        "Y_pred = model_SVR.predict(X_test_dep)\n",
        "rr = mean_absolute_percentage_error(y_test_dep, Y_pred)\n",
        " \n",
        "print(mean_absolute_percentage_error(y_test_dep, Y_pred))\n",
        "#print(r2_score(y_test_dep,Y_pred)*100)\n",
        "print(1.96 *rr*100 )\n",
        "acc_svm = 1.96*rr*100\n",
        "#acc = accuracy_score(y_test_dep, Y_pred)\n",
        "#print (acc)\n",
        "#scores = cross_val_score(model_RFR, y_test_dep, Y_pred, cv=6)\n",
        "#print(scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n-BoVZa22Mb",
        "outputId": "b4a25eb1-7a73-405f-d5dc-4ad082e1bf19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-40f4f03c9fd5>:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  model_RFR.fit(X_train_dep, y_train_dep)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0632231437009744\n",
            "88.43826458960514\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score \n",
        " \n",
        "model_RFR = RandomForestRegressor(n_estimators=10)\n",
        "model_RFR.fit(X_train_dep, y_train_dep)\n",
        "Y_pred = model_RFR.predict(X_test_dep)\n",
        "rr=mean_absolute_percentage_error(y_test_dep, Y_pred)\n",
        " \n",
        "print(mean_absolute_percentage_error(y_test_dep, Y_pred))\n",
        "#print(r2_score(y_test_dep, Y_pred)*100)\n",
        "scores = cross_val_score(model_RFR, y_test_dep, Y_pred, cv=6)\n",
        "print(scores[1]*100)\n",
        "acc_rfr = scores[1]*100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0ZG8hi3G1a",
        "outputId": "5cb26f31-b718-4348-e1b4-88fe7e1e9603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.15994863070012236\n",
            "[ 0.36077592 -0.23793314  0.23482257  0.2884896   0.46266787  0.27199153]\n",
            "31.34993161722398\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "import pickle\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "model_LR = LinearRegression()\n",
        "model_LR.fit(X_train_dep, y_train_dep)\n",
        "Y_pred = model_LR.predict(X_test_dep)\n",
        "xx=mean_absolute_percentage_error(y_test_dep, Y_pred)\n",
        " \n",
        "print(mean_absolute_percentage_error(y_test_dep, Y_pred))\n",
        "#print(r2_score(y_test_dep, Y_pred)*100)\n",
        "scores = cross_val_score(model_LR, y_test_dep, Y_pred, cv=6)\n",
        "print(scores)\n",
        "acc_lr = 1.96*xx*100\n",
        "print(acc_lr)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FR4hQ4N0TQS"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate([X_train_dep, X_test_dep], axis=0)\n",
        "\n",
        "# Standardization\n",
        "X = ss_X_dep.fit_transform(X)\n",
        "\n",
        "# First 12 years of data\n",
        "X_train_dep_std = X[0:144]\n",
        "y_train_dep_std = ss_y_dep.fit_transform(y_train_dep)\n",
        "\n",
        "# All 14 years of data\n",
        "X_test_dep_std  = X\n",
        "X_train_dep_std = np.expand_dims(X_train_dep_std, axis=0)\n",
        "y_train_dep_std = np.expand_dims(y_train_dep_std, axis=0)\n",
        "X_test_dep_std = np.expand_dims(X_test_dep_std, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET8RkJWb3hJn"
      },
      "outputs": [],
      "source": [
        "# Transfer to Pytorch Variable\n",
        "X_train_dep_std = Variable(torch.from_numpy(X_train_dep_std).float())\n",
        "y_train_dep_std = Variable(torch.from_numpy(y_train_dep_std).float())\n",
        "X_test_dep_std = Variable(torch.from_numpy(X_test_dep_std).float())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AY45JEa_3krM"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers, class_size, dropout=0.5, rnn_type='lstm'):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.class_size = class_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn_type = rnn_type\n",
        "\n",
        "        if self.rnn_type == 'lstm':\n",
        "            self.rnn = nn.LSTM(\n",
        "                input_size=self.input_size,\n",
        "                hidden_size=self.hidden_size,     # rnn hidden unit\n",
        "                num_layers=self.num_layers,       # number of rnn layer\n",
        "                batch_first=True,   # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
        "            )\n",
        "        elif self.rnn_type == 'rnn':\n",
        "            self.rnn = nn.RNN(\n",
        "                input_size=self.input_size,\n",
        "                hidden_size=self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                batch_first=True,\n",
        "            )\n",
        "        elif self.rnn_type == 'gru':\n",
        "            self.rnn = nn.GRU(\n",
        "                input_size=self.input_size,\n",
        "                hidden_size=self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                batch_first=True,\n",
        "            )\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(self.hidden_size, self.class_size) # FC layer in our paper\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        if self.rnn_type == 'lstm':\n",
        "            c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "            r_out, _ = self.rnn(x, (h0, c0))\n",
        "        else:\n",
        "            r_out, _ = self.rnn(x, h0)\n",
        "\n",
        "        outs = []    # save all predictions\n",
        "        for time_step in range(r_out.size(1)):    # calculate output for each time step\n",
        "            outs.append(self.out(self.dropout((r_out[:, time_step, :]))))\n",
        "        return torch.stack(outs, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gznx_Xbh3wjg"
      },
      "outputs": [],
      "source": [
        "# Define rnn model\n",
        "# We can also choose rnn_type as 'rnn' or 'gru'\n",
        "model = RNN(input_size=5, hidden_size=40, num_layers=1, class_size=1, dropout=0.5, rnn_type='lstm')\n",
        "\n",
        "# Define optimization function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)   # optimize all rnn parameters\n",
        "\n",
        "# Define loss function\n",
        "loss_func = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yld0Esve31k-",
        "outputId": "0d0f1322-afc1-44bf-80db-cbae1771c067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[Iteration: 1501] [Loss: 0.33105990290641785]\n",
            "[Iteration: 1502] [Loss: 0.32099056243896484]\n",
            "[Iteration: 1503] [Loss: 0.35768401622772217]\n",
            "[Iteration: 1504] [Loss: 0.3401056230068207]\n",
            "[Iteration: 1505] [Loss: 0.3320266008377075]\n",
            "[Iteration: 1506] [Loss: 0.308760404586792]\n",
            "[Iteration: 1507] [Loss: 0.3086667060852051]\n",
            "[Iteration: 1508] [Loss: 0.32166874408721924]\n",
            "[Iteration: 1509] [Loss: 0.31073763966560364]\n",
            "[Iteration: 1510] [Loss: 0.3493897318840027]\n",
            "[Iteration: 1511] [Loss: 0.30351701378822327]\n",
            "[Iteration: 1512] [Loss: 0.3185073137283325]\n",
            "[Iteration: 1513] [Loss: 0.32086002826690674]\n",
            "[Iteration: 1514] [Loss: 0.3254466950893402]\n",
            "[Iteration: 1515] [Loss: 0.3069824278354645]\n",
            "[Iteration: 1516] [Loss: 0.33730724453926086]\n",
            "[Iteration: 1517] [Loss: 0.3307633697986603]\n",
            "[Iteration: 1518] [Loss: 0.3294171392917633]\n",
            "[Iteration: 1519] [Loss: 0.34088432788848877]\n",
            "[Iteration: 1520] [Loss: 0.31737956404685974]\n",
            "[Iteration: 1521] [Loss: 0.3480396866798401]\n",
            "[Iteration: 1522] [Loss: 0.35138198733329773]\n",
            "[Iteration: 1523] [Loss: 0.3488268554210663]\n",
            "[Iteration: 1524] [Loss: 0.30448392033576965]\n",
            "[Iteration: 1525] [Loss: 0.31442171335220337]\n",
            "[Iteration: 1526] [Loss: 0.33181145787239075]\n",
            "[Iteration: 1527] [Loss: 0.3280773162841797]\n",
            "[Iteration: 1528] [Loss: 0.33825358748435974]\n",
            "[Iteration: 1529] [Loss: 0.32926079630851746]\n",
            "[Iteration: 1530] [Loss: 0.3550680875778198]\n",
            "[Iteration: 1531] [Loss: 0.319975346326828]\n",
            "[Iteration: 1532] [Loss: 0.3274165689945221]\n",
            "[Iteration: 1533] [Loss: 0.31458449363708496]\n",
            "[Iteration: 1534] [Loss: 0.30602025985717773]\n",
            "[Iteration: 1535] [Loss: 0.321958065032959]\n",
            "[Iteration: 1536] [Loss: 0.2959781587123871]\n",
            "[Iteration: 1537] [Loss: 0.3528374135494232]\n",
            "[Iteration: 1538] [Loss: 0.32338446378707886]\n",
            "[Iteration: 1539] [Loss: 0.30087944865226746]\n",
            "[Iteration: 1540] [Loss: 0.3411346673965454]\n",
            "[Iteration: 1541] [Loss: 0.3253101110458374]\n",
            "[Iteration: 1542] [Loss: 0.3398502469062805]\n",
            "[Iteration: 1543] [Loss: 0.303913950920105]\n",
            "[Iteration: 1544] [Loss: 0.3262471556663513]\n",
            "[Iteration: 1545] [Loss: 0.3248673677444458]\n",
            "[Iteration: 1546] [Loss: 0.3048717975616455]\n",
            "[Iteration: 1547] [Loss: 0.31605586409568787]\n",
            "[Iteration: 1548] [Loss: 0.30936628580093384]\n",
            "[Iteration: 1549] [Loss: 0.33021268248558044]\n",
            "[Iteration: 1550] [Loss: 0.3348202407360077]\n",
            "[Iteration: 1551] [Loss: 0.35196828842163086]\n",
            "[Iteration: 1552] [Loss: 0.30448082089424133]\n",
            "[Iteration: 1553] [Loss: 0.3644496202468872]\n",
            "[Iteration: 1554] [Loss: 0.3324394226074219]\n",
            "[Iteration: 1555] [Loss: 0.3494512736797333]\n",
            "[Iteration: 1556] [Loss: 0.34144195914268494]\n",
            "[Iteration: 1557] [Loss: 0.3500956892967224]\n",
            "[Iteration: 1558] [Loss: 0.334678053855896]\n",
            "[Iteration: 1559] [Loss: 0.3252512514591217]\n",
            "[Iteration: 1560] [Loss: 0.3527431786060333]\n",
            "[Iteration: 1561] [Loss: 0.3191491663455963]\n",
            "[Iteration: 1562] [Loss: 0.33032241463661194]\n",
            "[Iteration: 1563] [Loss: 0.29580768942832947]\n",
            "[Iteration: 1564] [Loss: 0.324707955121994]\n",
            "[Iteration: 1565] [Loss: 0.32069745659828186]\n",
            "[Iteration: 1566] [Loss: 0.35153728723526]\n",
            "[Iteration: 1567] [Loss: 0.3873780369758606]\n",
            "[Iteration: 1568] [Loss: 0.2751883864402771]\n",
            "[Iteration: 1569] [Loss: 0.3254360258579254]\n",
            "[Iteration: 1570] [Loss: 0.31810709834098816]\n",
            "[Iteration: 1571] [Loss: 0.3395802676677704]\n",
            "[Iteration: 1572] [Loss: 0.3066917657852173]\n",
            "[Iteration: 1573] [Loss: 0.32221803069114685]\n",
            "[Iteration: 1574] [Loss: 0.3509956896305084]\n",
            "[Iteration: 1575] [Loss: 0.3626578152179718]\n",
            "[Iteration: 1576] [Loss: 0.29863303899765015]\n",
            "[Iteration: 1577] [Loss: 0.3480210304260254]\n",
            "[Iteration: 1578] [Loss: 0.34226852655410767]\n",
            "[Iteration: 1579] [Loss: 0.32577988505363464]\n",
            "[Iteration: 1580] [Loss: 0.32779571413993835]\n",
            "[Iteration: 1581] [Loss: 0.33769166469573975]\n",
            "[Iteration: 1582] [Loss: 0.31779828667640686]\n",
            "[Iteration: 1583] [Loss: 0.3185223340988159]\n",
            "[Iteration: 1584] [Loss: 0.3357603847980499]\n",
            "[Iteration: 1585] [Loss: 0.3165571093559265]\n",
            "[Iteration: 1586] [Loss: 0.33930444717407227]\n",
            "[Iteration: 1587] [Loss: 0.33857473731040955]\n",
            "[Iteration: 1588] [Loss: 0.34691789746284485]\n",
            "[Iteration: 1589] [Loss: 0.3606714904308319]\n",
            "[Iteration: 1590] [Loss: 0.34737658500671387]\n",
            "[Iteration: 1591] [Loss: 0.33872711658477783]\n",
            "[Iteration: 1592] [Loss: 0.3425922095775604]\n",
            "[Iteration: 1593] [Loss: 0.3244333267211914]\n",
            "[Iteration: 1594] [Loss: 0.3159581422805786]\n",
            "[Iteration: 1595] [Loss: 0.3221266567707062]\n",
            "[Iteration: 1596] [Loss: 0.29479703307151794]\n",
            "[Iteration: 1597] [Loss: 0.3365616798400879]\n",
            "[Iteration: 1598] [Loss: 0.3470612168312073]\n",
            "[Iteration: 1599] [Loss: 0.31467026472091675]\n",
            "[Iteration: 1600] [Loss: 0.3086472749710083]\n",
            "[Iteration: 1601] [Loss: 0.32594144344329834]\n",
            "[Iteration: 1602] [Loss: 0.320659875869751]\n",
            "[Iteration: 1603] [Loss: 0.3219262957572937]\n",
            "[Iteration: 1604] [Loss: 0.32495081424713135]\n",
            "[Iteration: 1605] [Loss: 0.31472155451774597]\n",
            "[Iteration: 1606] [Loss: 0.28375762701034546]\n",
            "[Iteration: 1607] [Loss: 0.3098991811275482]\n",
            "[Iteration: 1608] [Loss: 0.3360308110713959]\n",
            "[Iteration: 1609] [Loss: 0.3004050850868225]\n",
            "[Iteration: 1610] [Loss: 0.30133140087127686]\n",
            "[Iteration: 1611] [Loss: 0.3361273407936096]\n",
            "[Iteration: 1612] [Loss: 0.31597959995269775]\n",
            "[Iteration: 1613] [Loss: 0.31934553384780884]\n",
            "[Iteration: 1614] [Loss: 0.2981019616127014]\n",
            "[Iteration: 1615] [Loss: 0.3300825357437134]\n",
            "[Iteration: 1616] [Loss: 0.33816012740135193]\n",
            "[Iteration: 1617] [Loss: 0.34256547689437866]\n",
            "[Iteration: 1618] [Loss: 0.31598877906799316]\n",
            "[Iteration: 1619] [Loss: 0.2965551018714905]\n",
            "[Iteration: 1620] [Loss: 0.351494163274765]\n",
            "[Iteration: 1621] [Loss: 0.34319233894348145]\n",
            "[Iteration: 1622] [Loss: 0.29603439569473267]\n",
            "[Iteration: 1623] [Loss: 0.3153782784938812]\n",
            "[Iteration: 1624] [Loss: 0.3348965346813202]\n",
            "[Iteration: 1625] [Loss: 0.35081946849823]\n",
            "[Iteration: 1626] [Loss: 0.35211142897605896]\n",
            "[Iteration: 1627] [Loss: 0.3294079005718231]\n",
            "[Iteration: 1628] [Loss: 0.3165537118911743]\n",
            "[Iteration: 1629] [Loss: 0.3408929705619812]\n",
            "[Iteration: 1630] [Loss: 0.29620522260665894]\n",
            "[Iteration: 1631] [Loss: 0.30592167377471924]\n",
            "[Iteration: 1632] [Loss: 0.315522164106369]\n",
            "[Iteration: 1633] [Loss: 0.3438901901245117]\n",
            "[Iteration: 1634] [Loss: 0.3153132498264313]\n",
            "[Iteration: 1635] [Loss: 0.323816180229187]\n",
            "[Iteration: 1636] [Loss: 0.3063645660877228]\n",
            "[Iteration: 1637] [Loss: 0.33608728647232056]\n",
            "[Iteration: 1638] [Loss: 0.2965295910835266]\n",
            "[Iteration: 1639] [Loss: 0.30147433280944824]\n",
            "[Iteration: 1640] [Loss: 0.323065847158432]\n",
            "[Iteration: 1641] [Loss: 0.32402271032333374]\n",
            "[Iteration: 1642] [Loss: 0.3147537410259247]\n",
            "[Iteration: 1643] [Loss: 0.3158227801322937]\n",
            "[Iteration: 1644] [Loss: 0.3056507408618927]\n",
            "[Iteration: 1645] [Loss: 0.30471399426460266]\n",
            "[Iteration: 1646] [Loss: 0.2788979709148407]\n",
            "[Iteration: 1647] [Loss: 0.3635959029197693]\n",
            "[Iteration: 1648] [Loss: 0.3026250898838043]\n",
            "[Iteration: 1649] [Loss: 0.32878491282463074]\n",
            "[Iteration: 1650] [Loss: 0.31835559010505676]\n",
            "[Iteration: 1651] [Loss: 0.2848725914955139]\n",
            "[Iteration: 1652] [Loss: 0.3461402356624603]\n",
            "[Iteration: 1653] [Loss: 0.30322185158729553]\n",
            "[Iteration: 1654] [Loss: 0.3335720896720886]\n",
            "[Iteration: 1655] [Loss: 0.3362175226211548]\n",
            "[Iteration: 1656] [Loss: 0.27313515543937683]\n",
            "[Iteration: 1657] [Loss: 0.3002660274505615]\n",
            "[Iteration: 1658] [Loss: 0.3158594071865082]\n",
            "[Iteration: 1659] [Loss: 0.29895123839378357]\n",
            "[Iteration: 1660] [Loss: 0.33755290508270264]\n",
            "[Iteration: 1661] [Loss: 0.3171702027320862]\n",
            "[Iteration: 1662] [Loss: 0.30690285563468933]\n",
            "[Iteration: 1663] [Loss: 0.28817978501319885]\n",
            "[Iteration: 1664] [Loss: 0.345488041639328]\n",
            "[Iteration: 1665] [Loss: 0.2874743640422821]\n",
            "[Iteration: 1666] [Loss: 0.3067759871482849]\n",
            "[Iteration: 1667] [Loss: 0.35193079710006714]\n",
            "[Iteration: 1668] [Loss: 0.32142215967178345]\n",
            "[Iteration: 1669] [Loss: 0.28732120990753174]\n",
            "[Iteration: 1670] [Loss: 0.3105405569076538]\n",
            "[Iteration: 1671] [Loss: 0.3412131369113922]\n",
            "[Iteration: 1672] [Loss: 0.3100098669528961]\n",
            "[Iteration: 1673] [Loss: 0.3103526532649994]\n",
            "[Iteration: 1674] [Loss: 0.3208376169204712]\n",
            "[Iteration: 1675] [Loss: 0.3065846264362335]\n",
            "[Iteration: 1676] [Loss: 0.3134443759918213]\n",
            "[Iteration: 1677] [Loss: 0.2849295139312744]\n",
            "[Iteration: 1678] [Loss: 0.32168638706207275]\n",
            "[Iteration: 1679] [Loss: 0.3237781226634979]\n",
            "[Iteration: 1680] [Loss: 0.2972172200679779]\n",
            "[Iteration: 1681] [Loss: 0.3050778806209564]\n",
            "[Iteration: 1682] [Loss: 0.3079158067703247]\n",
            "[Iteration: 1683] [Loss: 0.3266153335571289]\n",
            "[Iteration: 1684] [Loss: 0.3353011906147003]\n",
            "[Iteration: 1685] [Loss: 0.3252686858177185]\n",
            "[Iteration: 1686] [Loss: 0.33829882740974426]\n",
            "[Iteration: 1687] [Loss: 0.29207780957221985]\n",
            "[Iteration: 1688] [Loss: 0.28633028268814087]\n",
            "[Iteration: 1689] [Loss: 0.3304519057273865]\n",
            "[Iteration: 1690] [Loss: 0.31858259439468384]\n",
            "[Iteration: 1691] [Loss: 0.31357234716415405]\n",
            "[Iteration: 1692] [Loss: 0.33822640776634216]\n",
            "[Iteration: 1693] [Loss: 0.28831589221954346]\n",
            "[Iteration: 1694] [Loss: 0.28158989548683167]\n",
            "[Iteration: 1695] [Loss: 0.31302765011787415]\n",
            "[Iteration: 1696] [Loss: 0.3577471971511841]\n",
            "[Iteration: 1697] [Loss: 0.31684795022010803]\n",
            "[Iteration: 1698] [Loss: 0.3056620955467224]\n",
            "[Iteration: 1699] [Loss: 0.32569417357444763]\n",
            "[Iteration: 1700] [Loss: 0.31505775451660156]\n",
            "[Iteration: 1701] [Loss: 0.3048158288002014]\n",
            "[Iteration: 1702] [Loss: 0.3049744963645935]\n",
            "[Iteration: 1703] [Loss: 0.3064438998699188]\n",
            "[Iteration: 1704] [Loss: 0.29283636808395386]\n",
            "[Iteration: 1705] [Loss: 0.2898537516593933]\n",
            "[Iteration: 1706] [Loss: 0.3185671269893646]\n",
            "[Iteration: 1707] [Loss: 0.31733158230781555]\n",
            "[Iteration: 1708] [Loss: 0.31703630089759827]\n",
            "[Iteration: 1709] [Loss: 0.293026328086853]\n",
            "[Iteration: 1710] [Loss: 0.3013409972190857]\n",
            "[Iteration: 1711] [Loss: 0.2947472631931305]\n",
            "[Iteration: 1712] [Loss: 0.3087877631187439]\n",
            "[Iteration: 1713] [Loss: 0.2746252119541168]\n",
            "[Iteration: 1714] [Loss: 0.29011598229408264]\n",
            "[Iteration: 1715] [Loss: 0.33865779638290405]\n",
            "[Iteration: 1716] [Loss: 0.3137555420398712]\n",
            "[Iteration: 1717] [Loss: 0.3588537573814392]\n",
            "[Iteration: 1718] [Loss: 0.3002223074436188]\n",
            "[Iteration: 1719] [Loss: 0.3066629469394684]\n",
            "[Iteration: 1720] [Loss: 0.30506497621536255]\n",
            "[Iteration: 1721] [Loss: 0.30966871976852417]\n",
            "[Iteration: 1722] [Loss: 0.2648891508579254]\n",
            "[Iteration: 1723] [Loss: 0.27344709634780884]\n",
            "[Iteration: 1724] [Loss: 0.31580567359924316]\n",
            "[Iteration: 1725] [Loss: 0.27994558215141296]\n",
            "[Iteration: 1726] [Loss: 0.2664698362350464]\n",
            "[Iteration: 1727] [Loss: 0.27731868624687195]\n",
            "[Iteration: 1728] [Loss: 0.3260590434074402]\n",
            "[Iteration: 1729] [Loss: 0.31268417835235596]\n",
            "[Iteration: 1730] [Loss: 0.31064045429229736]\n",
            "[Iteration: 1731] [Loss: 0.29412955045700073]\n",
            "[Iteration: 1732] [Loss: 0.3409275710582733]\n",
            "[Iteration: 1733] [Loss: 0.32340365648269653]\n",
            "[Iteration: 1734] [Loss: 0.29391539096832275]\n",
            "[Iteration: 1735] [Loss: 0.31142228841781616]\n",
            "[Iteration: 1736] [Loss: 0.308346688747406]\n",
            "[Iteration: 1737] [Loss: 0.30377787351608276]\n",
            "[Iteration: 1738] [Loss: 0.30336007475852966]\n",
            "[Iteration: 1739] [Loss: 0.28818655014038086]\n",
            "[Iteration: 1740] [Loss: 0.288743793964386]\n",
            "[Iteration: 1741] [Loss: 0.3118310272693634]\n",
            "[Iteration: 1742] [Loss: 0.2924917936325073]\n",
            "[Iteration: 1743] [Loss: 0.3066674470901489]\n",
            "[Iteration: 1744] [Loss: 0.3171302080154419]\n",
            "[Iteration: 1745] [Loss: 0.3239900767803192]\n",
            "[Iteration: 1746] [Loss: 0.3322282135486603]\n",
            "[Iteration: 1747] [Loss: 0.30800846219062805]\n",
            "[Iteration: 1748] [Loss: 0.28073009848594666]\n",
            "[Iteration: 1749] [Loss: 0.29144760966300964]\n",
            "[Iteration: 1750] [Loss: 0.318625807762146]\n",
            "[Iteration: 1751] [Loss: 0.29393866658210754]\n",
            "[Iteration: 1752] [Loss: 0.29244542121887207]\n",
            "[Iteration: 1753] [Loss: 0.3064936101436615]\n",
            "[Iteration: 1754] [Loss: 0.2979196310043335]\n",
            "[Iteration: 1755] [Loss: 0.28067314624786377]\n",
            "[Iteration: 1756] [Loss: 0.31888383626937866]\n",
            "[Iteration: 1757] [Loss: 0.3209918737411499]\n",
            "[Iteration: 1758] [Loss: 0.3037351369857788]\n",
            "[Iteration: 1759] [Loss: 0.30980783700942993]\n",
            "[Iteration: 1760] [Loss: 0.3236672580242157]\n",
            "[Iteration: 1761] [Loss: 0.3194613456726074]\n",
            "[Iteration: 1762] [Loss: 0.30144813656806946]\n",
            "[Iteration: 1763] [Loss: 0.29399752616882324]\n",
            "[Iteration: 1764] [Loss: 0.3086875379085541]\n",
            "[Iteration: 1765] [Loss: 0.30290523171424866]\n",
            "[Iteration: 1766] [Loss: 0.28717002272605896]\n",
            "[Iteration: 1767] [Loss: 0.2876831293106079]\n",
            "[Iteration: 1768] [Loss: 0.319757342338562]\n",
            "[Iteration: 1769] [Loss: 0.29448044300079346]\n",
            "[Iteration: 1770] [Loss: 0.31481167674064636]\n",
            "[Iteration: 1771] [Loss: 0.28494545817375183]\n",
            "[Iteration: 1772] [Loss: 0.27151185274124146]\n",
            "[Iteration: 1773] [Loss: 0.3017386794090271]\n",
            "[Iteration: 1774] [Loss: 0.2958894670009613]\n",
            "[Iteration: 1775] [Loss: 0.28823322057724]\n",
            "[Iteration: 1776] [Loss: 0.29163888096809387]\n",
            "[Iteration: 1777] [Loss: 0.3065340220928192]\n",
            "[Iteration: 1778] [Loss: 0.28450146317481995]\n",
            "[Iteration: 1779] [Loss: 0.26380160450935364]\n",
            "[Iteration: 1780] [Loss: 0.3090842366218567]\n",
            "[Iteration: 1781] [Loss: 0.2884310483932495]\n",
            "[Iteration: 1782] [Loss: 0.3226136267185211]\n",
            "[Iteration: 1783] [Loss: 0.3306928873062134]\n",
            "[Iteration: 1784] [Loss: 0.30027449131011963]\n",
            "[Iteration: 1785] [Loss: 0.29306069016456604]\n",
            "[Iteration: 1786] [Loss: 0.299206405878067]\n",
            "[Iteration: 1787] [Loss: 0.3064369857311249]\n",
            "[Iteration: 1788] [Loss: 0.34455323219299316]\n",
            "[Iteration: 1789] [Loss: 0.3055804967880249]\n",
            "[Iteration: 1790] [Loss: 0.28368768095970154]\n",
            "[Iteration: 1791] [Loss: 0.27727261185646057]\n",
            "[Iteration: 1792] [Loss: 0.27854716777801514]\n",
            "[Iteration: 1793] [Loss: 0.28554484248161316]\n",
            "[Iteration: 1794] [Loss: 0.3247007429599762]\n",
            "[Iteration: 1795] [Loss: 0.31914764642715454]\n",
            "[Iteration: 1796] [Loss: 0.3385664224624634]\n",
            "[Iteration: 1797] [Loss: 0.2767926752567291]\n",
            "[Iteration: 1798] [Loss: 0.30891117453575134]\n",
            "[Iteration: 1799] [Loss: 0.3162285089492798]\n",
            "[Iteration: 1800] [Loss: 0.2980502247810364]\n",
            "[Iteration: 1801] [Loss: 0.30047211050987244]\n",
            "[Iteration: 1802] [Loss: 0.2943520247936249]\n",
            "[Iteration: 1803] [Loss: 0.29771655797958374]\n",
            "[Iteration: 1804] [Loss: 0.31085821986198425]\n",
            "[Iteration: 1805] [Loss: 0.27757951617240906]\n",
            "[Iteration: 1806] [Loss: 0.2772819697856903]\n",
            "[Iteration: 1807] [Loss: 0.35404834151268005]\n",
            "[Iteration: 1808] [Loss: 0.2946825325489044]\n",
            "[Iteration: 1809] [Loss: 0.27418607473373413]\n",
            "[Iteration: 1810] [Loss: 0.2910705804824829]\n",
            "[Iteration: 1811] [Loss: 0.30948150157928467]\n",
            "[Iteration: 1812] [Loss: 0.3277221620082855]\n",
            "[Iteration: 1813] [Loss: 0.29585549235343933]\n",
            "[Iteration: 1814] [Loss: 0.24699121713638306]\n",
            "[Iteration: 1815] [Loss: 0.3126969337463379]\n",
            "[Iteration: 1816] [Loss: 0.30269452929496765]\n",
            "[Iteration: 1817] [Loss: 0.2961617112159729]\n",
            "[Iteration: 1818] [Loss: 0.3109271228313446]\n",
            "[Iteration: 1819] [Loss: 0.2906471788883209]\n",
            "[Iteration: 1820] [Loss: 0.3034225106239319]\n",
            "[Iteration: 1821] [Loss: 0.26894620060920715]\n",
            "[Iteration: 1822] [Loss: 0.2653385102748871]\n",
            "[Iteration: 1823] [Loss: 0.2836928069591522]\n",
            "[Iteration: 1824] [Loss: 0.30369409918785095]\n",
            "[Iteration: 1825] [Loss: 0.29623210430145264]\n",
            "[Iteration: 1826] [Loss: 0.2958993911743164]\n",
            "[Iteration: 1827] [Loss: 0.2729686498641968]\n",
            "[Iteration: 1828] [Loss: 0.29614803194999695]\n",
            "[Iteration: 1829] [Loss: 0.27957236766815186]\n",
            "[Iteration: 1830] [Loss: 0.2785728871822357]\n",
            "[Iteration: 1831] [Loss: 0.2640587091445923]\n",
            "[Iteration: 1832] [Loss: 0.2641098201274872]\n",
            "[Iteration: 1833] [Loss: 0.32730749249458313]\n",
            "[Iteration: 1834] [Loss: 0.28615304827690125]\n",
            "[Iteration: 1835] [Loss: 0.27312660217285156]\n",
            "[Iteration: 1836] [Loss: 0.2870325446128845]\n",
            "[Iteration: 1837] [Loss: 0.26932311058044434]\n",
            "[Iteration: 1838] [Loss: 0.2831127643585205]\n",
            "[Iteration: 1839] [Loss: 0.28116574883461]\n",
            "[Iteration: 1840] [Loss: 0.27498772740364075]\n",
            "[Iteration: 1841] [Loss: 0.3046337962150574]\n",
            "[Iteration: 1842] [Loss: 0.2623349130153656]\n",
            "[Iteration: 1843] [Loss: 0.3020552098751068]\n",
            "[Iteration: 1844] [Loss: 0.2874983549118042]\n",
            "[Iteration: 1845] [Loss: 0.3323853015899658]\n",
            "[Iteration: 1846] [Loss: 0.28749287128448486]\n",
            "[Iteration: 1847] [Loss: 0.28238072991371155]\n",
            "[Iteration: 1848] [Loss: 0.3108595609664917]\n",
            "[Iteration: 1849] [Loss: 0.29327794909477234]\n",
            "[Iteration: 1850] [Loss: 0.2816622257232666]\n",
            "[Iteration: 1851] [Loss: 0.2721061706542969]\n",
            "[Iteration: 1852] [Loss: 0.3085569441318512]\n",
            "[Iteration: 1853] [Loss: 0.29476234316825867]\n",
            "[Iteration: 1854] [Loss: 0.28268688917160034]\n",
            "[Iteration: 1855] [Loss: 0.3233763873577118]\n",
            "[Iteration: 1856] [Loss: 0.2637619972229004]\n",
            "[Iteration: 1857] [Loss: 0.269999623298645]\n",
            "[Iteration: 1858] [Loss: 0.28148573637008667]\n",
            "[Iteration: 1859] [Loss: 0.2724040448665619]\n",
            "[Iteration: 1860] [Loss: 0.3163808286190033]\n",
            "[Iteration: 1861] [Loss: 0.2789268493652344]\n",
            "[Iteration: 1862] [Loss: 0.2632870078086853]\n",
            "[Iteration: 1863] [Loss: 0.322313517332077]\n",
            "[Iteration: 1864] [Loss: 0.31984663009643555]\n",
            "[Iteration: 1865] [Loss: 0.272038996219635]\n",
            "[Iteration: 1866] [Loss: 0.29428550601005554]\n",
            "[Iteration: 1867] [Loss: 0.25288668274879456]\n",
            "[Iteration: 1868] [Loss: 0.2947334051132202]\n",
            "[Iteration: 1869] [Loss: 0.2902553379535675]\n",
            "[Iteration: 1870] [Loss: 0.3378637135028839]\n",
            "[Iteration: 1871] [Loss: 0.29194191098213196]\n",
            "[Iteration: 1872] [Loss: 0.3017878830432892]\n",
            "[Iteration: 1873] [Loss: 0.313740998506546]\n",
            "[Iteration: 1874] [Loss: 0.31990331411361694]\n",
            "[Iteration: 1875] [Loss: 0.2895462214946747]\n",
            "[Iteration: 1876] [Loss: 0.28228703141212463]\n",
            "[Iteration: 1877] [Loss: 0.25903958082199097]\n",
            "[Iteration: 1878] [Loss: 0.31363582611083984]\n",
            "[Iteration: 1879] [Loss: 0.2976177930831909]\n",
            "[Iteration: 1880] [Loss: 0.2565106153488159]\n",
            "[Iteration: 1881] [Loss: 0.2608143091201782]\n",
            "[Iteration: 1882] [Loss: 0.2536974549293518]\n",
            "[Iteration: 1883] [Loss: 0.2664378583431244]\n",
            "[Iteration: 1884] [Loss: 0.2674518823623657]\n",
            "[Iteration: 1885] [Loss: 0.3107859194278717]\n",
            "[Iteration: 1886] [Loss: 0.28126266598701477]\n",
            "[Iteration: 1887] [Loss: 0.3048938512802124]\n",
            "[Iteration: 1888] [Loss: 0.3033111095428467]\n",
            "[Iteration: 1889] [Loss: 0.2777206003665924]\n",
            "[Iteration: 1890] [Loss: 0.2617000937461853]\n",
            "[Iteration: 1891] [Loss: 0.3057127892971039]\n",
            "[Iteration: 1892] [Loss: 0.30303701758384705]\n",
            "[Iteration: 1893] [Loss: 0.28349173069000244]\n",
            "[Iteration: 1894] [Loss: 0.28486523032188416]\n",
            "[Iteration: 1895] [Loss: 0.2694319486618042]\n",
            "[Iteration: 1896] [Loss: 0.2881666421890259]\n",
            "[Iteration: 1897] [Loss: 0.28371649980545044]\n",
            "[Iteration: 1898] [Loss: 0.26773032546043396]\n",
            "[Iteration: 1899] [Loss: 0.27115264534950256]\n",
            "[Iteration: 1900] [Loss: 0.3193068504333496]\n",
            "[Iteration: 1901] [Loss: 0.2807747721672058]\n",
            "[Iteration: 1902] [Loss: 0.272480845451355]\n",
            "[Iteration: 1903] [Loss: 0.2886350154876709]\n",
            "[Iteration: 1904] [Loss: 0.29282641410827637]\n",
            "[Iteration: 1905] [Loss: 0.3024270534515381]\n",
            "[Iteration: 1906] [Loss: 0.29299771785736084]\n",
            "[Iteration: 1907] [Loss: 0.31725141406059265]\n",
            "[Iteration: 1908] [Loss: 0.306901752948761]\n",
            "[Iteration: 1909] [Loss: 0.29958394169807434]\n",
            "[Iteration: 1910] [Loss: 0.26158812642097473]\n",
            "[Iteration: 1911] [Loss: 0.25477585196495056]\n",
            "[Iteration: 1912] [Loss: 0.3022182285785675]\n",
            "[Iteration: 1913] [Loss: 0.2904904782772064]\n",
            "[Iteration: 1914] [Loss: 0.334135502576828]\n",
            "[Iteration: 1915] [Loss: 0.296071320772171]\n",
            "[Iteration: 1916] [Loss: 0.2767578661441803]\n",
            "[Iteration: 1917] [Loss: 0.31167125701904297]\n",
            "[Iteration: 1918] [Loss: 0.2537195384502411]\n",
            "[Iteration: 1919] [Loss: 0.2999168634414673]\n",
            "[Iteration: 1920] [Loss: 0.24732178449630737]\n",
            "[Iteration: 1921] [Loss: 0.2673940062522888]\n",
            "[Iteration: 1922] [Loss: 0.2613093852996826]\n",
            "[Iteration: 1923] [Loss: 0.3037954270839691]\n",
            "[Iteration: 1924] [Loss: 0.29688864946365356]\n",
            "[Iteration: 1925] [Loss: 0.2842652499675751]\n",
            "[Iteration: 1926] [Loss: 0.318424254655838]\n",
            "[Iteration: 1927] [Loss: 0.29324203729629517]\n",
            "[Iteration: 1928] [Loss: 0.27241164445877075]\n",
            "[Iteration: 1929] [Loss: 0.27522608637809753]\n",
            "[Iteration: 1930] [Loss: 0.27450206875801086]\n",
            "[Iteration: 1931] [Loss: 0.2634855806827545]\n",
            "[Iteration: 1932] [Loss: 0.30528724193573]\n",
            "[Iteration: 1933] [Loss: 0.3068732023239136]\n",
            "[Iteration: 1934] [Loss: 0.2835439145565033]\n",
            "[Iteration: 1935] [Loss: 0.28889724612236023]\n",
            "[Iteration: 1936] [Loss: 0.26424142718315125]\n",
            "[Iteration: 1937] [Loss: 0.26957833766937256]\n",
            "[Iteration: 1938] [Loss: 0.28130167722702026]\n",
            "[Iteration: 1939] [Loss: 0.27254363894462585]\n",
            "[Iteration: 1940] [Loss: 0.25904497504234314]\n",
            "[Iteration: 1941] [Loss: 0.2507060766220093]\n",
            "[Iteration: 1942] [Loss: 0.2345382571220398]\n",
            "[Iteration: 1943] [Loss: 0.23795315623283386]\n",
            "[Iteration: 1944] [Loss: 0.2869749963283539]\n",
            "[Iteration: 1945] [Loss: 0.2780618667602539]\n",
            "[Iteration: 1946] [Loss: 0.23852545022964478]\n",
            "[Iteration: 1947] [Loss: 0.2711915969848633]\n",
            "[Iteration: 1948] [Loss: 0.28909868001937866]\n",
            "[Iteration: 1949] [Loss: 0.26151344180107117]\n",
            "[Iteration: 1950] [Loss: 0.2941698431968689]\n",
            "[Iteration: 1951] [Loss: 0.29919686913490295]\n",
            "[Iteration: 1952] [Loss: 0.32286155223846436]\n",
            "[Iteration: 1953] [Loss: 0.26000967621803284]\n",
            "[Iteration: 1954] [Loss: 0.29635003209114075]\n",
            "[Iteration: 1955] [Loss: 0.2699427604675293]\n",
            "[Iteration: 1956] [Loss: 0.3056166470050812]\n",
            "[Iteration: 1957] [Loss: 0.269565224647522]\n",
            "[Iteration: 1958] [Loss: 0.27605292201042175]\n",
            "[Iteration: 1959] [Loss: 0.27150043845176697]\n",
            "[Iteration: 1960] [Loss: 0.27516746520996094]\n",
            "[Iteration: 1961] [Loss: 0.2516903579235077]\n",
            "[Iteration: 1962] [Loss: 0.27452969551086426]\n",
            "[Iteration: 1963] [Loss: 0.3047600984573364]\n",
            "[Iteration: 1964] [Loss: 0.2672523856163025]\n",
            "[Iteration: 1965] [Loss: 0.27619490027427673]\n",
            "[Iteration: 1966] [Loss: 0.32667919993400574]\n",
            "[Iteration: 1967] [Loss: 0.2816806435585022]\n",
            "[Iteration: 1968] [Loss: 0.2995032072067261]\n",
            "[Iteration: 1969] [Loss: 0.2642022371292114]\n",
            "[Iteration: 1970] [Loss: 0.26949989795684814]\n",
            "[Iteration: 1971] [Loss: 0.2846149802207947]\n",
            "[Iteration: 1972] [Loss: 0.24838665127754211]\n",
            "[Iteration: 1973] [Loss: 0.25437986850738525]\n",
            "[Iteration: 1974] [Loss: 0.26027047634124756]\n",
            "[Iteration: 1975] [Loss: 0.30675452947616577]\n",
            "[Iteration: 1976] [Loss: 0.24421170353889465]\n",
            "[Iteration: 1977] [Loss: 0.2884063720703125]\n",
            "[Iteration: 1978] [Loss: 0.28262490034103394]\n",
            "[Iteration: 1979] [Loss: 0.27755388617515564]\n",
            "[Iteration: 1980] [Loss: 0.24699102342128754]\n",
            "[Iteration: 1981] [Loss: 0.2577783167362213]\n",
            "[Iteration: 1982] [Loss: 0.28871428966522217]\n",
            "[Iteration: 1983] [Loss: 0.2875858545303345]\n",
            "[Iteration: 1984] [Loss: 0.2360411286354065]\n",
            "[Iteration: 1985] [Loss: 0.2790012061595917]\n",
            "[Iteration: 1986] [Loss: 0.2826491594314575]\n",
            "[Iteration: 1987] [Loss: 0.26138973236083984]\n",
            "[Iteration: 1988] [Loss: 0.27141913771629333]\n",
            "[Iteration: 1989] [Loss: 0.3409503698348999]\n",
            "[Iteration: 1990] [Loss: 0.3054601550102234]\n",
            "[Iteration: 1991] [Loss: 0.2782261073589325]\n",
            "[Iteration: 1992] [Loss: 0.2758943736553192]\n",
            "[Iteration: 1993] [Loss: 0.28124746680259705]\n",
            "[Iteration: 1994] [Loss: 0.29420506954193115]\n",
            "[Iteration: 1995] [Loss: 0.2756291925907135]\n",
            "[Iteration: 1996] [Loss: 0.2721196711063385]\n",
            "[Iteration: 1997] [Loss: 0.28924354910850525]\n",
            "[Iteration: 1998] [Loss: 0.3014342486858368]\n",
            "[Iteration: 1999] [Loss: 0.26670482754707336]\n",
            "[Iteration: 2000] [Loss: 0.27439314126968384]\n",
            "[Iteration: 2001] [Loss: 0.2569552958011627]\n",
            "[Iteration: 2002] [Loss: 0.27813753485679626]\n",
            "[Iteration: 2003] [Loss: 0.29143479466438293]\n",
            "[Iteration: 2004] [Loss: 0.31033509969711304]\n",
            "[Iteration: 2005] [Loss: 0.26812541484832764]\n",
            "[Iteration: 2006] [Loss: 0.2738550901412964]\n",
            "[Iteration: 2007] [Loss: 0.29411745071411133]\n",
            "[Iteration: 2008] [Loss: 0.2688804566860199]\n",
            "[Iteration: 2009] [Loss: 0.26173901557922363]\n",
            "[Iteration: 2010] [Loss: 0.2814605236053467]\n",
            "[Iteration: 2011] [Loss: 0.2599213719367981]\n",
            "[Iteration: 2012] [Loss: 0.2555244266986847]\n",
            "[Iteration: 2013] [Loss: 0.26207590103149414]\n",
            "[Iteration: 2014] [Loss: 0.2804951071739197]\n",
            "[Iteration: 2015] [Loss: 0.26915109157562256]\n",
            "[Iteration: 2016] [Loss: 0.2764233350753784]\n",
            "[Iteration: 2017] [Loss: 0.2837991714477539]\n",
            "[Iteration: 2018] [Loss: 0.2631329894065857]\n",
            "[Iteration: 2019] [Loss: 0.2857624292373657]\n",
            "[Iteration: 2020] [Loss: 0.25445878505706787]\n",
            "[Iteration: 2021] [Loss: 0.27677732706069946]\n",
            "[Iteration: 2022] [Loss: 0.25506073236465454]\n",
            "[Iteration: 2023] [Loss: 0.25147417187690735]\n",
            "[Iteration: 2024] [Loss: 0.2600754499435425]\n",
            "[Iteration: 2025] [Loss: 0.2783777713775635]\n",
            "[Iteration: 2026] [Loss: 0.2820943295955658]\n",
            "[Iteration: 2027] [Loss: 0.3126028776168823]\n",
            "[Iteration: 2028] [Loss: 0.2682851552963257]\n",
            "[Iteration: 2029] [Loss: 0.26067548990249634]\n",
            "[Iteration: 2030] [Loss: 0.2584303319454193]\n",
            "[Iteration: 2031] [Loss: 0.26657044887542725]\n",
            "[Iteration: 2032] [Loss: 0.29942846298217773]\n",
            "[Iteration: 2033] [Loss: 0.2555811107158661]\n",
            "[Iteration: 2034] [Loss: 0.27262771129608154]\n",
            "[Iteration: 2035] [Loss: 0.24782055616378784]\n",
            "[Iteration: 2036] [Loss: 0.2417641282081604]\n",
            "[Iteration: 2037] [Loss: 0.31478384137153625]\n",
            "[Iteration: 2038] [Loss: 0.23430490493774414]\n",
            "[Iteration: 2039] [Loss: 0.28699126839637756]\n",
            "[Iteration: 2040] [Loss: 0.2713913321495056]\n",
            "[Iteration: 2041] [Loss: 0.28836962580680847]\n",
            "[Iteration: 2042] [Loss: 0.25990110635757446]\n",
            "[Iteration: 2043] [Loss: 0.26231878995895386]\n",
            "[Iteration: 2044] [Loss: 0.27958476543426514]\n",
            "[Iteration: 2045] [Loss: 0.29481014609336853]\n",
            "[Iteration: 2046] [Loss: 0.2949439287185669]\n",
            "[Iteration: 2047] [Loss: 0.2775566577911377]\n",
            "[Iteration: 2048] [Loss: 0.28044411540031433]\n",
            "[Iteration: 2049] [Loss: 0.25918298959732056]\n",
            "[Iteration: 2050] [Loss: 0.2800235152244568]\n",
            "[Iteration: 2051] [Loss: 0.30226266384124756]\n",
            "[Iteration: 2052] [Loss: 0.26610833406448364]\n",
            "[Iteration: 2053] [Loss: 0.2879742980003357]\n",
            "[Iteration: 2054] [Loss: 0.29336294531822205]\n",
            "[Iteration: 2055] [Loss: 0.26132258772850037]\n",
            "[Iteration: 2056] [Loss: 0.2405010610818863]\n",
            "[Iteration: 2057] [Loss: 0.2817279100418091]\n",
            "[Iteration: 2058] [Loss: 0.26126545667648315]\n",
            "[Iteration: 2059] [Loss: 0.28524050116539]\n",
            "[Iteration: 2060] [Loss: 0.25974205136299133]\n",
            "[Iteration: 2061] [Loss: 0.2998755872249603]\n",
            "[Iteration: 2062] [Loss: 0.2656876742839813]\n",
            "[Iteration: 2063] [Loss: 0.2593063414096832]\n",
            "[Iteration: 2064] [Loss: 0.27685534954071045]\n",
            "[Iteration: 2065] [Loss: 0.26389649510383606]\n",
            "[Iteration: 2066] [Loss: 0.2549445927143097]\n",
            "[Iteration: 2067] [Loss: 0.27340075373649597]\n",
            "[Iteration: 2068] [Loss: 0.28148066997528076]\n",
            "[Iteration: 2069] [Loss: 0.28006210923194885]\n",
            "[Iteration: 2070] [Loss: 0.2944728434085846]\n",
            "[Iteration: 2071] [Loss: 0.26860105991363525]\n",
            "[Iteration: 2072] [Loss: 0.26951393485069275]\n",
            "[Iteration: 2073] [Loss: 0.2551518678665161]\n",
            "[Iteration: 2074] [Loss: 0.25806471705436707]\n",
            "[Iteration: 2075] [Loss: 0.260573148727417]\n",
            "[Iteration: 2076] [Loss: 0.29897746443748474]\n",
            "[Iteration: 2077] [Loss: 0.27995002269744873]\n",
            "[Iteration: 2078] [Loss: 0.26505714654922485]\n",
            "[Iteration: 2079] [Loss: 0.24999867379665375]\n",
            "[Iteration: 2080] [Loss: 0.2390042394399643]\n",
            "[Iteration: 2081] [Loss: 0.26927539706230164]\n",
            "[Iteration: 2082] [Loss: 0.26075056195259094]\n",
            "[Iteration: 2083] [Loss: 0.2765846848487854]\n",
            "[Iteration: 2084] [Loss: 0.26789939403533936]\n",
            "[Iteration: 2085] [Loss: 0.24634581804275513]\n",
            "[Iteration: 2086] [Loss: 0.2765054702758789]\n",
            "[Iteration: 2087] [Loss: 0.24965016543865204]\n",
            "[Iteration: 2088] [Loss: 0.2875555753707886]\n",
            "[Iteration: 2089] [Loss: 0.28517356514930725]\n",
            "[Iteration: 2090] [Loss: 0.2696171700954437]\n",
            "[Iteration: 2091] [Loss: 0.2814740836620331]\n",
            "[Iteration: 2092] [Loss: 0.24409866333007812]\n",
            "[Iteration: 2093] [Loss: 0.27795514464378357]\n",
            "[Iteration: 2094] [Loss: 0.2822243869304657]\n",
            "[Iteration: 2095] [Loss: 0.22301854193210602]\n",
            "[Iteration: 2096] [Loss: 0.26417896151542664]\n",
            "[Iteration: 2097] [Loss: 0.29545238614082336]\n",
            "[Iteration: 2098] [Loss: 0.26860347390174866]\n",
            "[Iteration: 2099] [Loss: 0.2768464982509613]\n",
            "[Iteration: 2100] [Loss: 0.27996936440467834]\n",
            "[Iteration: 2101] [Loss: 0.28578200936317444]\n",
            "[Iteration: 2102] [Loss: 0.2653892934322357]\n",
            "[Iteration: 2103] [Loss: 0.2933741509914398]\n",
            "[Iteration: 2104] [Loss: 0.26519760489463806]\n",
            "[Iteration: 2105] [Loss: 0.25563737750053406]\n",
            "[Iteration: 2106] [Loss: 0.2413673996925354]\n",
            "[Iteration: 2107] [Loss: 0.27576562762260437]\n",
            "[Iteration: 2108] [Loss: 0.25044018030166626]\n",
            "[Iteration: 2109] [Loss: 0.2722010612487793]\n",
            "[Iteration: 2110] [Loss: 0.3082566261291504]\n",
            "[Iteration: 2111] [Loss: 0.27126336097717285]\n",
            "[Iteration: 2112] [Loss: 0.25041404366493225]\n",
            "[Iteration: 2113] [Loss: 0.26765045523643494]\n",
            "[Iteration: 2114] [Loss: 0.2205251306295395]\n",
            "[Iteration: 2115] [Loss: 0.3018112778663635]\n",
            "[Iteration: 2116] [Loss: 0.2315482497215271]\n",
            "[Iteration: 2117] [Loss: 0.27762266993522644]\n",
            "[Iteration: 2118] [Loss: 0.22325563430786133]\n",
            "[Iteration: 2119] [Loss: 0.2786305248737335]\n",
            "[Iteration: 2120] [Loss: 0.2701582908630371]\n",
            "[Iteration: 2121] [Loss: 0.2705111503601074]\n",
            "[Iteration: 2122] [Loss: 0.25352638959884644]\n",
            "[Iteration: 2123] [Loss: 0.2606242001056671]\n",
            "[Iteration: 2124] [Loss: 0.27139827609062195]\n",
            "[Iteration: 2125] [Loss: 0.26619940996170044]\n",
            "[Iteration: 2126] [Loss: 0.24714986979961395]\n",
            "[Iteration: 2127] [Loss: 0.2752603590488434]\n",
            "[Iteration: 2128] [Loss: 0.2751550078392029]\n",
            "[Iteration: 2129] [Loss: 0.25504085421562195]\n",
            "[Iteration: 2130] [Loss: 0.28214260935783386]\n",
            "[Iteration: 2131] [Loss: 0.25924694538116455]\n",
            "[Iteration: 2132] [Loss: 0.23550502955913544]\n",
            "[Iteration: 2133] [Loss: 0.2557574510574341]\n",
            "[Iteration: 2134] [Loss: 0.2661614716053009]\n",
            "[Iteration: 2135] [Loss: 0.2723638117313385]\n",
            "[Iteration: 2136] [Loss: 0.2661902606487274]\n",
            "[Iteration: 2137] [Loss: 0.24228814244270325]\n",
            "[Iteration: 2138] [Loss: 0.25001418590545654]\n",
            "[Iteration: 2139] [Loss: 0.24081730842590332]\n",
            "[Iteration: 2140] [Loss: 0.26044967770576477]\n",
            "[Iteration: 2141] [Loss: 0.2487289160490036]\n",
            "[Iteration: 2142] [Loss: 0.26744306087493896]\n",
            "[Iteration: 2143] [Loss: 0.2837736904621124]\n",
            "[Iteration: 2144] [Loss: 0.2876087427139282]\n",
            "[Iteration: 2145] [Loss: 0.2816677987575531]\n",
            "[Iteration: 2146] [Loss: 0.289835661649704]\n",
            "[Iteration: 2147] [Loss: 0.2425784021615982]\n",
            "[Iteration: 2148] [Loss: 0.24224397540092468]\n",
            "[Iteration: 2149] [Loss: 0.23780444264411926]\n",
            "[Iteration: 2150] [Loss: 0.2661873996257782]\n",
            "[Iteration: 2151] [Loss: 0.3092266321182251]\n",
            "[Iteration: 2152] [Loss: 0.2712806761264801]\n",
            "[Iteration: 2153] [Loss: 0.2556068003177643]\n",
            "[Iteration: 2154] [Loss: 0.2798355519771576]\n",
            "[Iteration: 2155] [Loss: 0.26013118028640747]\n",
            "[Iteration: 2156] [Loss: 0.2571178376674652]\n",
            "[Iteration: 2157] [Loss: 0.2828240692615509]\n",
            "[Iteration: 2158] [Loss: 0.2738777995109558]\n",
            "[Iteration: 2159] [Loss: 0.2655022144317627]\n",
            "[Iteration: 2160] [Loss: 0.26830756664276123]\n",
            "[Iteration: 2161] [Loss: 0.25167587399482727]\n",
            "[Iteration: 2162] [Loss: 0.27992165088653564]\n",
            "[Iteration: 2163] [Loss: 0.2517966032028198]\n",
            "[Iteration: 2164] [Loss: 0.26939305663108826]\n",
            "[Iteration: 2165] [Loss: 0.23960092663764954]\n",
            "[Iteration: 2166] [Loss: 0.2549494504928589]\n",
            "[Iteration: 2167] [Loss: 0.26097726821899414]\n",
            "[Iteration: 2168] [Loss: 0.30013254284858704]\n",
            "[Iteration: 2169] [Loss: 0.2718792259693146]\n",
            "[Iteration: 2170] [Loss: 0.2630084156990051]\n",
            "[Iteration: 2171] [Loss: 0.25549978017807007]\n",
            "[Iteration: 2172] [Loss: 0.27192366123199463]\n",
            "[Iteration: 2173] [Loss: 0.23795683681964874]\n",
            "[Iteration: 2174] [Loss: 0.25048959255218506]\n",
            "[Iteration: 2175] [Loss: 0.2898579239845276]\n",
            "[Iteration: 2176] [Loss: 0.262703537940979]\n",
            "[Iteration: 2177] [Loss: 0.2735653817653656]\n",
            "[Iteration: 2178] [Loss: 0.26840606331825256]\n",
            "[Iteration: 2179] [Loss: 0.23481856286525726]\n",
            "[Iteration: 2180] [Loss: 0.2563818097114563]\n",
            "[Iteration: 2181] [Loss: 0.2664010524749756]\n",
            "[Iteration: 2182] [Loss: 0.29515764117240906]\n",
            "[Iteration: 2183] [Loss: 0.2131127268075943]\n",
            "[Iteration: 2184] [Loss: 0.25733309984207153]\n",
            "[Iteration: 2185] [Loss: 0.24409572780132294]\n",
            "[Iteration: 2186] [Loss: 0.2774638235569]\n",
            "[Iteration: 2187] [Loss: 0.25387367606163025]\n",
            "[Iteration: 2188] [Loss: 0.2807239592075348]\n",
            "[Iteration: 2189] [Loss: 0.2823721468448639]\n",
            "[Iteration: 2190] [Loss: 0.27562904357910156]\n",
            "[Iteration: 2191] [Loss: 0.2707080841064453]\n",
            "[Iteration: 2192] [Loss: 0.25137320160865784]\n",
            "[Iteration: 2193] [Loss: 0.2727406322956085]\n",
            "[Iteration: 2194] [Loss: 0.25014305114746094]\n",
            "[Iteration: 2195] [Loss: 0.2518657445907593]\n",
            "[Iteration: 2196] [Loss: 0.24443800747394562]\n",
            "[Iteration: 2197] [Loss: 0.2758466303348541]\n",
            "[Iteration: 2198] [Loss: 0.23731906712055206]\n",
            "[Iteration: 2199] [Loss: 0.2617102861404419]\n",
            "[Iteration: 2200] [Loss: 0.27639299631118774]\n",
            "[Iteration: 2201] [Loss: 0.2515921890735626]\n",
            "[Iteration: 2202] [Loss: 0.245946004986763]\n",
            "[Iteration: 2203] [Loss: 0.2642412781715393]\n",
            "[Iteration: 2204] [Loss: 0.24943171441555023]\n",
            "[Iteration: 2205] [Loss: 0.2813704311847687]\n",
            "[Iteration: 2206] [Loss: 0.2538217306137085]\n",
            "[Iteration: 2207] [Loss: 0.2717024087905884]\n",
            "[Iteration: 2208] [Loss: 0.2748318612575531]\n",
            "[Iteration: 2209] [Loss: 0.29782524704933167]\n",
            "[Iteration: 2210] [Loss: 0.28135088086128235]\n",
            "[Iteration: 2211] [Loss: 0.26061055064201355]\n",
            "[Iteration: 2212] [Loss: 0.27068641781806946]\n",
            "[Iteration: 2213] [Loss: 0.247280091047287]\n",
            "[Iteration: 2214] [Loss: 0.24117006361484528]\n",
            "[Iteration: 2215] [Loss: 0.23679862916469574]\n",
            "[Iteration: 2216] [Loss: 0.2728304862976074]\n",
            "[Iteration: 2217] [Loss: 0.25250566005706787]\n",
            "[Iteration: 2218] [Loss: 0.29338571429252625]\n",
            "[Iteration: 2219] [Loss: 0.2654402554035187]\n",
            "[Iteration: 2220] [Loss: 0.24146482348442078]\n",
            "[Iteration: 2221] [Loss: 0.2809208333492279]\n",
            "[Iteration: 2222] [Loss: 0.2450646013021469]\n",
            "[Iteration: 2223] [Loss: 0.23831094801425934]\n",
            "[Iteration: 2224] [Loss: 0.2248995304107666]\n",
            "[Iteration: 2225] [Loss: 0.24808213114738464]\n",
            "[Iteration: 2226] [Loss: 0.2811882197856903]\n",
            "[Iteration: 2227] [Loss: 0.2556997537612915]\n",
            "[Iteration: 2228] [Loss: 0.2340400516986847]\n",
            "[Iteration: 2229] [Loss: 0.25340965390205383]\n",
            "[Iteration: 2230] [Loss: 0.25585848093032837]\n",
            "[Iteration: 2231] [Loss: 0.2623402178287506]\n",
            "[Iteration: 2232] [Loss: 0.29707232117652893]\n",
            "[Iteration: 2233] [Loss: 0.24726621806621552]\n",
            "[Iteration: 2234] [Loss: 0.26205193996429443]\n",
            "[Iteration: 2235] [Loss: 0.22581927478313446]\n",
            "[Iteration: 2236] [Loss: 0.2593378722667694]\n",
            "[Iteration: 2237] [Loss: 0.24367846548557281]\n",
            "[Iteration: 2238] [Loss: 0.24275732040405273]\n",
            "[Iteration: 2239] [Loss: 0.26911917328834534]\n",
            "[Iteration: 2240] [Loss: 0.2551373839378357]\n",
            "[Iteration: 2241] [Loss: 0.27217379212379456]\n",
            "[Iteration: 2242] [Loss: 0.22632363438606262]\n",
            "[Iteration: 2243] [Loss: 0.24348248541355133]\n",
            "[Iteration: 2244] [Loss: 0.2845529615879059]\n",
            "[Iteration: 2245] [Loss: 0.2460518181324005]\n",
            "[Iteration: 2246] [Loss: 0.28150951862335205]\n",
            "[Iteration: 2247] [Loss: 0.2695949375629425]\n",
            "[Iteration: 2248] [Loss: 0.2612127959728241]\n",
            "[Iteration: 2249] [Loss: 0.2585623860359192]\n",
            "[Iteration: 2250] [Loss: 0.23239074647426605]\n",
            "[Iteration: 2251] [Loss: 0.2784285247325897]\n",
            "[Iteration: 2252] [Loss: 0.23585160076618195]\n",
            "[Iteration: 2253] [Loss: 0.26921162009239197]\n",
            "[Iteration: 2254] [Loss: 0.23965893685817719]\n",
            "[Iteration: 2255] [Loss: 0.2535589337348938]\n",
            "[Iteration: 2256] [Loss: 0.24007081985473633]\n",
            "[Iteration: 2257] [Loss: 0.24730467796325684]\n",
            "[Iteration: 2258] [Loss: 0.2630293071269989]\n",
            "[Iteration: 2259] [Loss: 0.27961644530296326]\n",
            "[Iteration: 2260] [Loss: 0.29601818323135376]\n",
            "[Iteration: 2261] [Loss: 0.25216543674468994]\n",
            "[Iteration: 2262] [Loss: 0.21813048422336578]\n",
            "[Iteration: 2263] [Loss: 0.23324815928936005]\n",
            "[Iteration: 2264] [Loss: 0.260127454996109]\n",
            "[Iteration: 2265] [Loss: 0.2636781930923462]\n",
            "[Iteration: 2266] [Loss: 0.2774115800857544]\n",
            "[Iteration: 2267] [Loss: 0.25219660997390747]\n",
            "[Iteration: 2268] [Loss: 0.2519870102405548]\n",
            "[Iteration: 2269] [Loss: 0.25329533219337463]\n",
            "[Iteration: 2270] [Loss: 0.24543330073356628]\n",
            "[Iteration: 2271] [Loss: 0.2451760172843933]\n",
            "[Iteration: 2272] [Loss: 0.2730318307876587]\n",
            "[Iteration: 2273] [Loss: 0.25716474652290344]\n",
            "[Iteration: 2274] [Loss: 0.26053518056869507]\n",
            "[Iteration: 2275] [Loss: 0.25530317425727844]\n",
            "[Iteration: 2276] [Loss: 0.2527856230735779]\n",
            "[Iteration: 2277] [Loss: 0.25497257709503174]\n",
            "[Iteration: 2278] [Loss: 0.23932737112045288]\n",
            "[Iteration: 2279] [Loss: 0.2446032166481018]\n",
            "[Iteration: 2280] [Loss: 0.28728848695755005]\n",
            "[Iteration: 2281] [Loss: 0.23073069751262665]\n",
            "[Iteration: 2282] [Loss: 0.25125640630722046]\n",
            "[Iteration: 2283] [Loss: 0.25084033608436584]\n",
            "[Iteration: 2284] [Loss: 0.26549744606018066]\n",
            "[Iteration: 2285] [Loss: 0.2500508725643158]\n",
            "[Iteration: 2286] [Loss: 0.2540421187877655]\n",
            "[Iteration: 2287] [Loss: 0.27801263332366943]\n",
            "[Iteration: 2288] [Loss: 0.24186675250530243]\n",
            "[Iteration: 2289] [Loss: 0.2483072578907013]\n",
            "[Iteration: 2290] [Loss: 0.26983359456062317]\n",
            "[Iteration: 2291] [Loss: 0.23697297275066376]\n",
            "[Iteration: 2292] [Loss: 0.2558339238166809]\n",
            "[Iteration: 2293] [Loss: 0.26707541942596436]\n",
            "[Iteration: 2294] [Loss: 0.2609925866127014]\n",
            "[Iteration: 2295] [Loss: 0.24538713693618774]\n",
            "[Iteration: 2296] [Loss: 0.24273374676704407]\n",
            "[Iteration: 2297] [Loss: 0.2801661789417267]\n",
            "[Iteration: 2298] [Loss: 0.246050626039505]\n",
            "[Iteration: 2299] [Loss: 0.25935035943984985]\n",
            "[Iteration: 2300] [Loss: 0.26976150274276733]\n",
            "[Iteration: 2301] [Loss: 0.20152892172336578]\n",
            "[Iteration: 2302] [Loss: 0.25129401683807373]\n",
            "[Iteration: 2303] [Loss: 0.25054824352264404]\n",
            "[Iteration: 2304] [Loss: 0.2726609706878662]\n",
            "[Iteration: 2305] [Loss: 0.24923202395439148]\n",
            "[Iteration: 2306] [Loss: 0.25917208194732666]\n",
            "[Iteration: 2307] [Loss: 0.2523546814918518]\n",
            "[Iteration: 2308] [Loss: 0.23128408193588257]\n",
            "[Iteration: 2309] [Loss: 0.24055682122707367]\n",
            "[Iteration: 2310] [Loss: 0.2648335099220276]\n",
            "[Iteration: 2311] [Loss: 0.23972760140895844]\n",
            "[Iteration: 2312] [Loss: 0.2353113442659378]\n",
            "[Iteration: 2313] [Loss: 0.24456845223903656]\n",
            "[Iteration: 2314] [Loss: 0.2628954350948334]\n",
            "[Iteration: 2315] [Loss: 0.26250341534614563]\n",
            "[Iteration: 2316] [Loss: 0.2505655586719513]\n",
            "[Iteration: 2317] [Loss: 0.22150710225105286]\n",
            "[Iteration: 2318] [Loss: 0.25625333189964294]\n",
            "[Iteration: 2319] [Loss: 0.22674332559108734]\n",
            "[Iteration: 2320] [Loss: 0.2665860950946808]\n",
            "[Iteration: 2321] [Loss: 0.26056644320487976]\n",
            "[Iteration: 2322] [Loss: 0.25613853335380554]\n",
            "[Iteration: 2323] [Loss: 0.2713082730770111]\n",
            "[Iteration: 2324] [Loss: 0.2533475160598755]\n",
            "[Iteration: 2325] [Loss: 0.21545502543449402]\n",
            "[Iteration: 2326] [Loss: 0.25284868478775024]\n",
            "[Iteration: 2327] [Loss: 0.22778984904289246]\n",
            "[Iteration: 2328] [Loss: 0.26877763867378235]\n",
            "[Iteration: 2329] [Loss: 0.25468701124191284]\n",
            "[Iteration: 2330] [Loss: 0.20710623264312744]\n",
            "[Iteration: 2331] [Loss: 0.23572216928005219]\n",
            "[Iteration: 2332] [Loss: 0.21795518696308136]\n",
            "[Iteration: 2333] [Loss: 0.2607715427875519]\n",
            "[Iteration: 2334] [Loss: 0.2357780933380127]\n",
            "[Iteration: 2335] [Loss: 0.26040077209472656]\n",
            "[Iteration: 2336] [Loss: 0.23753561079502106]\n",
            "[Iteration: 2337] [Loss: 0.24344629049301147]\n",
            "[Iteration: 2338] [Loss: 0.2297581285238266]\n",
            "[Iteration: 2339] [Loss: 0.2285689264535904]\n",
            "[Iteration: 2340] [Loss: 0.2595222592353821]\n",
            "[Iteration: 2341] [Loss: 0.2577562928199768]\n",
            "[Iteration: 2342] [Loss: 0.24995899200439453]\n",
            "[Iteration: 2343] [Loss: 0.2505246102809906]\n",
            "[Iteration: 2344] [Loss: 0.24468442797660828]\n",
            "[Iteration: 2345] [Loss: 0.2378077507019043]\n",
            "[Iteration: 2346] [Loss: 0.2596566677093506]\n",
            "[Iteration: 2347] [Loss: 0.24355506896972656]\n",
            "[Iteration: 2348] [Loss: 0.2549990713596344]\n",
            "[Iteration: 2349] [Loss: 0.25781041383743286]\n",
            "[Iteration: 2350] [Loss: 0.22245270013809204]\n",
            "[Iteration: 2351] [Loss: 0.2390398383140564]\n",
            "[Iteration: 2352] [Loss: 0.24830351769924164]\n",
            "[Iteration: 2353] [Loss: 0.2543788254261017]\n",
            "[Iteration: 2354] [Loss: 0.24851363897323608]\n",
            "[Iteration: 2355] [Loss: 0.2532341480255127]\n",
            "[Iteration: 2356] [Loss: 0.23782454431056976]\n",
            "[Iteration: 2357] [Loss: 0.2351967990398407]\n",
            "[Iteration: 2358] [Loss: 0.24161021411418915]\n",
            "[Iteration: 2359] [Loss: 0.2606601417064667]\n",
            "[Iteration: 2360] [Loss: 0.2504235506057739]\n",
            "[Iteration: 2361] [Loss: 0.2721199691295624]\n",
            "[Iteration: 2362] [Loss: 0.2293933480978012]\n",
            "[Iteration: 2363] [Loss: 0.24797704815864563]\n",
            "[Iteration: 2364] [Loss: 0.2632199227809906]\n",
            "[Iteration: 2365] [Loss: 0.2531878650188446]\n",
            "[Iteration: 2366] [Loss: 0.2483164221048355]\n",
            "[Iteration: 2367] [Loss: 0.24920672178268433]\n",
            "[Iteration: 2368] [Loss: 0.24059931933879852]\n",
            "[Iteration: 2369] [Loss: 0.2570446729660034]\n",
            "[Iteration: 2370] [Loss: 0.2521669566631317]\n",
            "[Iteration: 2371] [Loss: 0.2330561727285385]\n",
            "[Iteration: 2372] [Loss: 0.2525569200515747]\n",
            "[Iteration: 2373] [Loss: 0.2308325171470642]\n",
            "[Iteration: 2374] [Loss: 0.2521224617958069]\n",
            "[Iteration: 2375] [Loss: 0.22413502633571625]\n",
            "[Iteration: 2376] [Loss: 0.23439186811447144]\n",
            "[Iteration: 2377] [Loss: 0.22747033834457397]\n",
            "[Iteration: 2378] [Loss: 0.23476658761501312]\n",
            "[Iteration: 2379] [Loss: 0.2462199479341507]\n",
            "[Iteration: 2380] [Loss: 0.26524510979652405]\n",
            "[Iteration: 2381] [Loss: 0.22982706129550934]\n",
            "[Iteration: 2382] [Loss: 0.24612164497375488]\n",
            "[Iteration: 2383] [Loss: 0.22305499017238617]\n",
            "[Iteration: 2384] [Loss: 0.2700520157814026]\n",
            "[Iteration: 2385] [Loss: 0.2353542596101761]\n",
            "[Iteration: 2386] [Loss: 0.25086280703544617]\n",
            "[Iteration: 2387] [Loss: 0.23796814680099487]\n",
            "[Iteration: 2388] [Loss: 0.2423906922340393]\n",
            "[Iteration: 2389] [Loss: 0.3044320344924927]\n",
            "[Iteration: 2390] [Loss: 0.2708253860473633]\n",
            "[Iteration: 2391] [Loss: 0.22469483315944672]\n",
            "[Iteration: 2392] [Loss: 0.23094098269939423]\n",
            "[Iteration: 2393] [Loss: 0.2399207204580307]\n",
            "[Iteration: 2394] [Loss: 0.23130591213703156]\n",
            "[Iteration: 2395] [Loss: 0.25711381435394287]\n",
            "[Iteration: 2396] [Loss: 0.2350747287273407]\n",
            "[Iteration: 2397] [Loss: 0.23040220141410828]\n",
            "[Iteration: 2398] [Loss: 0.23709051311016083]\n",
            "[Iteration: 2399] [Loss: 0.25664883852005005]\n",
            "[Iteration: 2400] [Loss: 0.2237986922264099]\n",
            "[Iteration: 2401] [Loss: 0.22766701877117157]\n",
            "[Iteration: 2402] [Loss: 0.22054871916770935]\n",
            "[Iteration: 2403] [Loss: 0.223554790019989]\n",
            "[Iteration: 2404] [Loss: 0.25747549533843994]\n",
            "[Iteration: 2405] [Loss: 0.22969187796115875]\n",
            "[Iteration: 2406] [Loss: 0.2307337075471878]\n",
            "[Iteration: 2407] [Loss: 0.23754800856113434]\n",
            "[Iteration: 2408] [Loss: 0.27502602338790894]\n",
            "[Iteration: 2409] [Loss: 0.25469356775283813]\n",
            "[Iteration: 2410] [Loss: 0.268225759267807]\n",
            "[Iteration: 2411] [Loss: 0.20871002972126007]\n",
            "[Iteration: 2412] [Loss: 0.25560253858566284]\n",
            "[Iteration: 2413] [Loss: 0.26870858669281006]\n",
            "[Iteration: 2414] [Loss: 0.23010820150375366]\n",
            "[Iteration: 2415] [Loss: 0.2546842396259308]\n",
            "[Iteration: 2416] [Loss: 0.2707776129245758]\n",
            "[Iteration: 2417] [Loss: 0.23723319172859192]\n",
            "[Iteration: 2418] [Loss: 0.22446481883525848]\n",
            "[Iteration: 2419] [Loss: 0.2527194321155548]\n",
            "[Iteration: 2420] [Loss: 0.27226874232292175]\n",
            "[Iteration: 2421] [Loss: 0.25784391164779663]\n",
            "[Iteration: 2422] [Loss: 0.2246628850698471]\n",
            "[Iteration: 2423] [Loss: 0.2443595677614212]\n",
            "[Iteration: 2424] [Loss: 0.2170107364654541]\n",
            "[Iteration: 2425] [Loss: 0.23663252592086792]\n",
            "[Iteration: 2426] [Loss: 0.26234865188598633]\n",
            "[Iteration: 2427] [Loss: 0.23566113412380219]\n",
            "[Iteration: 2428] [Loss: 0.24216750264167786]\n",
            "[Iteration: 2429] [Loss: 0.25820299983024597]\n",
            "[Iteration: 2430] [Loss: 0.2281411737203598]\n",
            "[Iteration: 2431] [Loss: 0.22409898042678833]\n",
            "[Iteration: 2432] [Loss: 0.25495609641075134]\n",
            "[Iteration: 2433] [Loss: 0.25543829798698425]\n",
            "[Iteration: 2434] [Loss: 0.2448291778564453]\n",
            "[Iteration: 2435] [Loss: 0.2102614790201187]\n",
            "[Iteration: 2436] [Loss: 0.22392381727695465]\n",
            "[Iteration: 2437] [Loss: 0.22895547747612]\n",
            "[Iteration: 2438] [Loss: 0.2341134250164032]\n",
            "[Iteration: 2439] [Loss: 0.2243226170539856]\n",
            "[Iteration: 2440] [Loss: 0.26134994626045227]\n",
            "[Iteration: 2441] [Loss: 0.24590931832790375]\n",
            "[Iteration: 2442] [Loss: 0.23835232853889465]\n",
            "[Iteration: 2443] [Loss: 0.23574751615524292]\n",
            "[Iteration: 2444] [Loss: 0.2486536204814911]\n",
            "[Iteration: 2445] [Loss: 0.22444748878479004]\n",
            "[Iteration: 2446] [Loss: 0.23844385147094727]\n",
            "[Iteration: 2447] [Loss: 0.23407970368862152]\n",
            "[Iteration: 2448] [Loss: 0.25565069913864136]\n",
            "[Iteration: 2449] [Loss: 0.25500044226646423]\n",
            "[Iteration: 2450] [Loss: 0.22622352838516235]\n",
            "[Iteration: 2451] [Loss: 0.2627432644367218]\n",
            "[Iteration: 2452] [Loss: 0.2233152687549591]\n",
            "[Iteration: 2453] [Loss: 0.2514163553714752]\n",
            "[Iteration: 2454] [Loss: 0.2281283736228943]\n",
            "[Iteration: 2455] [Loss: 0.2219909429550171]\n",
            "[Iteration: 2456] [Loss: 0.2279203236103058]\n",
            "[Iteration: 2457] [Loss: 0.21719278395175934]\n",
            "[Iteration: 2458] [Loss: 0.24104979634284973]\n",
            "[Iteration: 2459] [Loss: 0.19780926406383514]\n",
            "[Iteration: 2460] [Loss: 0.22247999906539917]\n",
            "[Iteration: 2461] [Loss: 0.2663840353488922]\n",
            "[Iteration: 2462] [Loss: 0.2177748680114746]\n",
            "[Iteration: 2463] [Loss: 0.22064149379730225]\n",
            "[Iteration: 2464] [Loss: 0.24144142866134644]\n",
            "[Iteration: 2465] [Loss: 0.22576840221881866]\n",
            "[Iteration: 2466] [Loss: 0.25082123279571533]\n",
            "[Iteration: 2467] [Loss: 0.2519405484199524]\n",
            "[Iteration: 2468] [Loss: 0.24938586354255676]\n",
            "[Iteration: 2469] [Loss: 0.22101996839046478]\n",
            "[Iteration: 2470] [Loss: 0.25198373198509216]\n",
            "[Iteration: 2471] [Loss: 0.24192854762077332]\n",
            "[Iteration: 2472] [Loss: 0.23250627517700195]\n",
            "[Iteration: 2473] [Loss: 0.20684431493282318]\n",
            "[Iteration: 2474] [Loss: 0.24186116456985474]\n",
            "[Iteration: 2475] [Loss: 0.26017898321151733]\n",
            "[Iteration: 2476] [Loss: 0.22819754481315613]\n",
            "[Iteration: 2477] [Loss: 0.2235996127128601]\n",
            "[Iteration: 2478] [Loss: 0.223628968000412]\n",
            "[Iteration: 2479] [Loss: 0.23379169404506683]\n",
            "[Iteration: 2480] [Loss: 0.2526334226131439]\n",
            "[Iteration: 2481] [Loss: 0.23371632397174835]\n",
            "[Iteration: 2482] [Loss: 0.25589436292648315]\n",
            "[Iteration: 2483] [Loss: 0.24150440096855164]\n",
            "[Iteration: 2484] [Loss: 0.2110617756843567]\n",
            "[Iteration: 2485] [Loss: 0.23940788209438324]\n",
            "[Iteration: 2486] [Loss: 0.23993293941020966]\n",
            "[Iteration: 2487] [Loss: 0.21159011125564575]\n",
            "[Iteration: 2488] [Loss: 0.23943275213241577]\n",
            "[Iteration: 2489] [Loss: 0.22121605277061462]\n",
            "[Iteration: 2490] [Loss: 0.28615596890449524]\n",
            "[Iteration: 2491] [Loss: 0.2452598661184311]\n",
            "[Iteration: 2492] [Loss: 0.23904384672641754]\n",
            "[Iteration: 2493] [Loss: 0.20210498571395874]\n",
            "[Iteration: 2494] [Loss: 0.22729510068893433]\n",
            "[Iteration: 2495] [Loss: 0.24704459309577942]\n",
            "[Iteration: 2496] [Loss: 0.22856181859970093]\n",
            "[Iteration: 2497] [Loss: 0.2284647822380066]\n",
            "[Iteration: 2498] [Loss: 0.23083308339118958]\n",
            "[Iteration: 2499] [Loss: 0.2619033455848694]\n",
            "[Iteration: 2500] [Loss: 0.2101014256477356]\n",
            "[Iteration: 2501] [Loss: 0.2402939796447754]\n",
            "[Iteration: 2502] [Loss: 0.2519446611404419]\n",
            "[Iteration: 2503] [Loss: 0.22588133811950684]\n",
            "[Iteration: 2504] [Loss: 0.2376047521829605]\n",
            "[Iteration: 2505] [Loss: 0.22214266657829285]\n",
            "[Iteration: 2506] [Loss: 0.2315502166748047]\n",
            "[Iteration: 2507] [Loss: 0.23051367700099945]\n",
            "[Iteration: 2508] [Loss: 0.2357502579689026]\n",
            "[Iteration: 2509] [Loss: 0.24416814744472504]\n",
            "[Iteration: 2510] [Loss: 0.21709808707237244]\n",
            "[Iteration: 2511] [Loss: 0.23735539615154266]\n",
            "[Iteration: 2512] [Loss: 0.23319000005722046]\n",
            "[Iteration: 2513] [Loss: 0.23344333469867706]\n",
            "[Iteration: 2514] [Loss: 0.23415671288967133]\n",
            "[Iteration: 2515] [Loss: 0.21547870337963104]\n",
            "[Iteration: 2516] [Loss: 0.231318399310112]\n",
            "[Iteration: 2517] [Loss: 0.24929934740066528]\n",
            "[Iteration: 2518] [Loss: 0.24751850962638855]\n",
            "[Iteration: 2519] [Loss: 0.22769573330879211]\n",
            "[Iteration: 2520] [Loss: 0.2358524054288864]\n",
            "[Iteration: 2521] [Loss: 0.23485486209392548]\n",
            "[Iteration: 2522] [Loss: 0.2569223642349243]\n",
            "[Iteration: 2523] [Loss: 0.2393747717142105]\n",
            "[Iteration: 2524] [Loss: 0.2105749249458313]\n",
            "[Iteration: 2525] [Loss: 0.285675585269928]\n",
            "[Iteration: 2526] [Loss: 0.23797713220119476]\n",
            "[Iteration: 2527] [Loss: 0.216087207198143]\n",
            "[Iteration: 2528] [Loss: 0.21916542947292328]\n",
            "[Iteration: 2529] [Loss: 0.236577570438385]\n",
            "[Iteration: 2530] [Loss: 0.22752438485622406]\n",
            "[Iteration: 2531] [Loss: 0.2115643322467804]\n",
            "[Iteration: 2532] [Loss: 0.2227896898984909]\n",
            "[Iteration: 2533] [Loss: 0.208919495344162]\n",
            "[Iteration: 2534] [Loss: 0.2187059372663498]\n",
            "[Iteration: 2535] [Loss: 0.2194688469171524]\n",
            "[Iteration: 2536] [Loss: 0.23205409944057465]\n",
            "[Iteration: 2537] [Loss: 0.23006974160671234]\n",
            "[Iteration: 2538] [Loss: 0.23000410199165344]\n",
            "[Iteration: 2539] [Loss: 0.21958261728286743]\n",
            "[Iteration: 2540] [Loss: 0.24925576150417328]\n",
            "[Iteration: 2541] [Loss: 0.2361043095588684]\n",
            "[Iteration: 2542] [Loss: 0.22387559711933136]\n",
            "[Iteration: 2543] [Loss: 0.2354528158903122]\n",
            "[Iteration: 2544] [Loss: 0.24446068704128265]\n",
            "[Iteration: 2545] [Loss: 0.242254838347435]\n",
            "[Iteration: 2546] [Loss: 0.2200910449028015]\n",
            "[Iteration: 2547] [Loss: 0.26376423239707947]\n",
            "[Iteration: 2548] [Loss: 0.22139881551265717]\n",
            "[Iteration: 2549] [Loss: 0.23396208882331848]\n",
            "[Iteration: 2550] [Loss: 0.22651603817939758]\n",
            "[Iteration: 2551] [Loss: 0.2433568686246872]\n",
            "[Iteration: 2552] [Loss: 0.23270103335380554]\n",
            "[Iteration: 2553] [Loss: 0.2628321349620819]\n",
            "[Iteration: 2554] [Loss: 0.24043403565883636]\n",
            "[Iteration: 2555] [Loss: 0.24077561497688293]\n",
            "[Iteration: 2556] [Loss: 0.23381955921649933]\n",
            "[Iteration: 2557] [Loss: 0.24370180070400238]\n",
            "[Iteration: 2558] [Loss: 0.1931203007698059]\n",
            "[Iteration: 2559] [Loss: 0.2269674688577652]\n",
            "[Iteration: 2560] [Loss: 0.24631494283676147]\n",
            "[Iteration: 2561] [Loss: 0.21801616251468658]\n",
            "[Iteration: 2562] [Loss: 0.22313565015792847]\n",
            "[Iteration: 2563] [Loss: 0.22961701452732086]\n",
            "[Iteration: 2564] [Loss: 0.27480456233024597]\n",
            "[Iteration: 2565] [Loss: 0.2144881784915924]\n",
            "[Iteration: 2566] [Loss: 0.2295716106891632]\n",
            "[Iteration: 2567] [Loss: 0.23328430950641632]\n",
            "[Iteration: 2568] [Loss: 0.23524615168571472]\n",
            "[Iteration: 2569] [Loss: 0.2620116174221039]\n",
            "[Iteration: 2570] [Loss: 0.26058465242385864]\n",
            "[Iteration: 2571] [Loss: 0.2515042722225189]\n",
            "[Iteration: 2572] [Loss: 0.24586574733257294]\n",
            "[Iteration: 2573] [Loss: 0.23282061517238617]\n",
            "[Iteration: 2574] [Loss: 0.22232535481452942]\n",
            "[Iteration: 2575] [Loss: 0.2277936339378357]\n",
            "[Iteration: 2576] [Loss: 0.23369179666042328]\n",
            "[Iteration: 2577] [Loss: 0.21581880748271942]\n",
            "[Iteration: 2578] [Loss: 0.23577673733234406]\n",
            "[Iteration: 2579] [Loss: 0.23673884570598602]\n",
            "[Iteration: 2580] [Loss: 0.2150515764951706]\n",
            "[Iteration: 2581] [Loss: 0.22952492535114288]\n",
            "[Iteration: 2582] [Loss: 0.23790767788887024]\n",
            "[Iteration: 2583] [Loss: 0.21440210938453674]\n",
            "[Iteration: 2584] [Loss: 0.21655085682868958]\n",
            "[Iteration: 2585] [Loss: 0.2158961296081543]\n",
            "[Iteration: 2586] [Loss: 0.21578368544578552]\n",
            "[Iteration: 2587] [Loss: 0.22250965237617493]\n",
            "[Iteration: 2588] [Loss: 0.2191338986158371]\n",
            "[Iteration: 2589] [Loss: 0.21479752659797668]\n",
            "[Iteration: 2590] [Loss: 0.2179146111011505]\n",
            "[Iteration: 2591] [Loss: 0.2371051013469696]\n",
            "[Iteration: 2592] [Loss: 0.21266981959342957]\n",
            "[Iteration: 2593] [Loss: 0.23222416639328003]\n",
            "[Iteration: 2594] [Loss: 0.2796182930469513]\n",
            "[Iteration: 2595] [Loss: 0.21469944715499878]\n",
            "[Iteration: 2596] [Loss: 0.20508626103401184]\n",
            "[Iteration: 2597] [Loss: 0.2013489156961441]\n",
            "[Iteration: 2598] [Loss: 0.26464736461639404]\n",
            "[Iteration: 2599] [Loss: 0.19404004514217377]\n",
            "[Iteration: 2600] [Loss: 0.26943182945251465]\n",
            "[Iteration: 2601] [Loss: 0.23560483753681183]\n",
            "[Iteration: 2602] [Loss: 0.20972520112991333]\n",
            "[Iteration: 2603] [Loss: 0.2330373078584671]\n",
            "[Iteration: 2604] [Loss: 0.23582866787910461]\n",
            "[Iteration: 2605] [Loss: 0.22898438572883606]\n",
            "[Iteration: 2606] [Loss: 0.21887686848640442]\n",
            "[Iteration: 2607] [Loss: 0.23662638664245605]\n",
            "[Iteration: 2608] [Loss: 0.2514886260032654]\n",
            "[Iteration: 2609] [Loss: 0.22995856404304504]\n",
            "[Iteration: 2610] [Loss: 0.26581838726997375]\n",
            "[Iteration: 2611] [Loss: 0.20783303678035736]\n",
            "[Iteration: 2612] [Loss: 0.21793150901794434]\n",
            "[Iteration: 2613] [Loss: 0.22889961302280426]\n",
            "[Iteration: 2614] [Loss: 0.21489068865776062]\n",
            "[Iteration: 2615] [Loss: 0.22516165673732758]\n",
            "[Iteration: 2616] [Loss: 0.2518104314804077]\n",
            "[Iteration: 2617] [Loss: 0.22324585914611816]\n",
            "[Iteration: 2618] [Loss: 0.2381308376789093]\n",
            "[Iteration: 2619] [Loss: 0.22646716237068176]\n",
            "[Iteration: 2620] [Loss: 0.22807222604751587]\n",
            "[Iteration: 2621] [Loss: 0.20552632212638855]\n",
            "[Iteration: 2622] [Loss: 0.25427353382110596]\n",
            "[Iteration: 2623] [Loss: 0.2348063588142395]\n",
            "[Iteration: 2624] [Loss: 0.2004387378692627]\n",
            "[Iteration: 2625] [Loss: 0.253356397151947]\n",
            "[Iteration: 2626] [Loss: 0.24239200353622437]\n",
            "[Iteration: 2627] [Loss: 0.24390479922294617]\n",
            "[Iteration: 2628] [Loss: 0.2307782769203186]\n",
            "[Iteration: 2629] [Loss: 0.22792407870292664]\n",
            "[Iteration: 2630] [Loss: 0.25048792362213135]\n",
            "[Iteration: 2631] [Loss: 0.23268373310565948]\n",
            "[Iteration: 2632] [Loss: 0.21639873087406158]\n",
            "[Iteration: 2633] [Loss: 0.2377169132232666]\n",
            "[Iteration: 2634] [Loss: 0.19655568897724152]\n",
            "[Iteration: 2635] [Loss: 0.22298237681388855]\n",
            "[Iteration: 2636] [Loss: 0.2699563801288605]\n",
            "[Iteration: 2637] [Loss: 0.2131207138299942]\n",
            "[Iteration: 2638] [Loss: 0.25210294127464294]\n",
            "[Iteration: 2639] [Loss: 0.2188737690448761]\n",
            "[Iteration: 2640] [Loss: 0.25125959515571594]\n",
            "[Iteration: 2641] [Loss: 0.21564100682735443]\n",
            "[Iteration: 2642] [Loss: 0.23254945874214172]\n",
            "[Iteration: 2643] [Loss: 0.22636887431144714]\n",
            "[Iteration: 2644] [Loss: 0.23454438149929047]\n",
            "[Iteration: 2645] [Loss: 0.21798229217529297]\n",
            "[Iteration: 2646] [Loss: 0.2519684135913849]\n",
            "[Iteration: 2647] [Loss: 0.20410262048244476]\n",
            "[Iteration: 2648] [Loss: 0.21008163690567017]\n",
            "[Iteration: 2649] [Loss: 0.21810126304626465]\n",
            "[Iteration: 2650] [Loss: 0.23003074526786804]\n",
            "[Iteration: 2651] [Loss: 0.27061712741851807]\n",
            "[Iteration: 2652] [Loss: 0.21281945705413818]\n",
            "[Iteration: 2653] [Loss: 0.19629299640655518]\n",
            "[Iteration: 2654] [Loss: 0.21575932204723358]\n",
            "[Iteration: 2655] [Loss: 0.26170486211776733]\n",
            "[Iteration: 2656] [Loss: 0.22362235188484192]\n",
            "[Iteration: 2657] [Loss: 0.21308179199695587]\n",
            "[Iteration: 2658] [Loss: 0.2014511376619339]\n",
            "[Iteration: 2659] [Loss: 0.23965515196323395]\n",
            "[Iteration: 2660] [Loss: 0.2184702306985855]\n",
            "[Iteration: 2661] [Loss: 0.2336532473564148]\n",
            "[Iteration: 2662] [Loss: 0.22900384664535522]\n",
            "[Iteration: 2663] [Loss: 0.21076345443725586]\n",
            "[Iteration: 2664] [Loss: 0.21703805029392242]\n",
            "[Iteration: 2665] [Loss: 0.2061256617307663]\n",
            "[Iteration: 2666] [Loss: 0.22343087196350098]\n",
            "[Iteration: 2667] [Loss: 0.23651735484600067]\n",
            "[Iteration: 2668] [Loss: 0.2393401712179184]\n",
            "[Iteration: 2669] [Loss: 0.25068002939224243]\n",
            "[Iteration: 2670] [Loss: 0.2063198685646057]\n",
            "[Iteration: 2671] [Loss: 0.2108653336763382]\n",
            "[Iteration: 2672] [Loss: 0.20231756567955017]\n",
            "[Iteration: 2673] [Loss: 0.21464161574840546]\n",
            "[Iteration: 2674] [Loss: 0.2375064492225647]\n",
            "[Iteration: 2675] [Loss: 0.22310344874858856]\n",
            "[Iteration: 2676] [Loss: 0.2032710611820221]\n",
            "[Iteration: 2677] [Loss: 0.22552275657653809]\n",
            "[Iteration: 2678] [Loss: 0.2439018338918686]\n",
            "[Iteration: 2679] [Loss: 0.25346601009368896]\n",
            "[Iteration: 2680] [Loss: 0.22649748623371124]\n",
            "[Iteration: 2681] [Loss: 0.21071761846542358]\n",
            "[Iteration: 2682] [Loss: 0.22014397382736206]\n",
            "[Iteration: 2683] [Loss: 0.2090480625629425]\n",
            "[Iteration: 2684] [Loss: 0.22154337167739868]\n",
            "[Iteration: 2685] [Loss: 0.21693524718284607]\n",
            "[Iteration: 2686] [Loss: 0.19951482117176056]\n",
            "[Iteration: 2687] [Loss: 0.21927839517593384]\n",
            "[Iteration: 2688] [Loss: 0.22881025075912476]\n",
            "[Iteration: 2689] [Loss: 0.22940462827682495]\n",
            "[Iteration: 2690] [Loss: 0.2123342901468277]\n",
            "[Iteration: 2691] [Loss: 0.23222997784614563]\n",
            "[Iteration: 2692] [Loss: 0.20276765525341034]\n",
            "[Iteration: 2693] [Loss: 0.2518409490585327]\n",
            "[Iteration: 2694] [Loss: 0.20158983767032623]\n",
            "[Iteration: 2695] [Loss: 0.24398401379585266]\n",
            "[Iteration: 2696] [Loss: 0.2017732709646225]\n",
            "[Iteration: 2697] [Loss: 0.20674145221710205]\n",
            "[Iteration: 2698] [Loss: 0.22097335755825043]\n",
            "[Iteration: 2699] [Loss: 0.19805219769477844]\n",
            "[Iteration: 2700] [Loss: 0.1948847621679306]\n",
            "[Iteration: 2701] [Loss: 0.233348548412323]\n",
            "[Iteration: 2702] [Loss: 0.24863441288471222]\n",
            "[Iteration: 2703] [Loss: 0.22548481822013855]\n",
            "[Iteration: 2704] [Loss: 0.2389337718486786]\n",
            "[Iteration: 2705] [Loss: 0.21558064222335815]\n",
            "[Iteration: 2706] [Loss: 0.2260688692331314]\n",
            "[Iteration: 2707] [Loss: 0.2254524528980255]\n",
            "[Iteration: 2708] [Loss: 0.24858130514621735]\n",
            "[Iteration: 2709] [Loss: 0.2154187262058258]\n",
            "[Iteration: 2710] [Loss: 0.19553238153457642]\n",
            "[Iteration: 2711] [Loss: 0.20556972920894623]\n",
            "[Iteration: 2712] [Loss: 0.19721025228500366]\n",
            "[Iteration: 2713] [Loss: 0.23879221081733704]\n",
            "[Iteration: 2714] [Loss: 0.2049866020679474]\n",
            "[Iteration: 2715] [Loss: 0.22035841643810272]\n",
            "[Iteration: 2716] [Loss: 0.21748463809490204]\n",
            "[Iteration: 2717] [Loss: 0.27412229776382446]\n",
            "[Iteration: 2718] [Loss: 0.24293316900730133]\n",
            "[Iteration: 2719] [Loss: 0.19746257364749908]\n",
            "[Iteration: 2720] [Loss: 0.20234167575836182]\n",
            "[Iteration: 2721] [Loss: 0.23788152635097504]\n",
            "[Iteration: 2722] [Loss: 0.2160368412733078]\n",
            "[Iteration: 2723] [Loss: 0.22069679200649261]\n",
            "[Iteration: 2724] [Loss: 0.20774224400520325]\n",
            "[Iteration: 2725] [Loss: 0.19731539487838745]\n",
            "[Iteration: 2726] [Loss: 0.2092568427324295]\n",
            "[Iteration: 2727] [Loss: 0.21878278255462646]\n",
            "[Iteration: 2728] [Loss: 0.215127632021904]\n",
            "[Iteration: 2729] [Loss: 0.23277606070041656]\n",
            "[Iteration: 2730] [Loss: 0.23776684701442719]\n",
            "[Iteration: 2731] [Loss: 0.19384115934371948]\n",
            "[Iteration: 2732] [Loss: 0.2229716032743454]\n",
            "[Iteration: 2733] [Loss: 0.2186923325061798]\n",
            "[Iteration: 2734] [Loss: 0.20341789722442627]\n",
            "[Iteration: 2735] [Loss: 0.19514261186122894]\n",
            "[Iteration: 2736] [Loss: 0.21341866254806519]\n",
            "[Iteration: 2737] [Loss: 0.2328014373779297]\n",
            "[Iteration: 2738] [Loss: 0.2281896024942398]\n",
            "[Iteration: 2739] [Loss: 0.22149930894374847]\n",
            "[Iteration: 2740] [Loss: 0.27022475004196167]\n",
            "[Iteration: 2741] [Loss: 0.24479492008686066]\n",
            "[Iteration: 2742] [Loss: 0.2388572096824646]\n",
            "[Iteration: 2743] [Loss: 0.2490745186805725]\n",
            "[Iteration: 2744] [Loss: 0.19593697786331177]\n",
            "[Iteration: 2745] [Loss: 0.22893373668193817]\n",
            "[Iteration: 2746] [Loss: 0.24775226414203644]\n",
            "[Iteration: 2747] [Loss: 0.2211264967918396]\n",
            "[Iteration: 2748] [Loss: 0.1931726336479187]\n",
            "[Iteration: 2749] [Loss: 0.22993691265583038]\n",
            "[Iteration: 2750] [Loss: 0.24163341522216797]\n",
            "[Iteration: 2751] [Loss: 0.2184538096189499]\n",
            "[Iteration: 2752] [Loss: 0.22184273600578308]\n",
            "[Iteration: 2753] [Loss: 0.20788566768169403]\n",
            "[Iteration: 2754] [Loss: 0.23479196429252625]\n",
            "[Iteration: 2755] [Loss: 0.23886540532112122]\n",
            "[Iteration: 2756] [Loss: 0.21555621922016144]\n",
            "[Iteration: 2757] [Loss: 0.22817444801330566]\n",
            "[Iteration: 2758] [Loss: 0.22400464117527008]\n",
            "[Iteration: 2759] [Loss: 0.221195250749588]\n",
            "[Iteration: 2760] [Loss: 0.23896591365337372]\n",
            "[Iteration: 2761] [Loss: 0.19818724691867828]\n",
            "[Iteration: 2762] [Loss: 0.1940123289823532]\n",
            "[Iteration: 2763] [Loss: 0.23268617689609528]\n",
            "[Iteration: 2764] [Loss: 0.2341182976961136]\n",
            "[Iteration: 2765] [Loss: 0.23850764334201813]\n",
            "[Iteration: 2766] [Loss: 0.21027249097824097]\n",
            "[Iteration: 2767] [Loss: 0.2680317759513855]\n",
            "[Iteration: 2768] [Loss: 0.2677164673805237]\n",
            "[Iteration: 2769] [Loss: 0.21921467781066895]\n",
            "[Iteration: 2770] [Loss: 0.22357392311096191]\n",
            "[Iteration: 2771] [Loss: 0.21957062184810638]\n",
            "[Iteration: 2772] [Loss: 0.19847753643989563]\n",
            "[Iteration: 2773] [Loss: 0.21699422597885132]\n",
            "[Iteration: 2774] [Loss: 0.22747492790222168]\n",
            "[Iteration: 2775] [Loss: 0.18503814935684204]\n",
            "[Iteration: 2776] [Loss: 0.2140907645225525]\n",
            "[Iteration: 2777] [Loss: 0.2159048616886139]\n",
            "[Iteration: 2778] [Loss: 0.21121171116828918]\n",
            "[Iteration: 2779] [Loss: 0.22081071138381958]\n",
            "[Iteration: 2780] [Loss: 0.21607021987438202]\n",
            "[Iteration: 2781] [Loss: 0.200975239276886]\n",
            "[Iteration: 2782] [Loss: 0.20079416036605835]\n",
            "[Iteration: 2783] [Loss: 0.1995537281036377]\n",
            "[Iteration: 2784] [Loss: 0.2103445827960968]\n",
            "[Iteration: 2785] [Loss: 0.2152547985315323]\n",
            "[Iteration: 2786] [Loss: 0.2195725291967392]\n",
            "[Iteration: 2787] [Loss: 0.25037771463394165]\n",
            "[Iteration: 2788] [Loss: 0.2016012966632843]\n",
            "[Iteration: 2789] [Loss: 0.22480297088623047]\n",
            "[Iteration: 2790] [Loss: 0.24079076945781708]\n",
            "[Iteration: 2791] [Loss: 0.24130651354789734]\n",
            "[Iteration: 2792] [Loss: 0.22467494010925293]\n",
            "[Iteration: 2793] [Loss: 0.19668065011501312]\n",
            "[Iteration: 2794] [Loss: 0.21296045184135437]\n",
            "[Iteration: 2795] [Loss: 0.2245541214942932]\n",
            "[Iteration: 2796] [Loss: 0.21169061958789825]\n",
            "[Iteration: 2797] [Loss: 0.21428006887435913]\n",
            "[Iteration: 2798] [Loss: 0.22057771682739258]\n",
            "[Iteration: 2799] [Loss: 0.22404581308364868]\n",
            "[Iteration: 2800] [Loss: 0.19068290293216705]\n",
            "[Iteration: 2801] [Loss: 0.20883136987686157]\n",
            "[Iteration: 2802] [Loss: 0.19037462770938873]\n",
            "[Iteration: 2803] [Loss: 0.21367880702018738]\n",
            "[Iteration: 2804] [Loss: 0.2371772676706314]\n",
            "[Iteration: 2805] [Loss: 0.21411475539207458]\n",
            "[Iteration: 2806] [Loss: 0.22170734405517578]\n",
            "[Iteration: 2807] [Loss: 0.20638133585453033]\n",
            "[Iteration: 2808] [Loss: 0.2221459299325943]\n",
            "[Iteration: 2809] [Loss: 0.20174585282802582]\n",
            "[Iteration: 2810] [Loss: 0.2169121652841568]\n",
            "[Iteration: 2811] [Loss: 0.20690912008285522]\n",
            "[Iteration: 2812] [Loss: 0.206229567527771]\n",
            "[Iteration: 2813] [Loss: 0.2241094708442688]\n",
            "[Iteration: 2814] [Loss: 0.20284196734428406]\n",
            "[Iteration: 2815] [Loss: 0.23201701045036316]\n",
            "[Iteration: 2816] [Loss: 0.19744595885276794]\n",
            "[Iteration: 2817] [Loss: 0.19849950075149536]\n",
            "[Iteration: 2818] [Loss: 0.23065826296806335]\n",
            "[Iteration: 2819] [Loss: 0.20171235501766205]\n",
            "[Iteration: 2820] [Loss: 0.19346283376216888]\n",
            "[Iteration: 2821] [Loss: 0.22016984224319458]\n",
            "[Iteration: 2822] [Loss: 0.23548224568367004]\n",
            "[Iteration: 2823] [Loss: 0.2266472727060318]\n",
            "[Iteration: 2824] [Loss: 0.2351638674736023]\n",
            "[Iteration: 2825] [Loss: 0.2107292264699936]\n",
            "[Iteration: 2826] [Loss: 0.24056394398212433]\n",
            "[Iteration: 2827] [Loss: 0.20204776525497437]\n",
            "[Iteration: 2828] [Loss: 0.20191645622253418]\n",
            "[Iteration: 2829] [Loss: 0.2239857316017151]\n",
            "[Iteration: 2830] [Loss: 0.23657923936843872]\n",
            "[Iteration: 2831] [Loss: 0.21577365696430206]\n",
            "[Iteration: 2832] [Loss: 0.22449146211147308]\n",
            "[Iteration: 2833] [Loss: 0.22884109616279602]\n",
            "[Iteration: 2834] [Loss: 0.2121417373418808]\n",
            "[Iteration: 2835] [Loss: 0.1975758671760559]\n",
            "[Iteration: 2836] [Loss: 0.23025093972682953]\n",
            "[Iteration: 2837] [Loss: 0.19960080087184906]\n",
            "[Iteration: 2838] [Loss: 0.19855128228664398]\n",
            "[Iteration: 2839] [Loss: 0.19810576736927032]\n",
            "[Iteration: 2840] [Loss: 0.21412786841392517]\n",
            "[Iteration: 2841] [Loss: 0.2399364858865738]\n",
            "[Iteration: 2842] [Loss: 0.20283041894435883]\n",
            "[Iteration: 2843] [Loss: 0.2041929066181183]\n",
            "[Iteration: 2844] [Loss: 0.22757898271083832]\n",
            "[Iteration: 2845] [Loss: 0.20735937356948853]\n",
            "[Iteration: 2846] [Loss: 0.2195296287536621]\n",
            "[Iteration: 2847] [Loss: 0.20962947607040405]\n",
            "[Iteration: 2848] [Loss: 0.23344649374485016]\n",
            "[Iteration: 2849] [Loss: 0.26233822107315063]\n",
            "[Iteration: 2850] [Loss: 0.22795017063617706]\n",
            "[Iteration: 2851] [Loss: 0.19824247062206268]\n",
            "[Iteration: 2852] [Loss: 0.2204451560974121]\n",
            "[Iteration: 2853] [Loss: 0.22204801440238953]\n",
            "[Iteration: 2854] [Loss: 0.20240511000156403]\n",
            "[Iteration: 2855] [Loss: 0.2261815071105957]\n",
            "[Iteration: 2856] [Loss: 0.23470711708068848]\n",
            "[Iteration: 2857] [Loss: 0.19952549040317535]\n",
            "[Iteration: 2858] [Loss: 0.20103685557842255]\n",
            "[Iteration: 2859] [Loss: 0.2111402004957199]\n",
            "[Iteration: 2860] [Loss: 0.2348518967628479]\n",
            "[Iteration: 2861] [Loss: 0.20054343342781067]\n",
            "[Iteration: 2862] [Loss: 0.23870941996574402]\n",
            "[Iteration: 2863] [Loss: 0.20771124958992004]\n",
            "[Iteration: 2864] [Loss: 0.19961488246917725]\n",
            "[Iteration: 2865] [Loss: 0.21864643692970276]\n",
            "[Iteration: 2866] [Loss: 0.24800477921962738]\n",
            "[Iteration: 2867] [Loss: 0.23305323719978333]\n",
            "[Iteration: 2868] [Loss: 0.2234838753938675]\n",
            "[Iteration: 2869] [Loss: 0.19903971254825592]\n",
            "[Iteration: 2870] [Loss: 0.2149476706981659]\n",
            "[Iteration: 2871] [Loss: 0.2123517394065857]\n",
            "[Iteration: 2872] [Loss: 0.2224155217409134]\n",
            "[Iteration: 2873] [Loss: 0.2160516232252121]\n",
            "[Iteration: 2874] [Loss: 0.2148493528366089]\n",
            "[Iteration: 2875] [Loss: 0.23523099720478058]\n",
            "[Iteration: 2876] [Loss: 0.22945883870124817]\n",
            "[Iteration: 2877] [Loss: 0.1938294619321823]\n",
            "[Iteration: 2878] [Loss: 0.23884674906730652]\n",
            "[Iteration: 2879] [Loss: 0.22633811831474304]\n",
            "[Iteration: 2880] [Loss: 0.19816814363002777]\n",
            "[Iteration: 2881] [Loss: 0.2162780463695526]\n",
            "[Iteration: 2882] [Loss: 0.193997323513031]\n",
            "[Iteration: 2883] [Loss: 0.19697286188602448]\n",
            "[Iteration: 2884] [Loss: 0.23508350551128387]\n",
            "[Iteration: 2885] [Loss: 0.22185325622558594]\n",
            "[Iteration: 2886] [Loss: 0.21927660703659058]\n",
            "[Iteration: 2887] [Loss: 0.20907078683376312]\n",
            "[Iteration: 2888] [Loss: 0.19043639302253723]\n",
            "[Iteration: 2889] [Loss: 0.19959601759910583]\n",
            "[Iteration: 2890] [Loss: 0.19959673285484314]\n",
            "[Iteration: 2891] [Loss: 0.21690958738327026]\n",
            "[Iteration: 2892] [Loss: 0.1981382817029953]\n",
            "[Iteration: 2893] [Loss: 0.2075330764055252]\n",
            "[Iteration: 2894] [Loss: 0.22439582645893097]\n",
            "[Iteration: 2895] [Loss: 0.2162657082080841]\n",
            "[Iteration: 2896] [Loss: 0.20243796706199646]\n",
            "[Iteration: 2897] [Loss: 0.2373029887676239]\n",
            "[Iteration: 2898] [Loss: 0.2066531479358673]\n",
            "[Iteration: 2899] [Loss: 0.23852787911891937]\n",
            "[Iteration: 2900] [Loss: 0.23163968324661255]\n",
            "[Iteration: 2901] [Loss: 0.22194916009902954]\n",
            "[Iteration: 2902] [Loss: 0.21024172008037567]\n",
            "[Iteration: 2903] [Loss: 0.21705995500087738]\n",
            "[Iteration: 2904] [Loss: 0.1891859620809555]\n",
            "[Iteration: 2905] [Loss: 0.17880254983901978]\n",
            "[Iteration: 2906] [Loss: 0.20100852847099304]\n",
            "[Iteration: 2907] [Loss: 0.24233682453632355]\n",
            "[Iteration: 2908] [Loss: 0.2152230143547058]\n",
            "[Iteration: 2909] [Loss: 0.2117973119020462]\n",
            "[Iteration: 2910] [Loss: 0.21865323185920715]\n",
            "[Iteration: 2911] [Loss: 0.19969111680984497]\n",
            "[Iteration: 2912] [Loss: 0.19950169324874878]\n",
            "[Iteration: 2913] [Loss: 0.22717812657356262]\n",
            "[Iteration: 2914] [Loss: 0.2177586406469345]\n",
            "[Iteration: 2915] [Loss: 0.25568926334381104]\n",
            "[Iteration: 2916] [Loss: 0.21954084932804108]\n",
            "[Iteration: 2917] [Loss: 0.1969403624534607]\n",
            "[Iteration: 2918] [Loss: 0.2325579822063446]\n",
            "[Iteration: 2919] [Loss: 0.2021523118019104]\n",
            "[Iteration: 2920] [Loss: 0.19337953627109528]\n",
            "[Iteration: 2921] [Loss: 0.20514948666095734]\n",
            "[Iteration: 2922] [Loss: 0.20363783836364746]\n",
            "[Iteration: 2923] [Loss: 0.2250807285308838]\n",
            "[Iteration: 2924] [Loss: 0.21018297970294952]\n",
            "[Iteration: 2925] [Loss: 0.22862757742404938]\n",
            "[Iteration: 2926] [Loss: 0.20680133998394012]\n",
            "[Iteration: 2927] [Loss: 0.2183007001876831]\n",
            "[Iteration: 2928] [Loss: 0.19336508214473724]\n",
            "[Iteration: 2929] [Loss: 0.22987787425518036]\n",
            "[Iteration: 2930] [Loss: 0.19842250645160675]\n",
            "[Iteration: 2931] [Loss: 0.21486623585224152]\n",
            "[Iteration: 2932] [Loss: 0.22715415060520172]\n",
            "[Iteration: 2933] [Loss: 0.19509387016296387]\n",
            "[Iteration: 2934] [Loss: 0.20477324724197388]\n",
            "[Iteration: 2935] [Loss: 0.20492824912071228]\n",
            "[Iteration: 2936] [Loss: 0.20290087163448334]\n",
            "[Iteration: 2937] [Loss: 0.21695971488952637]\n",
            "[Iteration: 2938] [Loss: 0.21112708747386932]\n",
            "[Iteration: 2939] [Loss: 0.22311732172966003]\n",
            "[Iteration: 2940] [Loss: 0.20903128385543823]\n",
            "[Iteration: 2941] [Loss: 0.22722114622592926]\n",
            "[Iteration: 2942] [Loss: 0.2154860645532608]\n",
            "[Iteration: 2943] [Loss: 0.21683643758296967]\n",
            "[Iteration: 2944] [Loss: 0.25230517983436584]\n",
            "[Iteration: 2945] [Loss: 0.1945686787366867]\n",
            "[Iteration: 2946] [Loss: 0.20139563083648682]\n",
            "[Iteration: 2947] [Loss: 0.2165963351726532]\n",
            "[Iteration: 2948] [Loss: 0.21480034291744232]\n",
            "[Iteration: 2949] [Loss: 0.21274733543395996]\n",
            "[Iteration: 2950] [Loss: 0.21656739711761475]\n",
            "[Iteration: 2951] [Loss: 0.22387954592704773]\n",
            "[Iteration: 2952] [Loss: 0.22494298219680786]\n",
            "[Iteration: 2953] [Loss: 0.19741074740886688]\n",
            "[Iteration: 2954] [Loss: 0.2221481204032898]\n",
            "[Iteration: 2955] [Loss: 0.2012566775083542]\n",
            "[Iteration: 2956] [Loss: 0.2086927741765976]\n",
            "[Iteration: 2957] [Loss: 0.20485351979732513]\n",
            "[Iteration: 2958] [Loss: 0.24915355443954468]\n",
            "[Iteration: 2959] [Loss: 0.20612826943397522]\n",
            "[Iteration: 2960] [Loss: 0.2389153093099594]\n",
            "[Iteration: 2961] [Loss: 0.18842367827892303]\n",
            "[Iteration: 2962] [Loss: 0.21472275257110596]\n",
            "[Iteration: 2963] [Loss: 0.20824019610881805]\n",
            "[Iteration: 2964] [Loss: 0.19951201975345612]\n",
            "[Iteration: 2965] [Loss: 0.19974170625209808]\n",
            "[Iteration: 2966] [Loss: 0.2035662680864334]\n",
            "[Iteration: 2967] [Loss: 0.2023615688085556]\n",
            "[Iteration: 2968] [Loss: 0.18452343344688416]\n",
            "[Iteration: 2969] [Loss: 0.22800476849079132]\n",
            "[Iteration: 2970] [Loss: 0.20401008427143097]\n",
            "[Iteration: 2971] [Loss: 0.2585718035697937]\n",
            "[Iteration: 2972] [Loss: 0.23764711618423462]\n",
            "[Iteration: 2973] [Loss: 0.20461003482341766]\n",
            "[Iteration: 2974] [Loss: 0.197010800242424]\n",
            "[Iteration: 2975] [Loss: 0.2021542191505432]\n",
            "[Iteration: 2976] [Loss: 0.20562709867954254]\n",
            "[Iteration: 2977] [Loss: 0.22612881660461426]\n",
            "[Iteration: 2978] [Loss: 0.1982821673154831]\n",
            "[Iteration: 2979] [Loss: 0.20016558468341827]\n",
            "[Iteration: 2980] [Loss: 0.21047283709049225]\n",
            "[Iteration: 2981] [Loss: 0.19048163294792175]\n",
            "[Iteration: 2982] [Loss: 0.24461661279201508]\n",
            "[Iteration: 2983] [Loss: 0.22025375068187714]\n",
            "[Iteration: 2984] [Loss: 0.2158847451210022]\n",
            "[Iteration: 2985] [Loss: 0.20377647876739502]\n",
            "[Iteration: 2986] [Loss: 0.18489719927310944]\n",
            "[Iteration: 2987] [Loss: 0.1964663714170456]\n",
            "[Iteration: 2988] [Loss: 0.2019353210926056]\n",
            "[Iteration: 2989] [Loss: 0.21021388471126556]\n",
            "[Iteration: 2990] [Loss: 0.20842157304286957]\n",
            "[Iteration: 2991] [Loss: 0.2095176726579666]\n",
            "[Iteration: 2992] [Loss: 0.22744958102703094]\n",
            "[Iteration: 2993] [Loss: 0.21762213110923767]\n",
            "[Iteration: 2994] [Loss: 0.2071036398410797]\n",
            "[Iteration: 2995] [Loss: 0.2419775128364563]\n",
            "[Iteration: 2996] [Loss: 0.22612915933132172]\n",
            "[Iteration: 2997] [Loss: 0.21048730611801147]\n",
            "[Iteration: 2998] [Loss: 0.18377073109149933]\n",
            "[Iteration: 2999] [Loss: 0.2008303701877594]\n",
            "[Iteration: 3000] [Loss: 0.18357768654823303]\n",
            "[Iteration: 3001] [Loss: 0.2213856279850006]\n",
            "[Iteration: 3002] [Loss: 0.20881928503513336]\n",
            "[Iteration: 3003] [Loss: 0.21613508462905884]\n",
            "[Iteration: 3004] [Loss: 0.21832063794136047]\n",
            "[Iteration: 3005] [Loss: 0.19981582462787628]\n",
            "[Iteration: 3006] [Loss: 0.19863298535346985]\n",
            "[Iteration: 3007] [Loss: 0.20489610731601715]\n",
            "[Iteration: 3008] [Loss: 0.22695738077163696]\n",
            "[Iteration: 3009] [Loss: 0.20906062424182892]\n",
            "[Iteration: 3010] [Loss: 0.20198269188404083]\n",
            "[Iteration: 3011] [Loss: 0.2242041975259781]\n",
            "[Iteration: 3012] [Loss: 0.19937579333782196]\n",
            "[Iteration: 3013] [Loss: 0.20345088839530945]\n",
            "[Iteration: 3014] [Loss: 0.23765182495117188]\n",
            "[Iteration: 3015] [Loss: 0.21859757602214813]\n",
            "[Iteration: 3016] [Loss: 0.18043255805969238]\n",
            "[Iteration: 3017] [Loss: 0.18521548807621002]\n",
            "[Iteration: 3018] [Loss: 0.18775056302547455]\n",
            "[Iteration: 3019] [Loss: 0.2113475352525711]\n",
            "[Iteration: 3020] [Loss: 0.21121564507484436]\n",
            "[Iteration: 3021] [Loss: 0.20080143213272095]\n",
            "[Iteration: 3022] [Loss: 0.21322840452194214]\n",
            "[Iteration: 3023] [Loss: 0.21151918172836304]\n",
            "[Iteration: 3024] [Loss: 0.2039605975151062]\n",
            "[Iteration: 3025] [Loss: 0.1892222911119461]\n",
            "[Iteration: 3026] [Loss: 0.22726088762283325]\n",
            "[Iteration: 3027] [Loss: 0.19430728256702423]\n",
            "[Iteration: 3028] [Loss: 0.20649708807468414]\n",
            "[Iteration: 3029] [Loss: 0.19942635297775269]\n",
            "[Iteration: 3030] [Loss: 0.20839981734752655]\n",
            "[Iteration: 3031] [Loss: 0.18546178936958313]\n",
            "[Iteration: 3032] [Loss: 0.19677148759365082]\n",
            "[Iteration: 3033] [Loss: 0.22432510554790497]\n",
            "[Iteration: 3034] [Loss: 0.19430558383464813]\n",
            "[Iteration: 3035] [Loss: 0.20239710807800293]\n",
            "[Iteration: 3036] [Loss: 0.20162467658519745]\n",
            "[Iteration: 3037] [Loss: 0.20423021912574768]\n",
            "[Iteration: 3038] [Loss: 0.21534281969070435]\n",
            "[Iteration: 3039] [Loss: 0.20707477629184723]\n",
            "[Iteration: 3040] [Loss: 0.211912602186203]\n",
            "[Iteration: 3041] [Loss: 0.2128971964120865]\n",
            "[Iteration: 3042] [Loss: 0.20727013051509857]\n",
            "[Iteration: 3043] [Loss: 0.2171141654253006]\n",
            "[Iteration: 3044] [Loss: 0.22818228602409363]\n",
            "[Iteration: 3045] [Loss: 0.19725121557712555]\n",
            "[Iteration: 3046] [Loss: 0.188749760389328]\n",
            "[Iteration: 3047] [Loss: 0.2057090848684311]\n",
            "[Iteration: 3048] [Loss: 0.21469764411449432]\n",
            "[Iteration: 3049] [Loss: 0.17377831041812897]\n",
            "[Iteration: 3050] [Loss: 0.19717401266098022]\n",
            "[Iteration: 3051] [Loss: 0.21993136405944824]\n",
            "[Iteration: 3052] [Loss: 0.23011037707328796]\n",
            "[Iteration: 3053] [Loss: 0.19941343367099762]\n",
            "[Iteration: 3054] [Loss: 0.19682033360004425]\n",
            "[Iteration: 3055] [Loss: 0.17887601256370544]\n",
            "[Iteration: 3056] [Loss: 0.19182045757770538]\n",
            "[Iteration: 3057] [Loss: 0.22136376798152924]\n",
            "[Iteration: 3058] [Loss: 0.21502551436424255]\n",
            "[Iteration: 3059] [Loss: 0.1846437156200409]\n",
            "[Iteration: 3060] [Loss: 0.22645309567451477]\n",
            "[Iteration: 3061] [Loss: 0.21462659537792206]\n",
            "[Iteration: 3062] [Loss: 0.21203765273094177]\n",
            "[Iteration: 3063] [Loss: 0.21066991984844208]\n",
            "[Iteration: 3064] [Loss: 0.19779467582702637]\n",
            "[Iteration: 3065] [Loss: 0.19995087385177612]\n",
            "[Iteration: 3066] [Loss: 0.21517808735370636]\n",
            "[Iteration: 3067] [Loss: 0.20927993953227997]\n",
            "[Iteration: 3068] [Loss: 0.19723442196846008]\n",
            "[Iteration: 3069] [Loss: 0.21665188670158386]\n",
            "[Iteration: 3070] [Loss: 0.21390025317668915]\n",
            "[Iteration: 3071] [Loss: 0.19964343309402466]\n",
            "[Iteration: 3072] [Loss: 0.19104133546352386]\n",
            "[Iteration: 3073] [Loss: 0.19477395713329315]\n",
            "[Iteration: 3074] [Loss: 0.23844408988952637]\n",
            "[Iteration: 3075] [Loss: 0.20307916402816772]\n",
            "[Iteration: 3076] [Loss: 0.21459348499774933]\n",
            "[Iteration: 3077] [Loss: 0.22744756937026978]\n",
            "[Iteration: 3078] [Loss: 0.18604399263858795]\n",
            "[Iteration: 3079] [Loss: 0.17702190577983856]\n",
            "[Iteration: 3080] [Loss: 0.21508964896202087]\n",
            "[Iteration: 3081] [Loss: 0.2048959583044052]\n",
            "[Iteration: 3082] [Loss: 0.2077006697654724]\n",
            "[Iteration: 3083] [Loss: 0.20066624879837036]\n",
            "[Iteration: 3084] [Loss: 0.2065284699201584]\n",
            "[Iteration: 3085] [Loss: 0.20187503099441528]\n",
            "[Iteration: 3086] [Loss: 0.20462407171726227]\n",
            "[Iteration: 3087] [Loss: 0.211838498711586]\n",
            "[Iteration: 3088] [Loss: 0.19120930135250092]\n",
            "[Iteration: 3089] [Loss: 0.1748681217432022]\n",
            "[Iteration: 3090] [Loss: 0.2367369830608368]\n",
            "[Iteration: 3091] [Loss: 0.19328397512435913]\n",
            "[Iteration: 3092] [Loss: 0.1998000591993332]\n",
            "[Iteration: 3093] [Loss: 0.19295503199100494]\n",
            "[Iteration: 3094] [Loss: 0.23871034383773804]\n",
            "[Iteration: 3095] [Loss: 0.1875809282064438]\n",
            "[Iteration: 3096] [Loss: 0.2001372128725052]\n",
            "[Iteration: 3097] [Loss: 0.18580961227416992]\n",
            "[Iteration: 3098] [Loss: 0.20717133581638336]\n",
            "[Iteration: 3099] [Loss: 0.16891363263130188]\n",
            "[Iteration: 3100] [Loss: 0.2160394787788391]\n",
            "[Iteration: 3101] [Loss: 0.19285328686237335]\n",
            "[Iteration: 3102] [Loss: 0.18481332063674927]\n",
            "[Iteration: 3103] [Loss: 0.18914295732975006]\n",
            "[Iteration: 3104] [Loss: 0.19954988360404968]\n",
            "[Iteration: 3105] [Loss: 0.17735132575035095]\n",
            "[Iteration: 3106] [Loss: 0.2180580347776413]\n",
            "[Iteration: 3107] [Loss: 0.20680132508277893]\n",
            "[Iteration: 3108] [Loss: 0.1955731064081192]\n",
            "[Iteration: 3109] [Loss: 0.2066134661436081]\n",
            "[Iteration: 3110] [Loss: 0.20377609133720398]\n",
            "[Iteration: 3111] [Loss: 0.20592467486858368]\n",
            "[Iteration: 3112] [Loss: 0.20941299200057983]\n",
            "[Iteration: 3113] [Loss: 0.19336247444152832]\n",
            "[Iteration: 3114] [Loss: 0.1962786167860031]\n",
            "[Iteration: 3115] [Loss: 0.19453713297843933]\n",
            "[Iteration: 3116] [Loss: 0.21402567625045776]\n",
            "[Iteration: 3117] [Loss: 0.18161341547966003]\n",
            "[Iteration: 3118] [Loss: 0.20021355152130127]\n",
            "[Iteration: 3119] [Loss: 0.19622740149497986]\n",
            "[Iteration: 3120] [Loss: 0.20465177297592163]\n",
            "[Iteration: 3121] [Loss: 0.19477730989456177]\n",
            "[Iteration: 3122] [Loss: 0.20586806535720825]\n",
            "[Iteration: 3123] [Loss: 0.20401060581207275]\n",
            "[Iteration: 3124] [Loss: 0.18233603239059448]\n",
            "[Iteration: 3125] [Loss: 0.2011587768793106]\n",
            "[Iteration: 3126] [Loss: 0.19723919034004211]\n",
            "[Iteration: 3127] [Loss: 0.193372443318367]\n",
            "[Iteration: 3128] [Loss: 0.2133527398109436]\n",
            "[Iteration: 3129] [Loss: 0.1840827614068985]\n",
            "[Iteration: 3130] [Loss: 0.188432976603508]\n",
            "[Iteration: 3131] [Loss: 0.20770815014839172]\n",
            "[Iteration: 3132] [Loss: 0.20404964685440063]\n",
            "[Iteration: 3133] [Loss: 0.23532846570014954]\n",
            "[Iteration: 3134] [Loss: 0.19452302157878876]\n",
            "[Iteration: 3135] [Loss: 0.19678866863250732]\n",
            "[Iteration: 3136] [Loss: 0.187602698802948]\n",
            "[Iteration: 3137] [Loss: 0.2075100690126419]\n",
            "[Iteration: 3138] [Loss: 0.22337855398654938]\n",
            "[Iteration: 3139] [Loss: 0.18620780110359192]\n",
            "[Iteration: 3140] [Loss: 0.181564062833786]\n",
            "[Iteration: 3141] [Loss: 0.20269648730754852]\n",
            "[Iteration: 3142] [Loss: 0.17989188432693481]\n",
            "[Iteration: 3143] [Loss: 0.18890374898910522]\n",
            "[Iteration: 3144] [Loss: 0.1862177699804306]\n",
            "[Iteration: 3145] [Loss: 0.2411433607339859]\n",
            "[Iteration: 3146] [Loss: 0.21717119216918945]\n",
            "[Iteration: 3147] [Loss: 0.20148855447769165]\n",
            "[Iteration: 3148] [Loss: 0.1942518800497055]\n",
            "[Iteration: 3149] [Loss: 0.18883125483989716]\n",
            "[Iteration: 3150] [Loss: 0.21316605806350708]\n",
            "[Iteration: 3151] [Loss: 0.2180200219154358]\n",
            "[Iteration: 3152] [Loss: 0.23119817674160004]\n",
            "[Iteration: 3153] [Loss: 0.23105184733867645]\n",
            "[Iteration: 3154] [Loss: 0.22418124973773956]\n",
            "[Iteration: 3155] [Loss: 0.20967960357666016]\n",
            "[Iteration: 3156] [Loss: 0.22650639712810516]\n",
            "[Iteration: 3157] [Loss: 0.21682457625865936]\n",
            "[Iteration: 3158] [Loss: 0.18185551464557648]\n",
            "[Iteration: 3159] [Loss: 0.17674483358860016]\n",
            "[Iteration: 3160] [Loss: 0.1872788816690445]\n",
            "[Iteration: 3161] [Loss: 0.21629180014133453]\n",
            "[Iteration: 3162] [Loss: 0.2042841911315918]\n",
            "[Iteration: 3163] [Loss: 0.18151238560676575]\n",
            "[Iteration: 3164] [Loss: 0.20968015491962433]\n",
            "[Iteration: 3165] [Loss: 0.2129163146018982]\n",
            "[Iteration: 3166] [Loss: 0.20166434347629547]\n",
            "[Iteration: 3167] [Loss: 0.2096875011920929]\n",
            "[Iteration: 3168] [Loss: 0.19797296822071075]\n",
            "[Iteration: 3169] [Loss: 0.22959266602993011]\n",
            "[Iteration: 3170] [Loss: 0.1990496963262558]\n",
            "[Iteration: 3171] [Loss: 0.1896926462650299]\n",
            "[Iteration: 3172] [Loss: 0.21483589708805084]\n",
            "[Iteration: 3173] [Loss: 0.20776134729385376]\n",
            "[Iteration: 3174] [Loss: 0.18582254648208618]\n",
            "[Iteration: 3175] [Loss: 0.17977577447891235]\n",
            "[Iteration: 3176] [Loss: 0.21122387051582336]\n",
            "[Iteration: 3177] [Loss: 0.1874699592590332]\n",
            "[Iteration: 3178] [Loss: 0.19406019151210785]\n",
            "[Iteration: 3179] [Loss: 0.18655754625797272]\n",
            "[Iteration: 3180] [Loss: 0.21661676466464996]\n",
            "[Iteration: 3181] [Loss: 0.18757423758506775]\n",
            "[Iteration: 3182] [Loss: 0.2054237723350525]\n",
            "[Iteration: 3183] [Loss: 0.20885898172855377]\n",
            "[Iteration: 3184] [Loss: 0.18014465272426605]\n",
            "[Iteration: 3185] [Loss: 0.21912024915218353]\n",
            "[Iteration: 3186] [Loss: 0.19879935681819916]\n",
            "[Iteration: 3187] [Loss: 0.20211100578308105]\n",
            "[Iteration: 3188] [Loss: 0.22224566340446472]\n",
            "[Iteration: 3189] [Loss: 0.22489306330680847]\n",
            "[Iteration: 3190] [Loss: 0.19603373110294342]\n",
            "[Iteration: 3191] [Loss: 0.2332300841808319]\n",
            "[Iteration: 3192] [Loss: 0.21541212499141693]\n",
            "[Iteration: 3193] [Loss: 0.2048577070236206]\n",
            "[Iteration: 3194] [Loss: 0.1859881430864334]\n",
            "[Iteration: 3195] [Loss: 0.20765113830566406]\n",
            "[Iteration: 3196] [Loss: 0.20207341015338898]\n",
            "[Iteration: 3197] [Loss: 0.190943643450737]\n",
            "[Iteration: 3198] [Loss: 0.19975198805332184]\n",
            "[Iteration: 3199] [Loss: 0.21111664175987244]\n",
            "[Iteration: 3200] [Loss: 0.19723160564899445]\n",
            "[Iteration: 3201] [Loss: 0.182138592004776]\n",
            "[Iteration: 3202] [Loss: 0.20691806077957153]\n",
            "[Iteration: 3203] [Loss: 0.18471579253673553]\n",
            "[Iteration: 3204] [Loss: 0.21231374144554138]\n",
            "[Iteration: 3205] [Loss: 0.2127687931060791]\n",
            "[Iteration: 3206] [Loss: 0.22303830087184906]\n",
            "[Iteration: 3207] [Loss: 0.2059224545955658]\n",
            "[Iteration: 3208] [Loss: 0.19033700227737427]\n",
            "[Iteration: 3209] [Loss: 0.18736013770103455]\n",
            "[Iteration: 3210] [Loss: 0.2115427851676941]\n",
            "[Iteration: 3211] [Loss: 0.1659868210554123]\n",
            "[Iteration: 3212] [Loss: 0.20743019878864288]\n",
            "[Iteration: 3213] [Loss: 0.2371094524860382]\n",
            "[Iteration: 3214] [Loss: 0.18491309881210327]\n",
            "[Iteration: 3215] [Loss: 0.22722524404525757]\n",
            "[Iteration: 3216] [Loss: 0.1993139237165451]\n",
            "[Iteration: 3217] [Loss: 0.1879783421754837]\n",
            "[Iteration: 3218] [Loss: 0.17150568962097168]\n",
            "[Iteration: 3219] [Loss: 0.19431598484516144]\n",
            "[Iteration: 3220] [Loss: 0.22455856204032898]\n",
            "[Iteration: 3221] [Loss: 0.22763842344284058]\n",
            "[Iteration: 3222] [Loss: 0.21073321998119354]\n",
            "[Iteration: 3223] [Loss: 0.21313755214214325]\n",
            "[Iteration: 3224] [Loss: 0.2040514051914215]\n",
            "[Iteration: 3225] [Loss: 0.21734124422073364]\n",
            "[Iteration: 3226] [Loss: 0.20127429068088531]\n",
            "[Iteration: 3227] [Loss: 0.18349212408065796]\n",
            "[Iteration: 3228] [Loss: 0.17978054285049438]\n",
            "[Iteration: 3229] [Loss: 0.17874732613563538]\n",
            "[Iteration: 3230] [Loss: 0.19152389466762543]\n",
            "[Iteration: 3231] [Loss: 0.2191331684589386]\n",
            "[Iteration: 3232] [Loss: 0.16539479792118073]\n",
            "[Iteration: 3233] [Loss: 0.17121213674545288]\n",
            "[Iteration: 3234] [Loss: 0.22250954806804657]\n",
            "[Iteration: 3235] [Loss: 0.17412999272346497]\n",
            "[Iteration: 3236] [Loss: 0.17481689155101776]\n",
            "[Iteration: 3237] [Loss: 0.20395582914352417]\n",
            "[Iteration: 3238] [Loss: 0.21762622892856598]\n",
            "[Iteration: 3239] [Loss: 0.18186695873737335]\n",
            "[Iteration: 3240] [Loss: 0.1841341108083725]\n",
            "[Iteration: 3241] [Loss: 0.17893871665000916]\n",
            "[Iteration: 3242] [Loss: 0.18996275961399078]\n",
            "[Iteration: 3243] [Loss: 0.20748299360275269]\n",
            "[Iteration: 3244] [Loss: 0.18879245221614838]\n",
            "[Iteration: 3245] [Loss: 0.19363653659820557]\n",
            "[Iteration: 3246] [Loss: 0.20585785806179047]\n",
            "[Iteration: 3247] [Loss: 0.2189437747001648]\n",
            "[Iteration: 3248] [Loss: 0.20419256389141083]\n",
            "[Iteration: 3249] [Loss: 0.1954878270626068]\n",
            "[Iteration: 3250] [Loss: 0.21934066712856293]\n",
            "[Iteration: 3251] [Loss: 0.19458307325839996]\n",
            "[Iteration: 3252] [Loss: 0.19353455305099487]\n",
            "[Iteration: 3253] [Loss: 0.2035859227180481]\n",
            "[Iteration: 3254] [Loss: 0.219869002699852]\n",
            "[Iteration: 3255] [Loss: 0.18539534509181976]\n",
            "[Iteration: 3256] [Loss: 0.17373651266098022]\n",
            "[Iteration: 3257] [Loss: 0.18036945164203644]\n",
            "[Iteration: 3258] [Loss: 0.2045125663280487]\n",
            "[Iteration: 3259] [Loss: 0.21579675376415253]\n",
            "[Iteration: 3260] [Loss: 0.18653631210327148]\n",
            "[Iteration: 3261] [Loss: 0.2044055014848709]\n",
            "[Iteration: 3262] [Loss: 0.21314257383346558]\n",
            "[Iteration: 3263] [Loss: 0.2044132798910141]\n",
            "[Iteration: 3264] [Loss: 0.19420190155506134]\n",
            "[Iteration: 3265] [Loss: 0.21263092756271362]\n",
            "[Iteration: 3266] [Loss: 0.19628915190696716]\n",
            "[Iteration: 3267] [Loss: 0.22834444046020508]\n",
            "[Iteration: 3268] [Loss: 0.21044346690177917]\n",
            "[Iteration: 3269] [Loss: 0.18763917684555054]\n",
            "[Iteration: 3270] [Loss: 0.20868165791034698]\n",
            "[Iteration: 3271] [Loss: 0.20241126418113708]\n",
            "[Iteration: 3272] [Loss: 0.19275741279125214]\n",
            "[Iteration: 3273] [Loss: 0.20978598296642303]\n",
            "[Iteration: 3274] [Loss: 0.19660528004169464]\n",
            "[Iteration: 3275] [Loss: 0.20181146264076233]\n",
            "[Iteration: 3276] [Loss: 0.17231613397598267]\n",
            "[Iteration: 3277] [Loss: 0.17366011440753937]\n",
            "[Iteration: 3278] [Loss: 0.2108735740184784]\n",
            "[Iteration: 3279] [Loss: 0.20892007648944855]\n",
            "[Iteration: 3280] [Loss: 0.19933338463306427]\n",
            "[Iteration: 3281] [Loss: 0.17376331984996796]\n",
            "[Iteration: 3282] [Loss: 0.1854758858680725]\n",
            "[Iteration: 3283] [Loss: 0.21958093345165253]\n",
            "[Iteration: 3284] [Loss: 0.19805540144443512]\n",
            "[Iteration: 3285] [Loss: 0.21030600368976593]\n",
            "[Iteration: 3286] [Loss: 0.19018380343914032]\n",
            "[Iteration: 3287] [Loss: 0.20122544467449188]\n",
            "[Iteration: 3288] [Loss: 0.19972708821296692]\n",
            "[Iteration: 3289] [Loss: 0.17857378721237183]\n",
            "[Iteration: 3290] [Loss: 0.20065344870090485]\n",
            "[Iteration: 3291] [Loss: 0.1743697077035904]\n",
            "[Iteration: 3292] [Loss: 0.20056888461112976]\n",
            "[Iteration: 3293] [Loss: 0.19775912165641785]\n",
            "[Iteration: 3294] [Loss: 0.17702269554138184]\n",
            "[Iteration: 3295] [Loss: 0.1655309796333313]\n",
            "[Iteration: 3296] [Loss: 0.2015421986579895]\n",
            "[Iteration: 3297] [Loss: 0.16988614201545715]\n",
            "[Iteration: 3298] [Loss: 0.19239242374897003]\n",
            "[Iteration: 3299] [Loss: 0.20177340507507324]\n",
            "[Iteration: 3300] [Loss: 0.17567415535449982]\n",
            "[Iteration: 3301] [Loss: 0.2016451358795166]\n",
            "[Iteration: 3302] [Loss: 0.19441451132297516]\n",
            "[Iteration: 3303] [Loss: 0.20719508826732635]\n",
            "[Iteration: 3304] [Loss: 0.20703314244747162]\n",
            "[Iteration: 3305] [Loss: 0.19792991876602173]\n",
            "[Iteration: 3306] [Loss: 0.20379364490509033]\n",
            "[Iteration: 3307] [Loss: 0.1750534176826477]\n",
            "[Iteration: 3308] [Loss: 0.18158932030200958]\n",
            "[Iteration: 3309] [Loss: 0.17712682485580444]\n",
            "[Iteration: 3310] [Loss: 0.17671658098697662]\n",
            "[Iteration: 3311] [Loss: 0.20515374839305878]\n",
            "[Iteration: 3312] [Loss: 0.19885772466659546]\n",
            "[Iteration: 3313] [Loss: 0.2068053036928177]\n",
            "[Iteration: 3314] [Loss: 0.21018099784851074]\n",
            "[Iteration: 3315] [Loss: 0.18243379890918732]\n",
            "[Iteration: 3316] [Loss: 0.19013305008411407]\n",
            "[Iteration: 3317] [Loss: 0.18890923261642456]\n",
            "[Iteration: 3318] [Loss: 0.18700070679187775]\n",
            "[Iteration: 3319] [Loss: 0.20427803695201874]\n",
            "[Iteration: 3320] [Loss: 0.1726931929588318]\n",
            "[Iteration: 3321] [Loss: 0.17637625336647034]\n",
            "[Iteration: 3322] [Loss: 0.1965099275112152]\n",
            "[Iteration: 3323] [Loss: 0.20181795954704285]\n",
            "[Iteration: 3324] [Loss: 0.1869307905435562]\n",
            "[Iteration: 3325] [Loss: 0.19127511978149414]\n",
            "[Iteration: 3326] [Loss: 0.20862992107868195]\n",
            "[Iteration: 3327] [Loss: 0.23603445291519165]\n",
            "[Iteration: 3328] [Loss: 0.19759005308151245]\n",
            "[Iteration: 3329] [Loss: 0.21219402551651]\n",
            "[Iteration: 3330] [Loss: 0.19991852343082428]\n",
            "[Iteration: 3331] [Loss: 0.20704665780067444]\n",
            "[Iteration: 3332] [Loss: 0.19008007645606995]\n",
            "[Iteration: 3333] [Loss: 0.2051377296447754]\n",
            "[Iteration: 3334] [Loss: 0.20568297803401947]\n",
            "[Iteration: 3335] [Loss: 0.19959071278572083]\n",
            "[Iteration: 3336] [Loss: 0.21076525747776031]\n",
            "[Iteration: 3337] [Loss: 0.2089858502149582]\n",
            "[Iteration: 3338] [Loss: 0.17411018908023834]\n",
            "[Iteration: 3339] [Loss: 0.18561138212680817]\n",
            "[Iteration: 3340] [Loss: 0.1727340668439865]\n",
            "[Iteration: 3341] [Loss: 0.18998929858207703]\n",
            "[Iteration: 3342] [Loss: 0.22806212306022644]\n",
            "[Iteration: 3343] [Loss: 0.21342907845973969]\n",
            "[Iteration: 3344] [Loss: 0.20611952245235443]\n",
            "[Iteration: 3345] [Loss: 0.20615772902965546]\n",
            "[Iteration: 3346] [Loss: 0.19500936567783356]\n",
            "[Iteration: 3347] [Loss: 0.19106775522232056]\n",
            "[Iteration: 3348] [Loss: 0.17886430025100708]\n",
            "[Iteration: 3349] [Loss: 0.19952650368213654]\n",
            "[Iteration: 3350] [Loss: 0.1600368469953537]\n",
            "[Iteration: 3351] [Loss: 0.18677927553653717]\n",
            "[Iteration: 3352] [Loss: 0.15931445360183716]\n",
            "[Iteration: 3353] [Loss: 0.21056976914405823]\n",
            "[Iteration: 3354] [Loss: 0.17318910360336304]\n",
            "[Iteration: 3355] [Loss: 0.21029886603355408]\n",
            "[Iteration: 3356] [Loss: 0.205089271068573]\n",
            "[Iteration: 3357] [Loss: 0.17192202806472778]\n",
            "[Iteration: 3358] [Loss: 0.16454575955867767]\n",
            "[Iteration: 3359] [Loss: 0.21046863496303558]\n",
            "[Iteration: 3360] [Loss: 0.18507714569568634]\n",
            "[Iteration: 3361] [Loss: 0.1850002110004425]\n",
            "[Iteration: 3362] [Loss: 0.19867625832557678]\n",
            "[Iteration: 3363] [Loss: 0.22291411459445953]\n",
            "[Iteration: 3364] [Loss: 0.19519029557704926]\n",
            "[Iteration: 3365] [Loss: 0.18550515174865723]\n",
            "[Iteration: 3366] [Loss: 0.18850231170654297]\n",
            "[Iteration: 3367] [Loss: 0.17394708096981049]\n",
            "[Iteration: 3368] [Loss: 0.19653159379959106]\n",
            "[Iteration: 3369] [Loss: 0.18947169184684753]\n",
            "[Iteration: 3370] [Loss: 0.18316273391246796]\n",
            "[Iteration: 3371] [Loss: 0.201456218957901]\n",
            "[Iteration: 3372] [Loss: 0.17760297656059265]\n",
            "[Iteration: 3373] [Loss: 0.19617117941379547]\n",
            "[Iteration: 3374] [Loss: 0.20399516820907593]\n",
            "[Iteration: 3375] [Loss: 0.19304201006889343]\n",
            "[Iteration: 3376] [Loss: 0.2067786008119583]\n",
            "[Iteration: 3377] [Loss: 0.1763932704925537]\n",
            "[Iteration: 3378] [Loss: 0.18722866475582123]\n",
            "[Iteration: 3379] [Loss: 0.21043258905410767]\n",
            "[Iteration: 3380] [Loss: 0.18779921531677246]\n",
            "[Iteration: 3381] [Loss: 0.19787472486495972]\n",
            "[Iteration: 3382] [Loss: 0.18165254592895508]\n",
            "[Iteration: 3383] [Loss: 0.18289746344089508]\n",
            "[Iteration: 3384] [Loss: 0.15845106542110443]\n",
            "[Iteration: 3385] [Loss: 0.1900539994239807]\n",
            "[Iteration: 3386] [Loss: 0.18228864669799805]\n",
            "[Iteration: 3387] [Loss: 0.20049618184566498]\n",
            "[Iteration: 3388] [Loss: 0.17382578551769257]\n",
            "[Iteration: 3389] [Loss: 0.1933189034461975]\n",
            "[Iteration: 3390] [Loss: 0.1990019679069519]\n",
            "[Iteration: 3391] [Loss: 0.1803978830575943]\n",
            "[Iteration: 3392] [Loss: 0.19845694303512573]\n",
            "[Iteration: 3393] [Loss: 0.2101116180419922]\n",
            "[Iteration: 3394] [Loss: 0.17996326088905334]\n",
            "[Iteration: 3395] [Loss: 0.20511361956596375]\n",
            "[Iteration: 3396] [Loss: 0.1940910518169403]\n",
            "[Iteration: 3397] [Loss: 0.20424135029315948]\n",
            "[Iteration: 3398] [Loss: 0.1999385952949524]\n",
            "[Iteration: 3399] [Loss: 0.18331009149551392]\n",
            "[Iteration: 3400] [Loss: 0.2175508588552475]\n",
            "[Iteration: 3401] [Loss: 0.15889114141464233]\n",
            "[Iteration: 3402] [Loss: 0.19132131338119507]\n",
            "[Iteration: 3403] [Loss: 0.192732036113739]\n",
            "[Iteration: 3404] [Loss: 0.1897699236869812]\n",
            "[Iteration: 3405] [Loss: 0.1907503306865692]\n",
            "[Iteration: 3406] [Loss: 0.1806456595659256]\n",
            "[Iteration: 3407] [Loss: 0.19706927239894867]\n",
            "[Iteration: 3408] [Loss: 0.1737799495458603]\n",
            "[Iteration: 3409] [Loss: 0.17233191430568695]\n",
            "[Iteration: 3410] [Loss: 0.19993166625499725]\n",
            "[Iteration: 3411] [Loss: 0.19693681597709656]\n",
            "[Iteration: 3412] [Loss: 0.17561382055282593]\n",
            "[Iteration: 3413] [Loss: 0.17469197511672974]\n",
            "[Iteration: 3414] [Loss: 0.18052755296230316]\n",
            "[Iteration: 3415] [Loss: 0.19048558175563812]\n",
            "[Iteration: 3416] [Loss: 0.18053677678108215]\n",
            "[Iteration: 3417] [Loss: 0.1931251436471939]\n",
            "[Iteration: 3418] [Loss: 0.1741013526916504]\n",
            "[Iteration: 3419] [Loss: 0.20364147424697876]\n",
            "[Iteration: 3420] [Loss: 0.20115703344345093]\n",
            "[Iteration: 3421] [Loss: 0.1700429469347]\n",
            "[Iteration: 3422] [Loss: 0.21921314299106598]\n",
            "[Iteration: 3423] [Loss: 0.20042580366134644]\n",
            "[Iteration: 3424] [Loss: 0.1812722533941269]\n",
            "[Iteration: 3425] [Loss: 0.18429015576839447]\n",
            "[Iteration: 3426] [Loss: 0.1840524524450302]\n",
            "[Iteration: 3427] [Loss: 0.19078688323497772]\n",
            "[Iteration: 3428] [Loss: 0.21132086217403412]\n",
            "[Iteration: 3429] [Loss: 0.23210223019123077]\n",
            "[Iteration: 3430] [Loss: 0.19886595010757446]\n",
            "[Iteration: 3431] [Loss: 0.18112808465957642]\n",
            "[Iteration: 3432] [Loss: 0.19749295711517334]\n",
            "[Iteration: 3433] [Loss: 0.2059786021709442]\n",
            "[Iteration: 3434] [Loss: 0.1949623078107834]\n",
            "[Iteration: 3435] [Loss: 0.19187848269939423]\n",
            "[Iteration: 3436] [Loss: 0.19843727350234985]\n",
            "[Iteration: 3437] [Loss: 0.18404388427734375]\n",
            "[Iteration: 3438] [Loss: 0.21178697049617767]\n",
            "[Iteration: 3439] [Loss: 0.1861828714609146]\n",
            "[Iteration: 3440] [Loss: 0.20328210294246674]\n",
            "[Iteration: 3441] [Loss: 0.16658741235733032]\n",
            "[Iteration: 3442] [Loss: 0.1764228343963623]\n",
            "[Iteration: 3443] [Loss: 0.18309740722179413]\n",
            "[Iteration: 3444] [Loss: 0.18466919660568237]\n",
            "[Iteration: 3445] [Loss: 0.18952447175979614]\n",
            "[Iteration: 3446] [Loss: 0.19013848900794983]\n",
            "[Iteration: 3447] [Loss: 0.18553464114665985]\n",
            "[Iteration: 3448] [Loss: 0.19244252145290375]\n",
            "[Iteration: 3449] [Loss: 0.1978892832994461]\n",
            "[Iteration: 3450] [Loss: 0.22015444934368134]\n",
            "[Iteration: 3451] [Loss: 0.1785275787115097]\n",
            "[Iteration: 3452] [Loss: 0.2022879719734192]\n",
            "[Iteration: 3453] [Loss: 0.1825316846370697]\n",
            "[Iteration: 3454] [Loss: 0.1724141389131546]\n",
            "[Iteration: 3455] [Loss: 0.18865787982940674]\n",
            "[Iteration: 3456] [Loss: 0.2028752565383911]\n",
            "[Iteration: 3457] [Loss: 0.19129475951194763]\n",
            "[Iteration: 3458] [Loss: 0.1962573379278183]\n",
            "[Iteration: 3459] [Loss: 0.18885692954063416]\n",
            "[Iteration: 3460] [Loss: 0.1822333037853241]\n",
            "[Iteration: 3461] [Loss: 0.18556056916713715]\n",
            "[Iteration: 3462] [Loss: 0.18990787863731384]\n",
            "[Iteration: 3463] [Loss: 0.16890664398670197]\n",
            "[Iteration: 3464] [Loss: 0.19433201849460602]\n",
            "[Iteration: 3465] [Loss: 0.18333753943443298]\n",
            "[Iteration: 3466] [Loss: 0.1590372622013092]\n",
            "[Iteration: 3467] [Loss: 0.19999228417873383]\n",
            "[Iteration: 3468] [Loss: 0.20797137916088104]\n",
            "[Iteration: 3469] [Loss: 0.20064739882946014]\n",
            "[Iteration: 3470] [Loss: 0.17625828087329865]\n",
            "[Iteration: 3471] [Loss: 0.17226628959178925]\n",
            "[Iteration: 3472] [Loss: 0.16422942280769348]\n",
            "[Iteration: 3473] [Loss: 0.17714516818523407]\n",
            "[Iteration: 3474] [Loss: 0.17300546169281006]\n",
            "[Iteration: 3475] [Loss: 0.19998705387115479]\n",
            "[Iteration: 3476] [Loss: 0.16871604323387146]\n",
            "[Iteration: 3477] [Loss: 0.20048753917217255]\n",
            "[Iteration: 3478] [Loss: 0.20797835290431976]\n",
            "[Iteration: 3479] [Loss: 0.18527162075042725]\n",
            "[Iteration: 3480] [Loss: 0.15799061954021454]\n",
            "[Iteration: 3481] [Loss: 0.17703840136528015]\n",
            "[Iteration: 3482] [Loss: 0.17849469184875488]\n",
            "[Iteration: 3483] [Loss: 0.18479715287685394]\n",
            "[Iteration: 3484] [Loss: 0.17802685499191284]\n",
            "[Iteration: 3485] [Loss: 0.1903068870306015]\n",
            "[Iteration: 3486] [Loss: 0.20976315438747406]\n",
            "[Iteration: 3487] [Loss: 0.18234844505786896]\n",
            "[Iteration: 3488] [Loss: 0.19547340273857117]\n",
            "[Iteration: 3489] [Loss: 0.21278789639472961]\n",
            "[Iteration: 3490] [Loss: 0.18191060423851013]\n",
            "[Iteration: 3491] [Loss: 0.17460788786411285]\n",
            "[Iteration: 3492] [Loss: 0.20433443784713745]\n",
            "[Iteration: 3493] [Loss: 0.17089933156967163]\n",
            "[Iteration: 3494] [Loss: 0.19694317877292633]\n",
            "[Iteration: 3495] [Loss: 0.18948635458946228]\n",
            "[Iteration: 3496] [Loss: 0.22214126586914062]\n",
            "[Iteration: 3497] [Loss: 0.18813782930374146]\n",
            "[Iteration: 3498] [Loss: 0.18522782623767853]\n",
            "[Iteration: 3499] [Loss: 0.2003878653049469]\n",
            "[Iteration: 3500] [Loss: 0.1885175257921219]\n",
            "[Iteration: 3501] [Loss: 0.18631185591220856]\n",
            "[Iteration: 3502] [Loss: 0.2171141803264618]\n",
            "[Iteration: 3503] [Loss: 0.19787760078907013]\n",
            "[Iteration: 3504] [Loss: 0.20550137758255005]\n",
            "[Iteration: 3505] [Loss: 0.16918742656707764]\n",
            "[Iteration: 3506] [Loss: 0.18366755545139313]\n",
            "[Iteration: 3507] [Loss: 0.17640015482902527]\n",
            "[Iteration: 3508] [Loss: 0.19466163218021393]\n",
            "[Iteration: 3509] [Loss: 0.1933097392320633]\n",
            "[Iteration: 3510] [Loss: 0.2022792100906372]\n",
            "[Iteration: 3511] [Loss: 0.17208418250083923]\n",
            "[Iteration: 3512] [Loss: 0.17200584709644318]\n",
            "[Iteration: 3513] [Loss: 0.21345579624176025]\n",
            "[Iteration: 3514] [Loss: 0.17809730768203735]\n",
            "[Iteration: 3515] [Loss: 0.2100744992494583]\n",
            "[Iteration: 3516] [Loss: 0.20426234602928162]\n",
            "[Iteration: 3517] [Loss: 0.17319031059741974]\n",
            "[Iteration: 3518] [Loss: 0.19347381591796875]\n",
            "[Iteration: 3519] [Loss: 0.1811668425798416]\n",
            "[Iteration: 3520] [Loss: 0.18142877519130707]\n",
            "[Iteration: 3521] [Loss: 0.1836061328649521]\n",
            "[Iteration: 3522] [Loss: 0.18154817819595337]\n",
            "[Iteration: 3523] [Loss: 0.1932832896709442]\n",
            "[Iteration: 3524] [Loss: 0.2074141949415207]\n",
            "[Iteration: 3525] [Loss: 0.1836603879928589]\n",
            "[Iteration: 3526] [Loss: 0.18521185219287872]\n",
            "[Iteration: 3527] [Loss: 0.17410655319690704]\n",
            "[Iteration: 3528] [Loss: 0.21916015446186066]\n",
            "[Iteration: 3529] [Loss: 0.18259947001934052]\n",
            "[Iteration: 3530] [Loss: 0.1942858099937439]\n",
            "[Iteration: 3531] [Loss: 0.2121259719133377]\n",
            "[Iteration: 3532] [Loss: 0.1966315060853958]\n",
            "[Iteration: 3533] [Loss: 0.1709161400794983]\n",
            "[Iteration: 3534] [Loss: 0.20061984658241272]\n",
            "[Iteration: 3535] [Loss: 0.1929129958152771]\n",
            "[Iteration: 3536] [Loss: 0.17215295135974884]\n",
            "[Iteration: 3537] [Loss: 0.15855294466018677]\n",
            "[Iteration: 3538] [Loss: 0.18673676252365112]\n",
            "[Iteration: 3539] [Loss: 0.18817001581192017]\n",
            "[Iteration: 3540] [Loss: 0.19827879965305328]\n",
            "[Iteration: 3541] [Loss: 0.18765464425086975]\n",
            "[Iteration: 3542] [Loss: 0.16439087688922882]\n",
            "[Iteration: 3543] [Loss: 0.19780568778514862]\n",
            "[Iteration: 3544] [Loss: 0.19657009840011597]\n",
            "[Iteration: 3545] [Loss: 0.17723281681537628]\n",
            "[Iteration: 3546] [Loss: 0.172824889421463]\n",
            "[Iteration: 3547] [Loss: 0.19780969619750977]\n",
            "[Iteration: 3548] [Loss: 0.17504018545150757]\n",
            "[Iteration: 3549] [Loss: 0.18693262338638306]\n",
            "[Iteration: 3550] [Loss: 0.195552796125412]\n",
            "[Iteration: 3551] [Loss: 0.17044122517108917]\n",
            "[Iteration: 3552] [Loss: 0.18895162642002106]\n",
            "[Iteration: 3553] [Loss: 0.2118556946516037]\n",
            "[Iteration: 3554] [Loss: 0.19160795211791992]\n",
            "[Iteration: 3555] [Loss: 0.15969409048557281]\n",
            "[Iteration: 3556] [Loss: 0.19358587265014648]\n",
            "[Iteration: 3557] [Loss: 0.17407573759555817]\n",
            "[Iteration: 3558] [Loss: 0.16238540410995483]\n",
            "[Iteration: 3559] [Loss: 0.1913129985332489]\n",
            "[Iteration: 3560] [Loss: 0.18802359700202942]\n",
            "[Iteration: 3561] [Loss: 0.1905076801776886]\n",
            "[Iteration: 3562] [Loss: 0.19574949145317078]\n",
            "[Iteration: 3563] [Loss: 0.20047667622566223]\n",
            "[Iteration: 3564] [Loss: 0.1945706307888031]\n",
            "[Iteration: 3565] [Loss: 0.1873491108417511]\n",
            "[Iteration: 3566] [Loss: 0.1850695163011551]\n",
            "[Iteration: 3567] [Loss: 0.1901264786720276]\n",
            "[Iteration: 3568] [Loss: 0.18384188413619995]\n",
            "[Iteration: 3569] [Loss: 0.20466545224189758]\n",
            "[Iteration: 3570] [Loss: 0.20615285634994507]\n",
            "[Iteration: 3571] [Loss: 0.21265973150730133]\n",
            "[Iteration: 3572] [Loss: 0.1790054440498352]\n",
            "[Iteration: 3573] [Loss: 0.18699020147323608]\n",
            "[Iteration: 3574] [Loss: 0.19642318785190582]\n",
            "[Iteration: 3575] [Loss: 0.20595593750476837]\n",
            "[Iteration: 3576] [Loss: 0.185533344745636]\n",
            "[Iteration: 3577] [Loss: 0.19288766384124756]\n",
            "[Iteration: 3578] [Loss: 0.18122221529483795]\n",
            "[Iteration: 3579] [Loss: 0.20290900766849518]\n",
            "[Iteration: 3580] [Loss: 0.18158775568008423]\n",
            "[Iteration: 3581] [Loss: 0.19720758497714996]\n",
            "[Iteration: 3582] [Loss: 0.1701490432024002]\n",
            "[Iteration: 3583] [Loss: 0.18841123580932617]\n",
            "[Iteration: 3584] [Loss: 0.2084587812423706]\n",
            "[Iteration: 3585] [Loss: 0.177320659160614]\n",
            "[Iteration: 3586] [Loss: 0.18621869385242462]\n",
            "[Iteration: 3587] [Loss: 0.15955720841884613]\n",
            "[Iteration: 3588] [Loss: 0.18783284723758698]\n",
            "[Iteration: 3589] [Loss: 0.18107819557189941]\n",
            "[Iteration: 3590] [Loss: 0.19752264022827148]\n",
            "[Iteration: 3591] [Loss: 0.19231706857681274]\n",
            "[Iteration: 3592] [Loss: 0.17579835653305054]\n",
            "[Iteration: 3593] [Loss: 0.1982136368751526]\n",
            "[Iteration: 3594] [Loss: 0.18743109703063965]\n",
            "[Iteration: 3595] [Loss: 0.17870083451271057]\n",
            "[Iteration: 3596] [Loss: 0.20442035794258118]\n",
            "[Iteration: 3597] [Loss: 0.17088764905929565]\n",
            "[Iteration: 3598] [Loss: 0.19032730162143707]\n",
            "[Iteration: 3599] [Loss: 0.16886009275913239]\n",
            "[Iteration: 3600] [Loss: 0.1888204663991928]\n",
            "[Iteration: 3601] [Loss: 0.1800532042980194]\n",
            "[Iteration: 3602] [Loss: 0.17508003115653992]\n",
            "[Iteration: 3603] [Loss: 0.191089928150177]\n",
            "[Iteration: 3604] [Loss: 0.1933797150850296]\n",
            "[Iteration: 3605] [Loss: 0.20240634679794312]\n",
            "[Iteration: 3606] [Loss: 0.1835833191871643]\n",
            "[Iteration: 3607] [Loss: 0.16857710480690002]\n",
            "[Iteration: 3608] [Loss: 0.17171227931976318]\n",
            "[Iteration: 3609] [Loss: 0.15327876806259155]\n",
            "[Iteration: 3610] [Loss: 0.180299773812294]\n",
            "[Iteration: 3611] [Loss: 0.18099334836006165]\n",
            "[Iteration: 3612] [Loss: 0.17606236040592194]\n",
            "[Iteration: 3613] [Loss: 0.1774999350309372]\n",
            "[Iteration: 3614] [Loss: 0.1757180541753769]\n",
            "[Iteration: 3615] [Loss: 0.1754368394613266]\n",
            "[Iteration: 3616] [Loss: 0.18106943368911743]\n",
            "[Iteration: 3617] [Loss: 0.17461691796779633]\n",
            "[Iteration: 3618] [Loss: 0.17636904120445251]\n",
            "[Iteration: 3619] [Loss: 0.1816621720790863]\n",
            "[Iteration: 3620] [Loss: 0.19306853413581848]\n",
            "[Iteration: 3621] [Loss: 0.16253221035003662]\n",
            "[Iteration: 3622] [Loss: 0.17100419104099274]\n",
            "[Iteration: 3623] [Loss: 0.1963699609041214]\n",
            "[Iteration: 3624] [Loss: 0.19914452731609344]\n",
            "[Iteration: 3625] [Loss: 0.19652879238128662]\n",
            "[Iteration: 3626] [Loss: 0.19462791085243225]\n",
            "[Iteration: 3627] [Loss: 0.170795738697052]\n",
            "[Iteration: 3628] [Loss: 0.17768444120883942]\n",
            "[Iteration: 3629] [Loss: 0.17859601974487305]\n",
            "[Iteration: 3630] [Loss: 0.17244327068328857]\n",
            "[Iteration: 3631] [Loss: 0.20450159907341003]\n",
            "[Iteration: 3632] [Loss: 0.15684626996517181]\n",
            "[Iteration: 3633] [Loss: 0.1843453347682953]\n",
            "[Iteration: 3634] [Loss: 0.17927952110767365]\n",
            "[Iteration: 3635] [Loss: 0.18760715425014496]\n",
            "[Iteration: 3636] [Loss: 0.17529019713401794]\n",
            "[Iteration: 3637] [Loss: 0.18592090904712677]\n",
            "[Iteration: 3638] [Loss: 0.20631219446659088]\n",
            "[Iteration: 3639] [Loss: 0.18334539234638214]\n",
            "[Iteration: 3640] [Loss: 0.18772616982460022]\n",
            "[Iteration: 3641] [Loss: 0.1776372641324997]\n",
            "[Iteration: 3642] [Loss: 0.17334522306919098]\n",
            "[Iteration: 3643] [Loss: 0.1469859480857849]\n",
            "[Iteration: 3644] [Loss: 0.18538470566272736]\n",
            "[Iteration: 3645] [Loss: 0.16990476846694946]\n",
            "[Iteration: 3646] [Loss: 0.18864691257476807]\n",
            "[Iteration: 3647] [Loss: 0.1875157654285431]\n",
            "[Iteration: 3648] [Loss: 0.17153137922286987]\n",
            "[Iteration: 3649] [Loss: 0.17987345159053802]\n",
            "[Iteration: 3650] [Loss: 0.16290634870529175]\n",
            "[Iteration: 3651] [Loss: 0.1674754023551941]\n",
            "[Iteration: 3652] [Loss: 0.17736351490020752]\n",
            "[Iteration: 3653] [Loss: 0.1907583326101303]\n",
            "[Iteration: 3654] [Loss: 0.18769891560077667]\n",
            "[Iteration: 3655] [Loss: 0.17707426846027374]\n",
            "[Iteration: 3656] [Loss: 0.1915658861398697]\n",
            "[Iteration: 3657] [Loss: 0.1783662736415863]\n",
            "[Iteration: 3658] [Loss: 0.18377117812633514]\n",
            "[Iteration: 3659] [Loss: 0.1753193736076355]\n",
            "[Iteration: 3660] [Loss: 0.19140580296516418]\n",
            "[Iteration: 3661] [Loss: 0.17646633088588715]\n",
            "[Iteration: 3662] [Loss: 0.1752910166978836]\n",
            "[Iteration: 3663] [Loss: 0.17335474491119385]\n",
            "[Iteration: 3664] [Loss: 0.16507190465927124]\n",
            "[Iteration: 3665] [Loss: 0.18853577971458435]\n",
            "[Iteration: 3666] [Loss: 0.17430327832698822]\n",
            "[Iteration: 3667] [Loss: 0.19693173468112946]\n",
            "[Iteration: 3668] [Loss: 0.16919824481010437]\n",
            "[Iteration: 3669] [Loss: 0.16787225008010864]\n",
            "[Iteration: 3670] [Loss: 0.17734231054782867]\n",
            "[Iteration: 3671] [Loss: 0.17762276530265808]\n",
            "[Iteration: 3672] [Loss: 0.18453989923000336]\n",
            "[Iteration: 3673] [Loss: 0.19042743742465973]\n",
            "[Iteration: 3674] [Loss: 0.16660958528518677]\n",
            "[Iteration: 3675] [Loss: 0.1929856687784195]\n",
            "[Iteration: 3676] [Loss: 0.17861168086528778]\n",
            "[Iteration: 3677] [Loss: 0.17913936078548431]\n",
            "[Iteration: 3678] [Loss: 0.19761225581169128]\n",
            "[Iteration: 3679] [Loss: 0.1846955567598343]\n",
            "[Iteration: 3680] [Loss: 0.19188354909420013]\n",
            "[Iteration: 3681] [Loss: 0.17194068431854248]\n",
            "[Iteration: 3682] [Loss: 0.16193191707134247]\n",
            "[Iteration: 3683] [Loss: 0.17406554520130157]\n",
            "[Iteration: 3684] [Loss: 0.16156752407550812]\n",
            "[Iteration: 3685] [Loss: 0.19010809063911438]\n",
            "[Iteration: 3686] [Loss: 0.17849315702915192]\n",
            "[Iteration: 3687] [Loss: 0.16718848049640656]\n",
            "[Iteration: 3688] [Loss: 0.16854757070541382]\n",
            "[Iteration: 3689] [Loss: 0.1805320382118225]\n",
            "[Iteration: 3690] [Loss: 0.1818179041147232]\n",
            "[Iteration: 3691] [Loss: 0.1711108386516571]\n",
            "[Iteration: 3692] [Loss: 0.1822555661201477]\n",
            "[Iteration: 3693] [Loss: 0.17972533404827118]\n",
            "[Iteration: 3694] [Loss: 0.20940960943698883]\n",
            "[Iteration: 3695] [Loss: 0.19494952261447906]\n",
            "[Iteration: 3696] [Loss: 0.16168123483657837]\n",
            "[Iteration: 3697] [Loss: 0.19819265604019165]\n",
            "[Iteration: 3698] [Loss: 0.16797217726707458]\n",
            "[Iteration: 3699] [Loss: 0.18701289594173431]\n",
            "[Iteration: 3700] [Loss: 0.16892679035663605]\n",
            "[Iteration: 3701] [Loss: 0.19763486087322235]\n",
            "[Iteration: 3702] [Loss: 0.1603609323501587]\n",
            "[Iteration: 3703] [Loss: 0.1822168380022049]\n",
            "[Iteration: 3704] [Loss: 0.16899502277374268]\n",
            "[Iteration: 3705] [Loss: 0.1623818576335907]\n",
            "[Iteration: 3706] [Loss: 0.2012149840593338]\n",
            "[Iteration: 3707] [Loss: 0.1681395173072815]\n",
            "[Iteration: 3708] [Loss: 0.17041398584842682]\n",
            "[Iteration: 3709] [Loss: 0.19559688866138458]\n",
            "[Iteration: 3710] [Loss: 0.19778740406036377]\n",
            "[Iteration: 3711] [Loss: 0.18473313748836517]\n",
            "[Iteration: 3712] [Loss: 0.175131693482399]\n",
            "[Iteration: 3713] [Loss: 0.16042320430278778]\n",
            "[Iteration: 3714] [Loss: 0.18725985288619995]\n",
            "[Iteration: 3715] [Loss: 0.1934337168931961]\n",
            "[Iteration: 3716] [Loss: 0.17000502347946167]\n",
            "[Iteration: 3717] [Loss: 0.1737896054983139]\n",
            "[Iteration: 3718] [Loss: 0.1892809271812439]\n",
            "[Iteration: 3719] [Loss: 0.18141454458236694]\n",
            "[Iteration: 3720] [Loss: 0.20346978306770325]\n",
            "[Iteration: 3721] [Loss: 0.19041767716407776]\n",
            "[Iteration: 3722] [Loss: 0.17450271546840668]\n",
            "[Iteration: 3723] [Loss: 0.18572017550468445]\n",
            "[Iteration: 3724] [Loss: 0.1699402928352356]\n",
            "[Iteration: 3725] [Loss: 0.18313156068325043]\n",
            "[Iteration: 3726] [Loss: 0.16548413038253784]\n",
            "[Iteration: 3727] [Loss: 0.15867935121059418]\n",
            "[Iteration: 3728] [Loss: 0.16051504015922546]\n",
            "[Iteration: 3729] [Loss: 0.17311713099479675]\n",
            "[Iteration: 3730] [Loss: 0.1980285942554474]\n",
            "[Iteration: 3731] [Loss: 0.16491243243217468]\n",
            "[Iteration: 3732] [Loss: 0.1644735336303711]\n",
            "[Iteration: 3733] [Loss: 0.17335431277751923]\n",
            "[Iteration: 3734] [Loss: 0.1921200156211853]\n",
            "[Iteration: 3735] [Loss: 0.1867087185382843]\n",
            "[Iteration: 3736] [Loss: 0.17014044523239136]\n",
            "[Iteration: 3737] [Loss: 0.1632116585969925]\n",
            "[Iteration: 3738] [Loss: 0.1590304970741272]\n",
            "[Iteration: 3739] [Loss: 0.18255899846553802]\n",
            "[Iteration: 3740] [Loss: 0.17816706001758575]\n",
            "[Iteration: 3741] [Loss: 0.18317532539367676]\n",
            "[Iteration: 3742] [Loss: 0.16292914748191833]\n",
            "[Iteration: 3743] [Loss: 0.1830766797065735]\n",
            "[Iteration: 3744] [Loss: 0.1862829029560089]\n",
            "[Iteration: 3745] [Loss: 0.15958580374717712]\n",
            "[Iteration: 3746] [Loss: 0.16224625706672668]\n",
            "[Iteration: 3747] [Loss: 0.15671749413013458]\n",
            "[Iteration: 3748] [Loss: 0.1910749226808548]\n",
            "[Iteration: 3749] [Loss: 0.18311922252178192]\n",
            "[Iteration: 3750] [Loss: 0.1770063042640686]\n",
            "[Iteration: 3751] [Loss: 0.16742773354053497]\n",
            "[Iteration: 3752] [Loss: 0.20128664374351501]\n",
            "[Iteration: 3753] [Loss: 0.17047695815563202]\n",
            "[Iteration: 3754] [Loss: 0.1682542860507965]\n",
            "[Iteration: 3755] [Loss: 0.17636236548423767]\n",
            "[Iteration: 3756] [Loss: 0.18919165432453156]\n",
            "[Iteration: 3757] [Loss: 0.17699308693408966]\n",
            "[Iteration: 3758] [Loss: 0.1720215529203415]\n",
            "[Iteration: 3759] [Loss: 0.167997807264328]\n",
            "[Iteration: 3760] [Loss: 0.16564559936523438]\n",
            "[Iteration: 3761] [Loss: 0.17818060517311096]\n",
            "[Iteration: 3762] [Loss: 0.1725432276725769]\n",
            "[Iteration: 3763] [Loss: 0.17992429435253143]\n",
            "[Iteration: 3764] [Loss: 0.182920902967453]\n",
            "[Iteration: 3765] [Loss: 0.19806058704853058]\n",
            "[Iteration: 3766] [Loss: 0.17923204600811005]\n",
            "[Iteration: 3767] [Loss: 0.19152553379535675]\n",
            "[Iteration: 3768] [Loss: 0.16363508999347687]\n",
            "[Iteration: 3769] [Loss: 0.17977331578731537]\n",
            "[Iteration: 3770] [Loss: 0.17317408323287964]\n",
            "[Iteration: 3771] [Loss: 0.19093568623065948]\n",
            "[Iteration: 3772] [Loss: 0.1706710010766983]\n",
            "[Iteration: 3773] [Loss: 0.19827406108379364]\n",
            "[Iteration: 3774] [Loss: 0.19372320175170898]\n",
            "[Iteration: 3775] [Loss: 0.18066848814487457]\n",
            "[Iteration: 3776] [Loss: 0.15119528770446777]\n",
            "[Iteration: 3777] [Loss: 0.17155665159225464]\n",
            "[Iteration: 3778] [Loss: 0.18146687746047974]\n",
            "[Iteration: 3779] [Loss: 0.15441781282424927]\n",
            "[Iteration: 3780] [Loss: 0.16919143497943878]\n",
            "[Iteration: 3781] [Loss: 0.1784290373325348]\n",
            "[Iteration: 3782] [Loss: 0.1850634068250656]\n",
            "[Iteration: 3783] [Loss: 0.1741657555103302]\n",
            "[Iteration: 3784] [Loss: 0.1806563436985016]\n",
            "[Iteration: 3785] [Loss: 0.18291956186294556]\n",
            "[Iteration: 3786] [Loss: 0.1810646951198578]\n",
            "[Iteration: 3787] [Loss: 0.16087347269058228]\n",
            "[Iteration: 3788] [Loss: 0.16475531458854675]\n",
            "[Iteration: 3789] [Loss: 0.18501821160316467]\n",
            "[Iteration: 3790] [Loss: 0.17189854383468628]\n",
            "[Iteration: 3791] [Loss: 0.18855562806129456]\n",
            "[Iteration: 3792] [Loss: 0.1898159235715866]\n",
            "[Iteration: 3793] [Loss: 0.1718350350856781]\n",
            "[Iteration: 3794] [Loss: 0.1741308569908142]\n",
            "[Iteration: 3795] [Loss: 0.1902444213628769]\n",
            "[Iteration: 3796] [Loss: 0.15700019896030426]\n",
            "[Iteration: 3797] [Loss: 0.14722450077533722]\n",
            "[Iteration: 3798] [Loss: 0.18070687353610992]\n",
            "[Iteration: 3799] [Loss: 0.18164683878421783]\n",
            "[Iteration: 3800] [Loss: 0.18065452575683594]\n",
            "[Iteration: 3801] [Loss: 0.1931873857975006]\n",
            "[Iteration: 3802] [Loss: 0.16731703281402588]\n",
            "[Iteration: 3803] [Loss: 0.1898026466369629]\n",
            "[Iteration: 3804] [Loss: 0.1799391806125641]\n",
            "[Iteration: 3805] [Loss: 0.18275953829288483]\n",
            "[Iteration: 3806] [Loss: 0.1679404228925705]\n",
            "[Iteration: 3807] [Loss: 0.17047490179538727]\n",
            "[Iteration: 3808] [Loss: 0.14724582433700562]\n",
            "[Iteration: 3809] [Loss: 0.17648762464523315]\n",
            "[Iteration: 3810] [Loss: 0.16671748459339142]\n",
            "[Iteration: 3811] [Loss: 0.16420380771160126]\n",
            "[Iteration: 3812] [Loss: 0.16050809621810913]\n",
            "[Iteration: 3813] [Loss: 0.2052033245563507]\n",
            "[Iteration: 3814] [Loss: 0.1714799702167511]\n",
            "[Iteration: 3815] [Loss: 0.18527942895889282]\n",
            "[Iteration: 3816] [Loss: 0.190810427069664]\n",
            "[Iteration: 3817] [Loss: 0.1606530249118805]\n",
            "[Iteration: 3818] [Loss: 0.18249794840812683]\n",
            "[Iteration: 3819] [Loss: 0.19357605278491974]\n",
            "[Iteration: 3820] [Loss: 0.21103087067604065]\n",
            "[Iteration: 3821] [Loss: 0.183000385761261]\n",
            "[Iteration: 3822] [Loss: 0.18005307018756866]\n",
            "[Iteration: 3823] [Loss: 0.1738896369934082]\n",
            "[Iteration: 3824] [Loss: 0.16460807621479034]\n",
            "[Iteration: 3825] [Loss: 0.17262078821659088]\n",
            "[Iteration: 3826] [Loss: 0.18012268841266632]\n",
            "[Iteration: 3827] [Loss: 0.1790989488363266]\n",
            "[Iteration: 3828] [Loss: 0.16801950335502625]\n",
            "[Iteration: 3829] [Loss: 0.17084342241287231]\n",
            "[Iteration: 3830] [Loss: 0.176285520195961]\n",
            "[Iteration: 3831] [Loss: 0.1831926703453064]\n",
            "[Iteration: 3832] [Loss: 0.16969293355941772]\n",
            "[Iteration: 3833] [Loss: 0.19200292229652405]\n",
            "[Iteration: 3834] [Loss: 0.17357344925403595]\n",
            "[Iteration: 3835] [Loss: 0.16203853487968445]\n",
            "[Iteration: 3836] [Loss: 0.19601024687290192]\n",
            "[Iteration: 3837] [Loss: 0.16815750300884247]\n",
            "[Iteration: 3838] [Loss: 0.19459901750087738]\n",
            "[Iteration: 3839] [Loss: 0.18054577708244324]\n",
            "[Iteration: 3840] [Loss: 0.1781976819038391]\n",
            "[Iteration: 3841] [Loss: 0.16853463649749756]\n",
            "[Iteration: 3842] [Loss: 0.1702558398246765]\n",
            "[Iteration: 3843] [Loss: 0.20409256219863892]\n",
            "[Iteration: 3844] [Loss: 0.14160630106925964]\n",
            "[Iteration: 3845] [Loss: 0.15590912103652954]\n",
            "[Iteration: 3846] [Loss: 0.17695395648479462]\n",
            "[Iteration: 3847] [Loss: 0.18182826042175293]\n",
            "[Iteration: 3848] [Loss: 0.18752291798591614]\n",
            "[Iteration: 3849] [Loss: 0.16086934506893158]\n",
            "[Iteration: 3850] [Loss: 0.17439693212509155]\n",
            "[Iteration: 3851] [Loss: 0.17403756082057953]\n",
            "[Iteration: 3852] [Loss: 0.15311217308044434]\n",
            "[Iteration: 3853] [Loss: 0.17186099290847778]\n",
            "[Iteration: 3854] [Loss: 0.18134917318820953]\n",
            "[Iteration: 3855] [Loss: 0.19789908826351166]\n",
            "[Iteration: 3856] [Loss: 0.1757604032754898]\n",
            "[Iteration: 3857] [Loss: 0.16547971963882446]\n",
            "[Iteration: 3858] [Loss: 0.16846689581871033]\n",
            "[Iteration: 3859] [Loss: 0.14461854100227356]\n",
            "[Iteration: 3860] [Loss: 0.18437933921813965]\n",
            "[Iteration: 3861] [Loss: 0.20663125813007355]\n",
            "[Iteration: 3862] [Loss: 0.19266457855701447]\n",
            "[Iteration: 3863] [Loss: 0.1533498764038086]\n",
            "[Iteration: 3864] [Loss: 0.18456774950027466]\n",
            "[Iteration: 3865] [Loss: 0.16843783855438232]\n",
            "[Iteration: 3866] [Loss: 0.16885314881801605]\n",
            "[Iteration: 3867] [Loss: 0.16358248889446259]\n",
            "[Iteration: 3868] [Loss: 0.1699017584323883]\n",
            "[Iteration: 3869] [Loss: 0.17611391842365265]\n",
            "[Iteration: 3870] [Loss: 0.1872159242630005]\n",
            "[Iteration: 3871] [Loss: 0.1961931735277176]\n",
            "[Iteration: 3872] [Loss: 0.17979620397090912]\n",
            "[Iteration: 3873] [Loss: 0.16416369378566742]\n",
            "[Iteration: 3874] [Loss: 0.17630726099014282]\n",
            "[Iteration: 3875] [Loss: 0.17053095996379852]\n",
            "[Iteration: 3876] [Loss: 0.1690245121717453]\n",
            "[Iteration: 3877] [Loss: 0.19659096002578735]\n",
            "[Iteration: 3878] [Loss: 0.16771022975444794]\n",
            "[Iteration: 3879] [Loss: 0.1803244650363922]\n",
            "[Iteration: 3880] [Loss: 0.16616807878017426]\n",
            "[Iteration: 3881] [Loss: 0.18015852570533752]\n",
            "[Iteration: 3882] [Loss: 0.17305725812911987]\n",
            "[Iteration: 3883] [Loss: 0.16227281093597412]\n",
            "[Iteration: 3884] [Loss: 0.1629503071308136]\n",
            "[Iteration: 3885] [Loss: 0.17307689785957336]\n",
            "[Iteration: 3886] [Loss: 0.16638313233852386]\n",
            "[Iteration: 3887] [Loss: 0.1638929843902588]\n",
            "[Iteration: 3888] [Loss: 0.19333574175834656]\n",
            "[Iteration: 3889] [Loss: 0.17996831238269806]\n",
            "[Iteration: 3890] [Loss: 0.18058815598487854]\n",
            "[Iteration: 3891] [Loss: 0.2035549283027649]\n",
            "[Iteration: 3892] [Loss: 0.17780326306819916]\n",
            "[Iteration: 3893] [Loss: 0.16079001128673553]\n",
            "[Iteration: 3894] [Loss: 0.18445450067520142]\n",
            "[Iteration: 3895] [Loss: 0.1695680320262909]\n",
            "[Iteration: 3896] [Loss: 0.14880436658859253]\n",
            "[Iteration: 3897] [Loss: 0.17065729200839996]\n",
            "[Iteration: 3898] [Loss: 0.14306189119815826]\n",
            "[Iteration: 3899] [Loss: 0.1583656668663025]\n",
            "[Iteration: 3900] [Loss: 0.17838650941848755]\n",
            "[Iteration: 3901] [Loss: 0.17819076776504517]\n",
            "[Iteration: 3902] [Loss: 0.16746696829795837]\n",
            "[Iteration: 3903] [Loss: 0.16556809842586517]\n",
            "[Iteration: 3904] [Loss: 0.14978189766407013]\n",
            "[Iteration: 3905] [Loss: 0.19888870418071747]\n",
            "[Iteration: 3906] [Loss: 0.17753608524799347]\n",
            "[Iteration: 3907] [Loss: 0.16384033858776093]\n",
            "[Iteration: 3908] [Loss: 0.16566917300224304]\n",
            "[Iteration: 3909] [Loss: 0.17787867784500122]\n",
            "[Iteration: 3910] [Loss: 0.1738971322774887]\n",
            "[Iteration: 3911] [Loss: 0.1719641089439392]\n",
            "[Iteration: 3912] [Loss: 0.16744357347488403]\n",
            "[Iteration: 3913] [Loss: 0.17146606743335724]\n",
            "[Iteration: 3914] [Loss: 0.1924920678138733]\n",
            "[Iteration: 3915] [Loss: 0.19138753414154053]\n",
            "[Iteration: 3916] [Loss: 0.16468779742717743]\n",
            "[Iteration: 3917] [Loss: 0.1774323582649231]\n",
            "[Iteration: 3918] [Loss: 0.1656731814146042]\n",
            "[Iteration: 3919] [Loss: 0.1907562017440796]\n",
            "[Iteration: 3920] [Loss: 0.15545041859149933]\n",
            "[Iteration: 3921] [Loss: 0.1772693246603012]\n",
            "[Iteration: 3922] [Loss: 0.16417953372001648]\n",
            "[Iteration: 3923] [Loss: 0.1660122126340866]\n",
            "[Iteration: 3924] [Loss: 0.1569843590259552]\n",
            "[Iteration: 3925] [Loss: 0.15898855030536652]\n",
            "[Iteration: 3926] [Loss: 0.1706218123435974]\n",
            "[Iteration: 3927] [Loss: 0.1695314347743988]\n",
            "[Iteration: 3928] [Loss: 0.19908294081687927]\n",
            "[Iteration: 3929] [Loss: 0.17822501063346863]\n",
            "[Iteration: 3930] [Loss: 0.1757555902004242]\n",
            "[Iteration: 3931] [Loss: 0.17573697865009308]\n",
            "[Iteration: 3932] [Loss: 0.15971443057060242]\n",
            "[Iteration: 3933] [Loss: 0.19131438434123993]\n",
            "[Iteration: 3934] [Loss: 0.14698852598667145]\n",
            "[Iteration: 3935] [Loss: 0.15970057249069214]\n",
            "[Iteration: 3936] [Loss: 0.1564640998840332]\n",
            "[Iteration: 3937] [Loss: 0.18968528509140015]\n",
            "[Iteration: 3938] [Loss: 0.18448930978775024]\n",
            "[Iteration: 3939] [Loss: 0.17916294932365417]\n",
            "[Iteration: 3940] [Loss: 0.17578867077827454]\n",
            "[Iteration: 3941] [Loss: 0.14797474443912506]\n",
            "[Iteration: 3942] [Loss: 0.16790683567523956]\n",
            "[Iteration: 3943] [Loss: 0.19442731142044067]\n",
            "[Iteration: 3944] [Loss: 0.16265654563903809]\n",
            "[Iteration: 3945] [Loss: 0.17383962869644165]\n",
            "[Iteration: 3946] [Loss: 0.19159699976444244]\n",
            "[Iteration: 3947] [Loss: 0.176805779337883]\n",
            "[Iteration: 3948] [Loss: 0.17073723673820496]\n",
            "[Iteration: 3949] [Loss: 0.17023001611232758]\n",
            "[Iteration: 3950] [Loss: 0.19490770995616913]\n",
            "[Iteration: 3951] [Loss: 0.1653795689344406]\n",
            "[Iteration: 3952] [Loss: 0.1890791952610016]\n",
            "[Iteration: 3953] [Loss: 0.16475354135036469]\n",
            "[Iteration: 3954] [Loss: 0.1756330132484436]\n",
            "[Iteration: 3955] [Loss: 0.1710691750049591]\n",
            "[Iteration: 3956] [Loss: 0.16262780129909515]\n",
            "[Iteration: 3957] [Loss: 0.18610793352127075]\n",
            "[Iteration: 3958] [Loss: 0.20406222343444824]\n",
            "[Iteration: 3959] [Loss: 0.1600622534751892]\n",
            "[Iteration: 3960] [Loss: 0.17710144817829132]\n",
            "[Iteration: 3961] [Loss: 0.16642753779888153]\n",
            "[Iteration: 3962] [Loss: 0.1514497846364975]\n",
            "[Iteration: 3963] [Loss: 0.1673382967710495]\n",
            "[Iteration: 3964] [Loss: 0.16791999340057373]\n",
            "[Iteration: 3965] [Loss: 0.15576167404651642]\n",
            "[Iteration: 3966] [Loss: 0.15615156292915344]\n",
            "[Iteration: 3967] [Loss: 0.16402557492256165]\n",
            "[Iteration: 3968] [Loss: 0.16134455800056458]\n",
            "[Iteration: 3969] [Loss: 0.1756044179201126]\n",
            "[Iteration: 3970] [Loss: 0.1696109175682068]\n",
            "[Iteration: 3971] [Loss: 0.18270929157733917]\n",
            "[Iteration: 3972] [Loss: 0.1813831776380539]\n",
            "[Iteration: 3973] [Loss: 0.15566442906856537]\n",
            "[Iteration: 3974] [Loss: 0.16665898263454437]\n",
            "[Iteration: 3975] [Loss: 0.17399369180202484]\n",
            "[Iteration: 3976] [Loss: 0.16683746874332428]\n",
            "[Iteration: 3977] [Loss: 0.19327035546302795]\n",
            "[Iteration: 3978] [Loss: 0.18410347402095795]\n",
            "[Iteration: 3979] [Loss: 0.18462036550045013]\n",
            "[Iteration: 3980] [Loss: 0.1939997673034668]\n",
            "[Iteration: 3981] [Loss: 0.14701387286186218]\n",
            "[Iteration: 3982] [Loss: 0.1480126827955246]\n",
            "[Iteration: 3983] [Loss: 0.16150178015232086]\n",
            "[Iteration: 3984] [Loss: 0.14208786189556122]\n",
            "[Iteration: 3985] [Loss: 0.16863733530044556]\n",
            "[Iteration: 3986] [Loss: 0.16168630123138428]\n",
            "[Iteration: 3987] [Loss: 0.1768357753753662]\n",
            "[Iteration: 3988] [Loss: 0.14176395535469055]\n",
            "[Iteration: 3989] [Loss: 0.16731901466846466]\n",
            "[Iteration: 3990] [Loss: 0.16799385845661163]\n",
            "[Iteration: 3991] [Loss: 0.18514172732830048]\n",
            "[Iteration: 3992] [Loss: 0.17925764620304108]\n",
            "[Iteration: 3993] [Loss: 0.16941697895526886]\n",
            "[Iteration: 3994] [Loss: 0.17940905690193176]\n",
            "[Iteration: 3995] [Loss: 0.163725346326828]\n",
            "[Iteration: 3996] [Loss: 0.16325314342975616]\n",
            "[Iteration: 3997] [Loss: 0.17469710111618042]\n",
            "[Iteration: 3998] [Loss: 0.16815294325351715]\n",
            "[Iteration: 3999] [Loss: 0.1803564578294754]\n",
            "[Iteration: 4000] [Loss: 0.17302590608596802]\n",
            "[Iteration: 4001] [Loss: 0.1812276989221573]\n",
            "[Iteration: 4002] [Loss: 0.18010100722312927]\n",
            "[Iteration: 4003] [Loss: 0.1739734411239624]\n",
            "[Iteration: 4004] [Loss: 0.1485110968351364]\n",
            "[Iteration: 4005] [Loss: 0.1657189279794693]\n",
            "[Iteration: 4006] [Loss: 0.17662350833415985]\n",
            "[Iteration: 4007] [Loss: 0.17995251715183258]\n",
            "[Iteration: 4008] [Loss: 0.17049698531627655]\n",
            "[Iteration: 4009] [Loss: 0.18081936240196228]\n",
            "[Iteration: 4010] [Loss: 0.1600717157125473]\n",
            "[Iteration: 4011] [Loss: 0.1622389554977417]\n",
            "[Iteration: 4012] [Loss: 0.14731614291667938]\n",
            "[Iteration: 4013] [Loss: 0.15510022640228271]\n",
            "[Iteration: 4014] [Loss: 0.16870751976966858]\n",
            "[Iteration: 4015] [Loss: 0.16784167289733887]\n",
            "[Iteration: 4016] [Loss: 0.15532399713993073]\n",
            "[Iteration: 4017] [Loss: 0.14826348423957825]\n",
            "[Iteration: 4018] [Loss: 0.16759496927261353]\n",
            "[Iteration: 4019] [Loss: 0.15806777775287628]\n",
            "[Iteration: 4020] [Loss: 0.1754717081785202]\n",
            "[Iteration: 4021] [Loss: 0.145365908741951]\n",
            "[Iteration: 4022] [Loss: 0.16825486719608307]\n",
            "[Iteration: 4023] [Loss: 0.1649314910173416]\n",
            "[Iteration: 4024] [Loss: 0.14571994543075562]\n",
            "[Iteration: 4025] [Loss: 0.15394729375839233]\n",
            "[Iteration: 4026] [Loss: 0.17552511394023895]\n",
            "[Iteration: 4027] [Loss: 0.17026160657405853]\n",
            "[Iteration: 4028] [Loss: 0.20379064977169037]\n",
            "[Iteration: 4029] [Loss: 0.16271035373210907]\n",
            "[Iteration: 4030] [Loss: 0.17098304629325867]\n",
            "[Iteration: 4031] [Loss: 0.17225295305252075]\n",
            "[Iteration: 4032] [Loss: 0.17580050230026245]\n",
            "[Iteration: 4033] [Loss: 0.1591954082250595]\n",
            "[Iteration: 4034] [Loss: 0.19105523824691772]\n",
            "[Iteration: 4035] [Loss: 0.15378206968307495]\n",
            "[Iteration: 4036] [Loss: 0.17829811573028564]\n",
            "[Iteration: 4037] [Loss: 0.14849089086055756]\n",
            "[Iteration: 4038] [Loss: 0.1544407457113266]\n",
            "[Iteration: 4039] [Loss: 0.16485632956027985]\n",
            "[Iteration: 4040] [Loss: 0.17308950424194336]\n",
            "[Iteration: 4041] [Loss: 0.16657565534114838]\n",
            "[Iteration: 4042] [Loss: 0.14642035961151123]\n",
            "[Iteration: 4043] [Loss: 0.18238034844398499]\n",
            "[Iteration: 4044] [Loss: 0.170742928981781]\n",
            "[Iteration: 4045] [Loss: 0.1798868179321289]\n",
            "[Iteration: 4046] [Loss: 0.16715513169765472]\n",
            "[Iteration: 4047] [Loss: 0.15368205308914185]\n",
            "[Iteration: 4048] [Loss: 0.16641217470169067]\n",
            "[Iteration: 4049] [Loss: 0.15092530846595764]\n",
            "[Iteration: 4050] [Loss: 0.18858635425567627]\n",
            "[Iteration: 4051] [Loss: 0.1657104790210724]\n",
            "[Iteration: 4052] [Loss: 0.15350039303302765]\n",
            "[Iteration: 4053] [Loss: 0.19066020846366882]\n",
            "[Iteration: 4054] [Loss: 0.161528080701828]\n",
            "[Iteration: 4055] [Loss: 0.16507014632225037]\n",
            "[Iteration: 4056] [Loss: 0.18768328428268433]\n",
            "[Iteration: 4057] [Loss: 0.18997780978679657]\n",
            "[Iteration: 4058] [Loss: 0.14609411358833313]\n",
            "[Iteration: 4059] [Loss: 0.16714845597743988]\n",
            "[Iteration: 4060] [Loss: 0.175736203789711]\n",
            "[Iteration: 4061] [Loss: 0.15135842561721802]\n",
            "[Iteration: 4062] [Loss: 0.179639995098114]\n",
            "[Iteration: 4063] [Loss: 0.17830704152584076]\n",
            "[Iteration: 4064] [Loss: 0.18692830204963684]\n",
            "[Iteration: 4065] [Loss: 0.17101843655109406]\n",
            "[Iteration: 4066] [Loss: 0.15819132328033447]\n",
            "[Iteration: 4067] [Loss: 0.16161631047725677]\n",
            "[Iteration: 4068] [Loss: 0.1683456301689148]\n",
            "[Iteration: 4069] [Loss: 0.1773267686367035]\n",
            "[Iteration: 4070] [Loss: 0.14522938430309296]\n",
            "[Iteration: 4071] [Loss: 0.1548180729150772]\n",
            "[Iteration: 4072] [Loss: 0.16624225676059723]\n",
            "[Iteration: 4073] [Loss: 0.1815105825662613]\n",
            "[Iteration: 4074] [Loss: 0.20070479810237885]\n",
            "[Iteration: 4075] [Loss: 0.1930331438779831]\n",
            "[Iteration: 4076] [Loss: 0.1468920111656189]\n",
            "[Iteration: 4077] [Loss: 0.18809279799461365]\n",
            "[Iteration: 4078] [Loss: 0.1682756543159485]\n",
            "[Iteration: 4079] [Loss: 0.16121336817741394]\n",
            "[Iteration: 4080] [Loss: 0.16336590051651]\n",
            "[Iteration: 4081] [Loss: 0.16924798488616943]\n",
            "[Iteration: 4082] [Loss: 0.14157260954380035]\n",
            "[Iteration: 4083] [Loss: 0.1530400812625885]\n",
            "[Iteration: 4084] [Loss: 0.15772907435894012]\n",
            "[Iteration: 4085] [Loss: 0.16595885157585144]\n",
            "[Iteration: 4086] [Loss: 0.18016229569911957]\n",
            "[Iteration: 4087] [Loss: 0.17000070214271545]\n",
            "[Iteration: 4088] [Loss: 0.15677838027477264]\n",
            "[Iteration: 4089] [Loss: 0.16807858645915985]\n",
            "[Iteration: 4090] [Loss: 0.15057110786437988]\n",
            "[Iteration: 4091] [Loss: 0.15802358090877533]\n",
            "[Iteration: 4092] [Loss: 0.16601522266864777]\n",
            "[Iteration: 4093] [Loss: 0.16330760717391968]\n",
            "[Iteration: 4094] [Loss: 0.16845747828483582]\n",
            "[Iteration: 4095] [Loss: 0.17771603167057037]\n",
            "[Iteration: 4096] [Loss: 0.17518354952335358]\n",
            "[Iteration: 4097] [Loss: 0.18007920682430267]\n",
            "[Iteration: 4098] [Loss: 0.16090720891952515]\n",
            "[Iteration: 4099] [Loss: 0.1639970988035202]\n",
            "[Iteration: 4100] [Loss: 0.1785617470741272]\n",
            "[Iteration: 4101] [Loss: 0.1739979088306427]\n",
            "[Iteration: 4102] [Loss: 0.17408141493797302]\n",
            "[Iteration: 4103] [Loss: 0.18790759146213531]\n",
            "[Iteration: 4104] [Loss: 0.16055798530578613]\n",
            "[Iteration: 4105] [Loss: 0.1631384938955307]\n",
            "[Iteration: 4106] [Loss: 0.15340310335159302]\n",
            "[Iteration: 4107] [Loss: 0.17110541462898254]\n",
            "[Iteration: 4108] [Loss: 0.17973652482032776]\n",
            "[Iteration: 4109] [Loss: 0.16331246495246887]\n",
            "[Iteration: 4110] [Loss: 0.15485765039920807]\n",
            "[Iteration: 4111] [Loss: 0.1742626130580902]\n",
            "[Iteration: 4112] [Loss: 0.161418616771698]\n",
            "[Iteration: 4113] [Loss: 0.16844642162322998]\n",
            "[Iteration: 4114] [Loss: 0.14220371842384338]\n",
            "[Iteration: 4115] [Loss: 0.18360896408557892]\n",
            "[Iteration: 4116] [Loss: 0.17285726964473724]\n",
            "[Iteration: 4117] [Loss: 0.1871793568134308]\n",
            "[Iteration: 4118] [Loss: 0.17819201946258545]\n",
            "[Iteration: 4119] [Loss: 0.14519521594047546]\n",
            "[Iteration: 4120] [Loss: 0.17822040617465973]\n",
            "[Iteration: 4121] [Loss: 0.15551704168319702]\n",
            "[Iteration: 4122] [Loss: 0.16447806358337402]\n",
            "[Iteration: 4123] [Loss: 0.1818014681339264]\n",
            "[Iteration: 4124] [Loss: 0.1528882384300232]\n",
            "[Iteration: 4125] [Loss: 0.16708388924598694]\n",
            "[Iteration: 4126] [Loss: 0.15957839787006378]\n",
            "[Iteration: 4127] [Loss: 0.1418464183807373]\n",
            "[Iteration: 4128] [Loss: 0.1555638611316681]\n",
            "[Iteration: 4129] [Loss: 0.16067010164260864]\n",
            "[Iteration: 4130] [Loss: 0.15242503583431244]\n",
            "[Iteration: 4131] [Loss: 0.1571190357208252]\n",
            "[Iteration: 4132] [Loss: 0.1521521508693695]\n",
            "[Iteration: 4133] [Loss: 0.18018680810928345]\n",
            "[Iteration: 4134] [Loss: 0.1582362800836563]\n",
            "[Iteration: 4135] [Loss: 0.16279838979244232]\n",
            "[Iteration: 4136] [Loss: 0.16677559912204742]\n",
            "[Iteration: 4137] [Loss: 0.1768767237663269]\n",
            "[Iteration: 4138] [Loss: 0.17005498707294464]\n",
            "[Iteration: 4139] [Loss: 0.1650087833404541]\n",
            "[Iteration: 4140] [Loss: 0.1473611742258072]\n",
            "[Iteration: 4141] [Loss: 0.16457951068878174]\n",
            "[Iteration: 4142] [Loss: 0.14033888280391693]\n",
            "[Iteration: 4143] [Loss: 0.14436976611614227]\n",
            "[Iteration: 4144] [Loss: 0.14652103185653687]\n",
            "[Iteration: 4145] [Loss: 0.18033312261104584]\n",
            "[Iteration: 4146] [Loss: 0.17839843034744263]\n",
            "[Iteration: 4147] [Loss: 0.14806395769119263]\n",
            "[Iteration: 4148] [Loss: 0.1634606271982193]\n",
            "[Iteration: 4149] [Loss: 0.16000689566135406]\n",
            "[Iteration: 4150] [Loss: 0.14752182364463806]\n",
            "[Iteration: 4151] [Loss: 0.1484236717224121]\n",
            "[Iteration: 4152] [Loss: 0.18907862901687622]\n",
            "[Iteration: 4153] [Loss: 0.16775837540626526]\n",
            "[Iteration: 4154] [Loss: 0.17729686200618744]\n",
            "[Iteration: 4155] [Loss: 0.1711811125278473]\n",
            "[Iteration: 4156] [Loss: 0.1695951223373413]\n",
            "[Iteration: 4157] [Loss: 0.15807142853736877]\n",
            "[Iteration: 4158] [Loss: 0.15850523114204407]\n",
            "[Iteration: 4159] [Loss: 0.16812698543071747]\n",
            "[Iteration: 4160] [Loss: 0.17830578982830048]\n",
            "[Iteration: 4161] [Loss: 0.16863422095775604]\n",
            "[Iteration: 4162] [Loss: 0.17867428064346313]\n",
            "[Iteration: 4163] [Loss: 0.1680348515510559]\n",
            "[Iteration: 4164] [Loss: 0.17812855541706085]\n",
            "[Iteration: 4165] [Loss: 0.15718232095241547]\n",
            "[Iteration: 4166] [Loss: 0.1505785882472992]\n",
            "[Iteration: 4167] [Loss: 0.17313063144683838]\n",
            "[Iteration: 4168] [Loss: 0.15986233949661255]\n",
            "[Iteration: 4169] [Loss: 0.15568409860134125]\n",
            "[Iteration: 4170] [Loss: 0.16041649878025055]\n",
            "[Iteration: 4171] [Loss: 0.15981552004814148]\n",
            "[Iteration: 4172] [Loss: 0.16519348323345184]\n",
            "[Iteration: 4173] [Loss: 0.15247511863708496]\n",
            "[Iteration: 4174] [Loss: 0.17154794931411743]\n",
            "[Iteration: 4175] [Loss: 0.15637853741645813]\n",
            "[Iteration: 4176] [Loss: 0.16546723246574402]\n",
            "[Iteration: 4177] [Loss: 0.15182587504386902]\n",
            "[Iteration: 4178] [Loss: 0.15774361789226532]\n",
            "[Iteration: 4179] [Loss: 0.16942520439624786]\n",
            "[Iteration: 4180] [Loss: 0.1575918197631836]\n",
            "[Iteration: 4181] [Loss: 0.14758163690567017]\n",
            "[Iteration: 4182] [Loss: 0.17482596635818481]\n",
            "[Iteration: 4183] [Loss: 0.17240065336227417]\n",
            "[Iteration: 4184] [Loss: 0.16391658782958984]\n",
            "[Iteration: 4185] [Loss: 0.15768186748027802]\n",
            "[Iteration: 4186] [Loss: 0.13904240727424622]\n",
            "[Iteration: 4187] [Loss: 0.1377508044242859]\n",
            "[Iteration: 4188] [Loss: 0.17152875661849976]\n",
            "[Iteration: 4189] [Loss: 0.14528420567512512]\n",
            "[Iteration: 4190] [Loss: 0.16838563978672028]\n",
            "[Iteration: 4191] [Loss: 0.13867168128490448]\n",
            "[Iteration: 4192] [Loss: 0.14215323328971863]\n",
            "[Iteration: 4193] [Loss: 0.16784588992595673]\n",
            "[Iteration: 4194] [Loss: 0.16895928978919983]\n",
            "[Iteration: 4195] [Loss: 0.15706458687782288]\n",
            "[Iteration: 4196] [Loss: 0.16497062146663666]\n",
            "[Iteration: 4197] [Loss: 0.1628744900226593]\n",
            "[Iteration: 4198] [Loss: 0.15988248586654663]\n",
            "[Iteration: 4199] [Loss: 0.1616705060005188]\n",
            "[Iteration: 4200] [Loss: 0.16440542042255402]\n",
            "[Iteration: 4201] [Loss: 0.14716733992099762]\n",
            "[Iteration: 4202] [Loss: 0.15448075532913208]\n",
            "[Iteration: 4203] [Loss: 0.17182624340057373]\n",
            "[Iteration: 4204] [Loss: 0.15656064450740814]\n",
            "[Iteration: 4205] [Loss: 0.15852254629135132]\n",
            "[Iteration: 4206] [Loss: 0.15927523374557495]\n",
            "[Iteration: 4207] [Loss: 0.17710630595684052]\n",
            "[Iteration: 4208] [Loss: 0.16598713397979736]\n",
            "[Iteration: 4209] [Loss: 0.18652161955833435]\n",
            "[Iteration: 4210] [Loss: 0.17209768295288086]\n",
            "[Iteration: 4211] [Loss: 0.17260433733463287]\n",
            "[Iteration: 4212] [Loss: 0.18277905881404877]\n",
            "[Iteration: 4213] [Loss: 0.16197270154953003]\n",
            "[Iteration: 4214] [Loss: 0.1635410487651825]\n",
            "[Iteration: 4215] [Loss: 0.18326309323310852]\n",
            "[Iteration: 4216] [Loss: 0.15339580178260803]\n",
            "[Iteration: 4217] [Loss: 0.18053041398525238]\n",
            "[Iteration: 4218] [Loss: 0.16248928010463715]\n",
            "[Iteration: 4219] [Loss: 0.1904207170009613]\n",
            "[Iteration: 4220] [Loss: 0.17455367743968964]\n",
            "[Iteration: 4221] [Loss: 0.14202754199504852]\n",
            "[Iteration: 4222] [Loss: 0.15267780423164368]\n",
            "[Iteration: 4223] [Loss: 0.17426081001758575]\n",
            "[Iteration: 4224] [Loss: 0.1396351456642151]\n",
            "[Iteration: 4225] [Loss: 0.16991430521011353]\n",
            "[Iteration: 4226] [Loss: 0.15521889925003052]\n",
            "[Iteration: 4227] [Loss: 0.1543438732624054]\n",
            "[Iteration: 4228] [Loss: 0.15244995057582855]\n",
            "[Iteration: 4229] [Loss: 0.15427124500274658]\n",
            "[Iteration: 4230] [Loss: 0.15982726216316223]\n",
            "[Iteration: 4231] [Loss: 0.16610155999660492]\n",
            "[Iteration: 4232] [Loss: 0.1575731635093689]\n",
            "[Iteration: 4233] [Loss: 0.16253329813480377]\n",
            "[Iteration: 4234] [Loss: 0.15795551240444183]\n",
            "[Iteration: 4235] [Loss: 0.14220502972602844]\n",
            "[Iteration: 4236] [Loss: 0.16994702816009521]\n",
            "[Iteration: 4237] [Loss: 0.14802806079387665]\n",
            "[Iteration: 4238] [Loss: 0.1536739617586136]\n",
            "[Iteration: 4239] [Loss: 0.14723724126815796]\n",
            "[Iteration: 4240] [Loss: 0.14720000326633453]\n",
            "[Iteration: 4241] [Loss: 0.16447709500789642]\n",
            "[Iteration: 4242] [Loss: 0.1433425098657608]\n",
            "[Iteration: 4243] [Loss: 0.1615385264158249]\n",
            "[Iteration: 4244] [Loss: 0.13635152578353882]\n",
            "[Iteration: 4245] [Loss: 0.15092839300632477]\n",
            "[Iteration: 4246] [Loss: 0.16467739641666412]\n",
            "[Iteration: 4247] [Loss: 0.16146577894687653]\n",
            "[Iteration: 4248] [Loss: 0.19221952557563782]\n",
            "[Iteration: 4249] [Loss: 0.13769644498825073]\n",
            "[Iteration: 4250] [Loss: 0.17950423061847687]\n",
            "[Iteration: 4251] [Loss: 0.17780159413814545]\n",
            "[Iteration: 4252] [Loss: 0.1498664915561676]\n",
            "[Iteration: 4253] [Loss: 0.14996445178985596]\n",
            "[Iteration: 4254] [Loss: 0.18452414870262146]\n",
            "[Iteration: 4255] [Loss: 0.1650668978691101]\n",
            "[Iteration: 4256] [Loss: 0.16637077927589417]\n",
            "[Iteration: 4257] [Loss: 0.16284877061843872]\n",
            "[Iteration: 4258] [Loss: 0.14452418684959412]\n",
            "[Iteration: 4259] [Loss: 0.16386525332927704]\n",
            "[Iteration: 4260] [Loss: 0.15459179878234863]\n",
            "[Iteration: 4261] [Loss: 0.15913017094135284]\n",
            "[Iteration: 4262] [Loss: 0.16034826636314392]\n",
            "[Iteration: 4263] [Loss: 0.16617818176746368]\n",
            "[Iteration: 4264] [Loss: 0.1471511721611023]\n",
            "[Iteration: 4265] [Loss: 0.1607174128293991]\n",
            "[Iteration: 4266] [Loss: 0.17486445605754852]\n",
            "[Iteration: 4267] [Loss: 0.16095268726348877]\n",
            "[Iteration: 4268] [Loss: 0.16287901997566223]\n",
            "[Iteration: 4269] [Loss: 0.16160911321640015]\n",
            "[Iteration: 4270] [Loss: 0.1689133644104004]\n",
            "[Iteration: 4271] [Loss: 0.1830817013978958]\n",
            "[Iteration: 4272] [Loss: 0.16147202253341675]\n",
            "[Iteration: 4273] [Loss: 0.1806146502494812]\n",
            "[Iteration: 4274] [Loss: 0.16056469082832336]\n",
            "[Iteration: 4275] [Loss: 0.1376970410346985]\n",
            "[Iteration: 4276] [Loss: 0.1500842571258545]\n",
            "[Iteration: 4277] [Loss: 0.1625644862651825]\n",
            "[Iteration: 4278] [Loss: 0.1744174361228943]\n",
            "[Iteration: 4279] [Loss: 0.1542797088623047]\n",
            "[Iteration: 4280] [Loss: 0.16989995539188385]\n",
            "[Iteration: 4281] [Loss: 0.1673939973115921]\n",
            "[Iteration: 4282] [Loss: 0.1621144860982895]\n",
            "[Iteration: 4283] [Loss: 0.15602849423885345]\n",
            "[Iteration: 4284] [Loss: 0.16042372584342957]\n",
            "[Iteration: 4285] [Loss: 0.17531803250312805]\n",
            "[Iteration: 4286] [Loss: 0.15254680812358856]\n",
            "[Iteration: 4287] [Loss: 0.17147649824619293]\n",
            "[Iteration: 4288] [Loss: 0.14533860981464386]\n",
            "[Iteration: 4289] [Loss: 0.14575618505477905]\n",
            "[Iteration: 4290] [Loss: 0.14500001072883606]\n",
            "[Iteration: 4291] [Loss: 0.17418096959590912]\n",
            "[Iteration: 4292] [Loss: 0.14643283188343048]\n",
            "[Iteration: 4293] [Loss: 0.1636670082807541]\n",
            "[Iteration: 4294] [Loss: 0.15313047170639038]\n",
            "[Iteration: 4295] [Loss: 0.15812908113002777]\n",
            "[Iteration: 4296] [Loss: 0.12752693891525269]\n",
            "[Iteration: 4297] [Loss: 0.15513616800308228]\n",
            "[Iteration: 4298] [Loss: 0.15586744248867035]\n",
            "[Iteration: 4299] [Loss: 0.1515757441520691]\n",
            "[Iteration: 4300] [Loss: 0.14927951991558075]\n",
            "[Iteration: 4301] [Loss: 0.16344211995601654]\n",
            "[Iteration: 4302] [Loss: 0.1700918972492218]\n",
            "[Iteration: 4303] [Loss: 0.160476416349411]\n",
            "[Iteration: 4304] [Loss: 0.14244119822978973]\n",
            "[Iteration: 4305] [Loss: 0.15738311409950256]\n",
            "[Iteration: 4306] [Loss: 0.1721089482307434]\n",
            "[Iteration: 4307] [Loss: 0.1665826439857483]\n",
            "[Iteration: 4308] [Loss: 0.17794325947761536]\n",
            "[Iteration: 4309] [Loss: 0.1623445451259613]\n",
            "[Iteration: 4310] [Loss: 0.18514855206012726]\n",
            "[Iteration: 4311] [Loss: 0.1584557741880417]\n",
            "[Iteration: 4312] [Loss: 0.15113034844398499]\n",
            "[Iteration: 4313] [Loss: 0.15330001711845398]\n",
            "[Iteration: 4314] [Loss: 0.13575094938278198]\n",
            "[Iteration: 4315] [Loss: 0.16154660284519196]\n",
            "[Iteration: 4316] [Loss: 0.1749788373708725]\n",
            "[Iteration: 4317] [Loss: 0.14947429299354553]\n",
            "[Iteration: 4318] [Loss: 0.1600242257118225]\n",
            "[Iteration: 4319] [Loss: 0.13129204511642456]\n",
            "[Iteration: 4320] [Loss: 0.16693329811096191]\n",
            "[Iteration: 4321] [Loss: 0.15221060812473297]\n",
            "[Iteration: 4322] [Loss: 0.13543365895748138]\n",
            "[Iteration: 4323] [Loss: 0.1778360903263092]\n",
            "[Iteration: 4324] [Loss: 0.15241092443466187]\n",
            "[Iteration: 4325] [Loss: 0.19866260886192322]\n",
            "[Iteration: 4326] [Loss: 0.1471724659204483]\n",
            "[Iteration: 4327] [Loss: 0.1699262410402298]\n",
            "[Iteration: 4328] [Loss: 0.1736406683921814]\n",
            "[Iteration: 4329] [Loss: 0.16581030189990997]\n",
            "[Iteration: 4330] [Loss: 0.15363004803657532]\n",
            "[Iteration: 4331] [Loss: 0.1335233896970749]\n",
            "[Iteration: 4332] [Loss: 0.16764166951179504]\n",
            "[Iteration: 4333] [Loss: 0.15941780805587769]\n",
            "[Iteration: 4334] [Loss: 0.1654137670993805]\n",
            "[Iteration: 4335] [Loss: 0.177634134888649]\n",
            "[Iteration: 4336] [Loss: 0.15297967195510864]\n",
            "[Iteration: 4337] [Loss: 0.1713976263999939]\n",
            "[Iteration: 4338] [Loss: 0.16093680262565613]\n",
            "[Iteration: 4339] [Loss: 0.1647682785987854]\n",
            "[Iteration: 4340] [Loss: 0.15317851305007935]\n",
            "[Iteration: 4341] [Loss: 0.15518726408481598]\n",
            "[Iteration: 4342] [Loss: 0.17795003950595856]\n",
            "[Iteration: 4343] [Loss: 0.15950828790664673]\n",
            "[Iteration: 4344] [Loss: 0.15982085466384888]\n",
            "[Iteration: 4345] [Loss: 0.17235490679740906]\n",
            "[Iteration: 4346] [Loss: 0.15378040075302124]\n",
            "[Iteration: 4347] [Loss: 0.1555621176958084]\n",
            "[Iteration: 4348] [Loss: 0.16282255947589874]\n",
            "[Iteration: 4349] [Loss: 0.14657600224018097]\n",
            "[Iteration: 4350] [Loss: 0.1624683141708374]\n",
            "[Iteration: 4351] [Loss: 0.15499740839004517]\n",
            "[Iteration: 4352] [Loss: 0.19133904576301575]\n",
            "[Iteration: 4353] [Loss: 0.19025032222270966]\n",
            "[Iteration: 4354] [Loss: 0.14038525521755219]\n",
            "[Iteration: 4355] [Loss: 0.1664099395275116]\n",
            "[Iteration: 4356] [Loss: 0.17340391874313354]\n",
            "[Iteration: 4357] [Loss: 0.15843749046325684]\n",
            "[Iteration: 4358] [Loss: 0.15663768351078033]\n",
            "[Iteration: 4359] [Loss: 0.16793088614940643]\n",
            "[Iteration: 4360] [Loss: 0.18083477020263672]\n",
            "[Iteration: 4361] [Loss: 0.1497088074684143]\n",
            "[Iteration: 4362] [Loss: 0.1573680341243744]\n",
            "[Iteration: 4363] [Loss: 0.16001391410827637]\n",
            "[Iteration: 4364] [Loss: 0.15560327470302582]\n",
            "[Iteration: 4365] [Loss: 0.16415339708328247]\n",
            "[Iteration: 4366] [Loss: 0.1630202680826187]\n",
            "[Iteration: 4367] [Loss: 0.1640433520078659]\n",
            "[Iteration: 4368] [Loss: 0.15210862457752228]\n",
            "[Iteration: 4369] [Loss: 0.19295336306095123]\n",
            "[Iteration: 4370] [Loss: 0.17226846516132355]\n",
            "[Iteration: 4371] [Loss: 0.16861476004123688]\n",
            "[Iteration: 4372] [Loss: 0.15632319450378418]\n",
            "[Iteration: 4373] [Loss: 0.14947134256362915]\n",
            "[Iteration: 4374] [Loss: 0.1657014638185501]\n",
            "[Iteration: 4375] [Loss: 0.14824804663658142]\n",
            "[Iteration: 4376] [Loss: 0.17061962187290192]\n",
            "[Iteration: 4377] [Loss: 0.14594966173171997]\n",
            "[Iteration: 4378] [Loss: 0.143575057387352]\n",
            "[Iteration: 4379] [Loss: 0.1629316657781601]\n",
            "[Iteration: 4380] [Loss: 0.1390337496995926]\n",
            "[Iteration: 4381] [Loss: 0.16647137701511383]\n",
            "[Iteration: 4382] [Loss: 0.1792791187763214]\n",
            "[Iteration: 4383] [Loss: 0.1598081886768341]\n",
            "[Iteration: 4384] [Loss: 0.1682039201259613]\n",
            "[Iteration: 4385] [Loss: 0.16808058321475983]\n",
            "[Iteration: 4386] [Loss: 0.16085664927959442]\n",
            "[Iteration: 4387] [Loss: 0.16946348547935486]\n",
            "[Iteration: 4388] [Loss: 0.15943655371665955]\n",
            "[Iteration: 4389] [Loss: 0.1566706746816635]\n",
            "[Iteration: 4390] [Loss: 0.14747931063175201]\n",
            "[Iteration: 4391] [Loss: 0.17825345695018768]\n",
            "[Iteration: 4392] [Loss: 0.155729740858078]\n",
            "[Iteration: 4393] [Loss: 0.19097645580768585]\n",
            "[Iteration: 4394] [Loss: 0.15633386373519897]\n",
            "[Iteration: 4395] [Loss: 0.15894368290901184]\n",
            "[Iteration: 4396] [Loss: 0.17440563440322876]\n",
            "[Iteration: 4397] [Loss: 0.17531542479991913]\n",
            "[Iteration: 4398] [Loss: 0.15043646097183228]\n",
            "[Iteration: 4399] [Loss: 0.16142362356185913]\n",
            "[Iteration: 4400] [Loss: 0.16324439644813538]\n",
            "[Iteration: 4401] [Loss: 0.1518630087375641]\n",
            "[Iteration: 4402] [Loss: 0.14517775177955627]\n",
            "[Iteration: 4403] [Loss: 0.1574947088956833]\n",
            "[Iteration: 4404] [Loss: 0.1755601167678833]\n",
            "[Iteration: 4405] [Loss: 0.1603756994009018]\n",
            "[Iteration: 4406] [Loss: 0.1465330570936203]\n",
            "[Iteration: 4407] [Loss: 0.15780764818191528]\n",
            "[Iteration: 4408] [Loss: 0.17864000797271729]\n",
            "[Iteration: 4409] [Loss: 0.14214304089546204]\n",
            "[Iteration: 4410] [Loss: 0.16933734714984894]\n",
            "[Iteration: 4411] [Loss: 0.16970421373844147]\n",
            "[Iteration: 4412] [Loss: 0.15607230365276337]\n",
            "[Iteration: 4413] [Loss: 0.16744115948677063]\n",
            "[Iteration: 4414] [Loss: 0.16262850165367126]\n",
            "[Iteration: 4415] [Loss: 0.14435864984989166]\n",
            "[Iteration: 4416] [Loss: 0.15789681673049927]\n",
            "[Iteration: 4417] [Loss: 0.15397833287715912]\n",
            "[Iteration: 4418] [Loss: 0.1587018221616745]\n",
            "[Iteration: 4419] [Loss: 0.17447398602962494]\n",
            "[Iteration: 4420] [Loss: 0.1455504596233368]\n",
            "[Iteration: 4421] [Loss: 0.16010533273220062]\n",
            "[Iteration: 4422] [Loss: 0.14663992822170258]\n",
            "[Iteration: 4423] [Loss: 0.14363832771778107]\n",
            "[Iteration: 4424] [Loss: 0.15585240721702576]\n",
            "[Iteration: 4425] [Loss: 0.1402660459280014]\n",
            "[Iteration: 4426] [Loss: 0.16783982515335083]\n",
            "[Iteration: 4427] [Loss: 0.16114091873168945]\n",
            "[Iteration: 4428] [Loss: 0.14416959881782532]\n",
            "[Iteration: 4429] [Loss: 0.14382848143577576]\n",
            "[Iteration: 4430] [Loss: 0.16009965538978577]\n",
            "[Iteration: 4431] [Loss: 0.15794986486434937]\n",
            "[Iteration: 4432] [Loss: 0.16461127996444702]\n",
            "[Iteration: 4433] [Loss: 0.1465645581483841]\n",
            "[Iteration: 4434] [Loss: 0.13708175718784332]\n",
            "[Iteration: 4435] [Loss: 0.16051653027534485]\n",
            "[Iteration: 4436] [Loss: 0.14858070015907288]\n",
            "[Iteration: 4437] [Loss: 0.15553070604801178]\n",
            "[Iteration: 4438] [Loss: 0.1580657809972763]\n",
            "[Iteration: 4439] [Loss: 0.184855654835701]\n",
            "[Iteration: 4440] [Loss: 0.13917852938175201]\n",
            "[Iteration: 4441] [Loss: 0.15960925817489624]\n",
            "[Iteration: 4442] [Loss: 0.14447730779647827]\n",
            "[Iteration: 4443] [Loss: 0.16504202783107758]\n",
            "[Iteration: 4444] [Loss: 0.15093687176704407]\n",
            "[Iteration: 4445] [Loss: 0.1727927327156067]\n",
            "[Iteration: 4446] [Loss: 0.14174018800258636]\n",
            "[Iteration: 4447] [Loss: 0.14529265463352203]\n",
            "[Iteration: 4448] [Loss: 0.1766868680715561]\n",
            "[Iteration: 4449] [Loss: 0.14927725493907928]\n",
            "[Iteration: 4450] [Loss: 0.17240774631500244]\n",
            "[Iteration: 4451] [Loss: 0.15357065200805664]\n",
            "[Iteration: 4452] [Loss: 0.16736586391925812]\n",
            "[Iteration: 4453] [Loss: 0.12403734773397446]\n",
            "[Iteration: 4454] [Loss: 0.15207485854625702]\n",
            "[Iteration: 4455] [Loss: 0.17620782554149628]\n",
            "[Iteration: 4456] [Loss: 0.1634274125099182]\n",
            "[Iteration: 4457] [Loss: 0.16792042553424835]\n",
            "[Iteration: 4458] [Loss: 0.15873636305332184]\n",
            "[Iteration: 4459] [Loss: 0.16355782747268677]\n",
            "[Iteration: 4460] [Loss: 0.14649422466754913]\n",
            "[Iteration: 4461] [Loss: 0.15530508756637573]\n",
            "[Iteration: 4462] [Loss: 0.17577017843723297]\n",
            "[Iteration: 4463] [Loss: 0.1755555421113968]\n",
            "[Iteration: 4464] [Loss: 0.16485878825187683]\n",
            "[Iteration: 4465] [Loss: 0.1611064374446869]\n",
            "[Iteration: 4466] [Loss: 0.14205332100391388]\n",
            "[Iteration: 4467] [Loss: 0.17385394871234894]\n",
            "[Iteration: 4468] [Loss: 0.1351962387561798]\n",
            "[Iteration: 4469] [Loss: 0.1507110893726349]\n",
            "[Iteration: 4470] [Loss: 0.1575150489807129]\n",
            "[Iteration: 4471] [Loss: 0.16828936338424683]\n",
            "[Iteration: 4472] [Loss: 0.14895741641521454]\n",
            "[Iteration: 4473] [Loss: 0.15767918527126312]\n",
            "[Iteration: 4474] [Loss: 0.16403447091579437]\n",
            "[Iteration: 4475] [Loss: 0.1572088599205017]\n",
            "[Iteration: 4476] [Loss: 0.1755153387784958]\n",
            "[Iteration: 4477] [Loss: 0.17528660595417023]\n",
            "[Iteration: 4478] [Loss: 0.16246269643306732]\n",
            "[Iteration: 4479] [Loss: 0.15985092520713806]\n",
            "[Iteration: 4480] [Loss: 0.14091292023658752]\n",
            "[Iteration: 4481] [Loss: 0.15941542387008667]\n",
            "[Iteration: 4482] [Loss: 0.1544359028339386]\n",
            "[Iteration: 4483] [Loss: 0.16011224687099457]\n",
            "[Iteration: 4484] [Loss: 0.16083437204360962]\n",
            "[Iteration: 4485] [Loss: 0.16047926247119904]\n",
            "[Iteration: 4486] [Loss: 0.1597350388765335]\n",
            "[Iteration: 4487] [Loss: 0.17326858639717102]\n",
            "[Iteration: 4488] [Loss: 0.15926191210746765]\n",
            "[Iteration: 4489] [Loss: 0.1548611968755722]\n",
            "[Iteration: 4490] [Loss: 0.15815110504627228]\n",
            "[Iteration: 4491] [Loss: 0.16486036777496338]\n",
            "[Iteration: 4492] [Loss: 0.17947392165660858]\n",
            "[Iteration: 4493] [Loss: 0.14334741234779358]\n",
            "[Iteration: 4494] [Loss: 0.16815227270126343]\n",
            "[Iteration: 4495] [Loss: 0.14677855372428894]\n",
            "[Iteration: 4496] [Loss: 0.1325170248746872]\n",
            "[Iteration: 4497] [Loss: 0.16504248976707458]\n",
            "[Iteration: 4498] [Loss: 0.16812103986740112]\n",
            "[Iteration: 4499] [Loss: 0.17776605486869812]\n",
            "[Iteration: 4500] [Loss: 0.15743988752365112]\n",
            "[Iteration: 4501] [Loss: 0.14146697521209717]\n",
            "[Iteration: 4502] [Loss: 0.15551364421844482]\n",
            "[Iteration: 4503] [Loss: 0.16543230414390564]\n",
            "[Iteration: 4504] [Loss: 0.16093255579471588]\n",
            "[Iteration: 4505] [Loss: 0.17464612424373627]\n",
            "[Iteration: 4506] [Loss: 0.165157750248909]\n",
            "[Iteration: 4507] [Loss: 0.15799224376678467]\n",
            "[Iteration: 4508] [Loss: 0.14623968303203583]\n",
            "[Iteration: 4509] [Loss: 0.14825083315372467]\n",
            "[Iteration: 4510] [Loss: 0.18701063096523285]\n",
            "[Iteration: 4511] [Loss: 0.14239387214183807]\n",
            "[Iteration: 4512] [Loss: 0.14232170581817627]\n",
            "[Iteration: 4513] [Loss: 0.1459272801876068]\n",
            "[Iteration: 4514] [Loss: 0.15807059407234192]\n",
            "[Iteration: 4515] [Loss: 0.1560298055410385]\n",
            "[Iteration: 4516] [Loss: 0.1681796759366989]\n",
            "[Iteration: 4517] [Loss: 0.1517956405878067]\n",
            "[Iteration: 4518] [Loss: 0.1734877973794937]\n",
            "[Iteration: 4519] [Loss: 0.16245165467262268]\n",
            "[Iteration: 4520] [Loss: 0.1465991586446762]\n",
            "[Iteration: 4521] [Loss: 0.14821027219295502]\n",
            "[Iteration: 4522] [Loss: 0.19880063831806183]\n",
            "[Iteration: 4523] [Loss: 0.13641387224197388]\n",
            "[Iteration: 4524] [Loss: 0.14691002666950226]\n",
            "[Iteration: 4525] [Loss: 0.1790306568145752]\n",
            "[Iteration: 4526] [Loss: 0.16938187181949615]\n",
            "[Iteration: 4527] [Loss: 0.15565262734889984]\n",
            "[Iteration: 4528] [Loss: 0.16729599237442017]\n",
            "[Iteration: 4529] [Loss: 0.16333767771720886]\n",
            "[Iteration: 4530] [Loss: 0.15999668836593628]\n",
            "[Iteration: 4531] [Loss: 0.15476083755493164]\n",
            "[Iteration: 4532] [Loss: 0.16465048491954803]\n",
            "[Iteration: 4533] [Loss: 0.14938823878765106]\n",
            "[Iteration: 4534] [Loss: 0.1650085747241974]\n",
            "[Iteration: 4535] [Loss: 0.15113599598407745]\n",
            "[Iteration: 4536] [Loss: 0.16172832250595093]\n",
            "[Iteration: 4537] [Loss: 0.15384283661842346]\n",
            "[Iteration: 4538] [Loss: 0.15191885828971863]\n",
            "[Iteration: 4539] [Loss: 0.14496846497058868]\n",
            "[Iteration: 4540] [Loss: 0.15815061330795288]\n",
            "[Iteration: 4541] [Loss: 0.190111443400383]\n",
            "[Iteration: 4542] [Loss: 0.17334121465682983]\n",
            "[Iteration: 4543] [Loss: 0.1488388478755951]\n",
            "[Iteration: 4544] [Loss: 0.1483757197856903]\n",
            "[Iteration: 4545] [Loss: 0.16149967908859253]\n",
            "[Iteration: 4546] [Loss: 0.17125771939754486]\n",
            "[Iteration: 4547] [Loss: 0.16282124817371368]\n",
            "[Iteration: 4548] [Loss: 0.1627034842967987]\n",
            "[Iteration: 4549] [Loss: 0.17105630040168762]\n",
            "[Iteration: 4550] [Loss: 0.14286433160305023]\n",
            "[Iteration: 4551] [Loss: 0.1482173353433609]\n",
            "[Iteration: 4552] [Loss: 0.13854867219924927]\n",
            "[Iteration: 4553] [Loss: 0.1734960824251175]\n",
            "[Iteration: 4554] [Loss: 0.1604587435722351]\n",
            "[Iteration: 4555] [Loss: 0.14278072118759155]\n",
            "[Iteration: 4556] [Loss: 0.1637883186340332]\n",
            "[Iteration: 4557] [Loss: 0.17929020524024963]\n",
            "[Iteration: 4558] [Loss: 0.13922880589962006]\n",
            "[Iteration: 4559] [Loss: 0.16864798963069916]\n",
            "[Iteration: 4560] [Loss: 0.13733385503292084]\n",
            "[Iteration: 4561] [Loss: 0.17037013173103333]\n",
            "[Iteration: 4562] [Loss: 0.14770886301994324]\n",
            "[Iteration: 4563] [Loss: 0.16243652999401093]\n",
            "[Iteration: 4564] [Loss: 0.14362257719039917]\n",
            "[Iteration: 4565] [Loss: 0.15956705808639526]\n",
            "[Iteration: 4566] [Loss: 0.1569889783859253]\n",
            "[Iteration: 4567] [Loss: 0.157868430018425]\n",
            "[Iteration: 4568] [Loss: 0.1558683067560196]\n",
            "[Iteration: 4569] [Loss: 0.15797850489616394]\n",
            "[Iteration: 4570] [Loss: 0.1628398299217224]\n",
            "[Iteration: 4571] [Loss: 0.15923099219799042]\n",
            "[Iteration: 4572] [Loss: 0.15914596617221832]\n",
            "[Iteration: 4573] [Loss: 0.1620841771364212]\n",
            "[Iteration: 4574] [Loss: 0.1737346053123474]\n",
            "[Iteration: 4575] [Loss: 0.1659833937883377]\n",
            "[Iteration: 4576] [Loss: 0.16431201994419098]\n",
            "[Iteration: 4577] [Loss: 0.13260234892368317]\n",
            "[Iteration: 4578] [Loss: 0.17514361441135406]\n",
            "[Iteration: 4579] [Loss: 0.15488837659358978]\n",
            "[Iteration: 4580] [Loss: 0.1692628264427185]\n",
            "[Iteration: 4581] [Loss: 0.1746472418308258]\n",
            "[Iteration: 4582] [Loss: 0.1493820995092392]\n",
            "[Iteration: 4583] [Loss: 0.15262919664382935]\n",
            "[Iteration: 4584] [Loss: 0.15352977812290192]\n",
            "[Iteration: 4585] [Loss: 0.1553235650062561]\n",
            "[Iteration: 4586] [Loss: 0.17129570245742798]\n",
            "[Iteration: 4587] [Loss: 0.15847966074943542]\n",
            "[Iteration: 4588] [Loss: 0.15452682971954346]\n",
            "[Iteration: 4589] [Loss: 0.13553005456924438]\n",
            "[Iteration: 4590] [Loss: 0.15364496409893036]\n",
            "[Iteration: 4591] [Loss: 0.18350541591644287]\n",
            "[Iteration: 4592] [Loss: 0.15792721509933472]\n",
            "[Iteration: 4593] [Loss: 0.15472836792469025]\n",
            "[Iteration: 4594] [Loss: 0.17527250945568085]\n",
            "[Iteration: 4595] [Loss: 0.17536622285842896]\n",
            "[Iteration: 4596] [Loss: 0.1563539355993271]\n",
            "[Iteration: 4597] [Loss: 0.16620692610740662]\n",
            "[Iteration: 4598] [Loss: 0.15519525110721588]\n",
            "[Iteration: 4599] [Loss: 0.17080707848072052]\n",
            "[Iteration: 4600] [Loss: 0.15270648896694183]\n",
            "[Iteration: 4601] [Loss: 0.1532350480556488]\n",
            "[Iteration: 4602] [Loss: 0.16290992498397827]\n",
            "[Iteration: 4603] [Loss: 0.14040866494178772]\n",
            "[Iteration: 4604] [Loss: 0.16757602989673615]\n",
            "[Iteration: 4605] [Loss: 0.15669474005699158]\n",
            "[Iteration: 4606] [Loss: 0.15231835842132568]\n",
            "[Iteration: 4607] [Loss: 0.17063727974891663]\n",
            "[Iteration: 4608] [Loss: 0.16734322905540466]\n",
            "[Iteration: 4609] [Loss: 0.14516779780387878]\n",
            "[Iteration: 4610] [Loss: 0.13984499871730804]\n",
            "[Iteration: 4611] [Loss: 0.17067886888980865]\n",
            "[Iteration: 4612] [Loss: 0.14785397052764893]\n",
            "[Iteration: 4613] [Loss: 0.14238061010837555]\n",
            "[Iteration: 4614] [Loss: 0.15353642404079437]\n",
            "[Iteration: 4615] [Loss: 0.15601679682731628]\n",
            "[Iteration: 4616] [Loss: 0.14793114364147186]\n",
            "[Iteration: 4617] [Loss: 0.15774281322956085]\n",
            "[Iteration: 4618] [Loss: 0.15382903814315796]\n",
            "[Iteration: 4619] [Loss: 0.15073184669017792]\n",
            "[Iteration: 4620] [Loss: 0.169586181640625]\n",
            "[Iteration: 4621] [Loss: 0.1464247703552246]\n",
            "[Iteration: 4622] [Loss: 0.1597118079662323]\n",
            "[Iteration: 4623] [Loss: 0.14163869619369507]\n",
            "[Iteration: 4624] [Loss: 0.16190844774246216]\n",
            "[Iteration: 4625] [Loss: 0.16191525757312775]\n",
            "[Iteration: 4626] [Loss: 0.15125077962875366]\n",
            "[Iteration: 4627] [Loss: 0.1700780987739563]\n",
            "[Iteration: 4628] [Loss: 0.1550786793231964]\n",
            "[Iteration: 4629] [Loss: 0.14234226942062378]\n",
            "[Iteration: 4630] [Loss: 0.1405540108680725]\n",
            "[Iteration: 4631] [Loss: 0.1699519157409668]\n",
            "[Iteration: 4632] [Loss: 0.14416277408599854]\n",
            "[Iteration: 4633] [Loss: 0.16333025693893433]\n",
            "[Iteration: 4634] [Loss: 0.1586974710226059]\n",
            "[Iteration: 4635] [Loss: 0.12920746207237244]\n",
            "[Iteration: 4636] [Loss: 0.14110451936721802]\n",
            "[Iteration: 4637] [Loss: 0.1744520515203476]\n",
            "[Iteration: 4638] [Loss: 0.142175555229187]\n",
            "[Iteration: 4639] [Loss: 0.14739754796028137]\n",
            "[Iteration: 4640] [Loss: 0.15626341104507446]\n",
            "[Iteration: 4641] [Loss: 0.14374706149101257]\n",
            "[Iteration: 4642] [Loss: 0.15252861380577087]\n",
            "[Iteration: 4643] [Loss: 0.1612788736820221]\n",
            "[Iteration: 4644] [Loss: 0.14721883833408356]\n",
            "[Iteration: 4645] [Loss: 0.17628048360347748]\n",
            "[Iteration: 4646] [Loss: 0.14574800431728363]\n",
            "[Iteration: 4647] [Loss: 0.13871632516384125]\n",
            "[Iteration: 4648] [Loss: 0.15516966581344604]\n",
            "[Iteration: 4649] [Loss: 0.14173457026481628]\n",
            "[Iteration: 4650] [Loss: 0.1703992486000061]\n",
            "[Iteration: 4651] [Loss: 0.16615070402622223]\n",
            "[Iteration: 4652] [Loss: 0.1706984043121338]\n",
            "[Iteration: 4653] [Loss: 0.1561262011528015]\n",
            "[Iteration: 4654] [Loss: 0.1631225198507309]\n",
            "[Iteration: 4655] [Loss: 0.15218029916286469]\n",
            "[Iteration: 4656] [Loss: 0.1435786336660385]\n",
            "[Iteration: 4657] [Loss: 0.15128162503242493]\n",
            "[Iteration: 4658] [Loss: 0.16150805354118347]\n",
            "[Iteration: 4659] [Loss: 0.17420735955238342]\n",
            "[Iteration: 4660] [Loss: 0.16427704691886902]\n",
            "[Iteration: 4661] [Loss: 0.15294915437698364]\n",
            "[Iteration: 4662] [Loss: 0.17661292850971222]\n",
            "[Iteration: 4663] [Loss: 0.13284534215927124]\n",
            "[Iteration: 4664] [Loss: 0.1410863697528839]\n",
            "[Iteration: 4665] [Loss: 0.14762365818023682]\n",
            "[Iteration: 4666] [Loss: 0.12567485868930817]\n",
            "[Iteration: 4667] [Loss: 0.1523265391588211]\n",
            "[Iteration: 4668] [Loss: 0.15502606332302094]\n",
            "[Iteration: 4669] [Loss: 0.15691930055618286]\n",
            "[Iteration: 4670] [Loss: 0.1636885702610016]\n",
            "[Iteration: 4671] [Loss: 0.17519870400428772]\n",
            "[Iteration: 4672] [Loss: 0.1667432188987732]\n",
            "[Iteration: 4673] [Loss: 0.18020419776439667]\n",
            "[Iteration: 4674] [Loss: 0.1582794338464737]\n",
            "[Iteration: 4675] [Loss: 0.16920006275177002]\n",
            "[Iteration: 4676] [Loss: 0.13136233389377594]\n",
            "[Iteration: 4677] [Loss: 0.15737365186214447]\n",
            "[Iteration: 4678] [Loss: 0.16007904708385468]\n",
            "[Iteration: 4679] [Loss: 0.15421980619430542]\n",
            "[Iteration: 4680] [Loss: 0.1457275152206421]\n",
            "[Iteration: 4681] [Loss: 0.1634385585784912]\n",
            "[Iteration: 4682] [Loss: 0.16912370920181274]\n",
            "[Iteration: 4683] [Loss: 0.16779851913452148]\n",
            "[Iteration: 4684] [Loss: 0.14694833755493164]\n",
            "[Iteration: 4685] [Loss: 0.14754718542099]\n",
            "[Iteration: 4686] [Loss: 0.15715357661247253]\n",
            "[Iteration: 4687] [Loss: 0.15265876054763794]\n",
            "[Iteration: 4688] [Loss: 0.17378105223178864]\n",
            "[Iteration: 4689] [Loss: 0.14095646142959595]\n",
            "[Iteration: 4690] [Loss: 0.17235788702964783]\n",
            "[Iteration: 4691] [Loss: 0.1618833988904953]\n",
            "[Iteration: 4692] [Loss: 0.15917830169200897]\n",
            "[Iteration: 4693] [Loss: 0.13559120893478394]\n",
            "[Iteration: 4694] [Loss: 0.16560585796833038]\n",
            "[Iteration: 4695] [Loss: 0.1680586338043213]\n",
            "[Iteration: 4696] [Loss: 0.13607607781887054]\n",
            "[Iteration: 4697] [Loss: 0.14950516819953918]\n",
            "[Iteration: 4698] [Loss: 0.15873879194259644]\n",
            "[Iteration: 4699] [Loss: 0.14353129267692566]\n",
            "[Iteration: 4700] [Loss: 0.14661604166030884]\n",
            "[Iteration: 4701] [Loss: 0.13789409399032593]\n",
            "[Iteration: 4702] [Loss: 0.141203835606575]\n",
            "[Iteration: 4703] [Loss: 0.14969569444656372]\n",
            "[Iteration: 4704] [Loss: 0.15276125073432922]\n",
            "[Iteration: 4705] [Loss: 0.163964182138443]\n",
            "[Iteration: 4706] [Loss: 0.18635044991970062]\n",
            "[Iteration: 4707] [Loss: 0.13015133142471313]\n",
            "[Iteration: 4708] [Loss: 0.1556575894355774]\n",
            "[Iteration: 4709] [Loss: 0.14677537977695465]\n",
            "[Iteration: 4710] [Loss: 0.16360197961330414]\n",
            "[Iteration: 4711] [Loss: 0.16046904027462006]\n",
            "[Iteration: 4712] [Loss: 0.1405181884765625]\n",
            "[Iteration: 4713] [Loss: 0.15074065327644348]\n",
            "[Iteration: 4714] [Loss: 0.16585825383663177]\n",
            "[Iteration: 4715] [Loss: 0.15937663614749908]\n",
            "[Iteration: 4716] [Loss: 0.1747547835111618]\n",
            "[Iteration: 4717] [Loss: 0.14673081040382385]\n",
            "[Iteration: 4718] [Loss: 0.1486775279045105]\n",
            "[Iteration: 4719] [Loss: 0.15452377498149872]\n",
            "[Iteration: 4720] [Loss: 0.1568201333284378]\n",
            "[Iteration: 4721] [Loss: 0.14804229140281677]\n",
            "[Iteration: 4722] [Loss: 0.15293912589550018]\n",
            "[Iteration: 4723] [Loss: 0.15885567665100098]\n",
            "[Iteration: 4724] [Loss: 0.15957596898078918]\n",
            "[Iteration: 4725] [Loss: 0.16909414529800415]\n",
            "[Iteration: 4726] [Loss: 0.17083650827407837]\n",
            "[Iteration: 4727] [Loss: 0.15038155019283295]\n",
            "[Iteration: 4728] [Loss: 0.15325132012367249]\n",
            "[Iteration: 4729] [Loss: 0.15608741343021393]\n",
            "[Iteration: 4730] [Loss: 0.1474267840385437]\n",
            "[Iteration: 4731] [Loss: 0.150486022233963]\n",
            "[Iteration: 4732] [Loss: 0.13851207494735718]\n",
            "[Iteration: 4733] [Loss: 0.1676737666130066]\n",
            "[Iteration: 4734] [Loss: 0.15696702897548676]\n",
            "[Iteration: 4735] [Loss: 0.12408316135406494]\n",
            "[Iteration: 4736] [Loss: 0.1724511831998825]\n",
            "[Iteration: 4737] [Loss: 0.154276043176651]\n",
            "[Iteration: 4738] [Loss: 0.16406185925006866]\n",
            "[Iteration: 4739] [Loss: 0.16183152794837952]\n",
            "[Iteration: 4740] [Loss: 0.15385791659355164]\n",
            "[Iteration: 4741] [Loss: 0.14617769420146942]\n",
            "[Iteration: 4742] [Loss: 0.15694135427474976]\n",
            "[Iteration: 4743] [Loss: 0.15681074559688568]\n",
            "[Iteration: 4744] [Loss: 0.15160562098026276]\n",
            "[Iteration: 4745] [Loss: 0.14356642961502075]\n",
            "[Iteration: 4746] [Loss: 0.13086819648742676]\n",
            "[Iteration: 4747] [Loss: 0.1347147673368454]\n",
            "[Iteration: 4748] [Loss: 0.13904285430908203]\n",
            "[Iteration: 4749] [Loss: 0.1547965407371521]\n",
            "[Iteration: 4750] [Loss: 0.1770964115858078]\n",
            "[Iteration: 4751] [Loss: 0.14759472012519836]\n",
            "[Iteration: 4752] [Loss: 0.14386534690856934]\n",
            "[Iteration: 4753] [Loss: 0.16328199207782745]\n",
            "[Iteration: 4754] [Loss: 0.1475430727005005]\n",
            "[Iteration: 4755] [Loss: 0.1397298127412796]\n",
            "[Iteration: 4756] [Loss: 0.12533625960350037]\n",
            "[Iteration: 4757] [Loss: 0.14182768762111664]\n",
            "[Iteration: 4758] [Loss: 0.18712083995342255]\n",
            "[Iteration: 4759] [Loss: 0.1458946168422699]\n",
            "[Iteration: 4760] [Loss: 0.14497245848178864]\n",
            "[Iteration: 4761] [Loss: 0.12976022064685822]\n",
            "[Iteration: 4762] [Loss: 0.16622349619865417]\n",
            "[Iteration: 4763] [Loss: 0.14326144754886627]\n",
            "[Iteration: 4764] [Loss: 0.1486349254846573]\n",
            "[Iteration: 4765] [Loss: 0.15372200310230255]\n",
            "[Iteration: 4766] [Loss: 0.1237666979432106]\n",
            "[Iteration: 4767] [Loss: 0.14832761883735657]\n",
            "[Iteration: 4768] [Loss: 0.14651936292648315]\n",
            "[Iteration: 4769] [Loss: 0.16573616862297058]\n",
            "[Iteration: 4770] [Loss: 0.15222448110580444]\n",
            "[Iteration: 4771] [Loss: 0.1692960113286972]\n",
            "[Iteration: 4772] [Loss: 0.16668231785297394]\n",
            "[Iteration: 4773] [Loss: 0.15604761242866516]\n",
            "[Iteration: 4774] [Loss: 0.151079922914505]\n",
            "[Iteration: 4775] [Loss: 0.15294700860977173]\n",
            "[Iteration: 4776] [Loss: 0.17677153646945953]\n",
            "[Iteration: 4777] [Loss: 0.16151303052902222]\n",
            "[Iteration: 4778] [Loss: 0.15161320567131042]\n",
            "[Iteration: 4779] [Loss: 0.1589796245098114]\n",
            "[Iteration: 4780] [Loss: 0.1496850699186325]\n",
            "[Iteration: 4781] [Loss: 0.15239542722702026]\n",
            "[Iteration: 4782] [Loss: 0.14826637506484985]\n",
            "[Iteration: 4783] [Loss: 0.16575652360916138]\n",
            "[Iteration: 4784] [Loss: 0.15551084280014038]\n",
            "[Iteration: 4785] [Loss: 0.15473566949367523]\n",
            "[Iteration: 4786] [Loss: 0.14435070753097534]\n",
            "[Iteration: 4787] [Loss: 0.15828366577625275]\n",
            "[Iteration: 4788] [Loss: 0.16907909512519836]\n",
            "[Iteration: 4789] [Loss: 0.1490386426448822]\n",
            "[Iteration: 4790] [Loss: 0.13012737035751343]\n",
            "[Iteration: 4791] [Loss: 0.14327335357666016]\n",
            "[Iteration: 4792] [Loss: 0.16670149564743042]\n",
            "[Iteration: 4793] [Loss: 0.15624207258224487]\n",
            "[Iteration: 4794] [Loss: 0.16214968264102936]\n",
            "[Iteration: 4795] [Loss: 0.12756726145744324]\n",
            "[Iteration: 4796] [Loss: 0.13810977339744568]\n",
            "[Iteration: 4797] [Loss: 0.15726029872894287]\n",
            "[Iteration: 4798] [Loss: 0.1431093066930771]\n",
            "[Iteration: 4799] [Loss: 0.18578748404979706]\n",
            "[Iteration: 4800] [Loss: 0.14348866045475006]\n",
            "[Iteration: 4801] [Loss: 0.18456333875656128]\n",
            "[Iteration: 4802] [Loss: 0.1530996561050415]\n",
            "[Iteration: 4803] [Loss: 0.15556713938713074]\n",
            "[Iteration: 4804] [Loss: 0.1570175439119339]\n",
            "[Iteration: 4805] [Loss: 0.1388290375471115]\n",
            "[Iteration: 4806] [Loss: 0.15121550858020782]\n",
            "[Iteration: 4807] [Loss: 0.15748608112335205]\n",
            "[Iteration: 4808] [Loss: 0.1587548404932022]\n",
            "[Iteration: 4809] [Loss: 0.12613216042518616]\n",
            "[Iteration: 4810] [Loss: 0.16235844790935516]\n",
            "[Iteration: 4811] [Loss: 0.17098881304264069]\n",
            "[Iteration: 4812] [Loss: 0.15933848917484283]\n",
            "[Iteration: 4813] [Loss: 0.14683984220027924]\n",
            "[Iteration: 4814] [Loss: 0.16093529760837555]\n",
            "[Iteration: 4815] [Loss: 0.15699182450771332]\n",
            "[Iteration: 4816] [Loss: 0.14530538022518158]\n",
            "[Iteration: 4817] [Loss: 0.13537928462028503]\n",
            "[Iteration: 4818] [Loss: 0.1370704621076584]\n",
            "[Iteration: 4819] [Loss: 0.14923757314682007]\n",
            "[Iteration: 4820] [Loss: 0.17194116115570068]\n",
            "[Iteration: 4821] [Loss: 0.14355066418647766]\n",
            "[Iteration: 4822] [Loss: 0.1348915845155716]\n",
            "[Iteration: 4823] [Loss: 0.14558729529380798]\n",
            "[Iteration: 4824] [Loss: 0.1464952975511551]\n",
            "[Iteration: 4825] [Loss: 0.15911374986171722]\n",
            "[Iteration: 4826] [Loss: 0.159560889005661]\n",
            "[Iteration: 4827] [Loss: 0.1452765166759491]\n",
            "[Iteration: 4828] [Loss: 0.16954271495342255]\n",
            "[Iteration: 4829] [Loss: 0.15500231087207794]\n",
            "[Iteration: 4830] [Loss: 0.17444077134132385]\n",
            "[Iteration: 4831] [Loss: 0.14982445538043976]\n",
            "[Iteration: 4832] [Loss: 0.1387196183204651]\n",
            "[Iteration: 4833] [Loss: 0.15879155695438385]\n",
            "[Iteration: 4834] [Loss: 0.1589905172586441]\n",
            "[Iteration: 4835] [Loss: 0.146348774433136]\n",
            "[Iteration: 4836] [Loss: 0.1935925930738449]\n",
            "[Iteration: 4837] [Loss: 0.15488648414611816]\n",
            "[Iteration: 4838] [Loss: 0.1424243003129959]\n",
            "[Iteration: 4839] [Loss: 0.14962756633758545]\n",
            "[Iteration: 4840] [Loss: 0.15654996037483215]\n",
            "[Iteration: 4841] [Loss: 0.15748435258865356]\n",
            "[Iteration: 4842] [Loss: 0.15026134252548218]\n",
            "[Iteration: 4843] [Loss: 0.1514137238264084]\n",
            "[Iteration: 4844] [Loss: 0.14859497547149658]\n",
            "[Iteration: 4845] [Loss: 0.14286279678344727]\n",
            "[Iteration: 4846] [Loss: 0.1411917358636856]\n",
            "[Iteration: 4847] [Loss: 0.15387943387031555]\n",
            "[Iteration: 4848] [Loss: 0.16854412853717804]\n",
            "[Iteration: 4849] [Loss: 0.16143684089183807]\n",
            "[Iteration: 4850] [Loss: 0.14922450482845306]\n",
            "[Iteration: 4851] [Loss: 0.13442999124526978]\n",
            "[Iteration: 4852] [Loss: 0.13187818229198456]\n",
            "[Iteration: 4853] [Loss: 0.14927025139331818]\n",
            "[Iteration: 4854] [Loss: 0.1540321409702301]\n",
            "[Iteration: 4855] [Loss: 0.14742346107959747]\n",
            "[Iteration: 4856] [Loss: 0.15198440849781036]\n",
            "[Iteration: 4857] [Loss: 0.13721810281276703]\n",
            "[Iteration: 4858] [Loss: 0.15466302633285522]\n",
            "[Iteration: 4859] [Loss: 0.16219571232795715]\n",
            "[Iteration: 4860] [Loss: 0.13930299878120422]\n",
            "[Iteration: 4861] [Loss: 0.16095560789108276]\n",
            "[Iteration: 4862] [Loss: 0.1564026176929474]\n",
            "[Iteration: 4863] [Loss: 0.14323432743549347]\n",
            "[Iteration: 4864] [Loss: 0.14502021670341492]\n",
            "[Iteration: 4865] [Loss: 0.16248877346515656]\n",
            "[Iteration: 4866] [Loss: 0.14577801525592804]\n",
            "[Iteration: 4867] [Loss: 0.15540069341659546]\n",
            "[Iteration: 4868] [Loss: 0.13517606258392334]\n",
            "[Iteration: 4869] [Loss: 0.14897984266281128]\n",
            "[Iteration: 4870] [Loss: 0.16963933408260345]\n",
            "[Iteration: 4871] [Loss: 0.15122003853321075]\n",
            "[Iteration: 4872] [Loss: 0.1362641453742981]\n",
            "[Iteration: 4873] [Loss: 0.16180112957954407]\n",
            "[Iteration: 4874] [Loss: 0.13465231657028198]\n",
            "[Iteration: 4875] [Loss: 0.16630546748638153]\n",
            "[Iteration: 4876] [Loss: 0.1551864594221115]\n",
            "[Iteration: 4877] [Loss: 0.1663580685853958]\n",
            "[Iteration: 4878] [Loss: 0.13626697659492493]\n",
            "[Iteration: 4879] [Loss: 0.1699027121067047]\n",
            "[Iteration: 4880] [Loss: 0.15096136927604675]\n",
            "[Iteration: 4881] [Loss: 0.1786838173866272]\n",
            "[Iteration: 4882] [Loss: 0.16336648166179657]\n",
            "[Iteration: 4883] [Loss: 0.15028120577335358]\n",
            "[Iteration: 4884] [Loss: 0.1479620337486267]\n",
            "[Iteration: 4885] [Loss: 0.1587873101234436]\n",
            "[Iteration: 4886] [Loss: 0.14462943375110626]\n",
            "[Iteration: 4887] [Loss: 0.14071381092071533]\n",
            "[Iteration: 4888] [Loss: 0.1567430943250656]\n",
            "[Iteration: 4889] [Loss: 0.1506361961364746]\n",
            "[Iteration: 4890] [Loss: 0.14023327827453613]\n",
            "[Iteration: 4891] [Loss: 0.15139174461364746]\n",
            "[Iteration: 4892] [Loss: 0.16506072878837585]\n",
            "[Iteration: 4893] [Loss: 0.13319489359855652]\n",
            "[Iteration: 4894] [Loss: 0.15765349566936493]\n",
            "[Iteration: 4895] [Loss: 0.1235344409942627]\n",
            "[Iteration: 4896] [Loss: 0.15058599412441254]\n",
            "[Iteration: 4897] [Loss: 0.16122502088546753]\n",
            "[Iteration: 4898] [Loss: 0.16166605055332184]\n",
            "[Iteration: 4899] [Loss: 0.15933680534362793]\n",
            "[Iteration: 4900] [Loss: 0.1313706338405609]\n",
            "[Iteration: 4901] [Loss: 0.15816915035247803]\n",
            "[Iteration: 4902] [Loss: 0.17692162096500397]\n",
            "[Iteration: 4903] [Loss: 0.14320164918899536]\n",
            "[Iteration: 4904] [Loss: 0.16801339387893677]\n",
            "[Iteration: 4905] [Loss: 0.1795300841331482]\n",
            "[Iteration: 4906] [Loss: 0.1479257345199585]\n",
            "[Iteration: 4907] [Loss: 0.15872862935066223]\n",
            "[Iteration: 4908] [Loss: 0.14249764382839203]\n",
            "[Iteration: 4909] [Loss: 0.14301973581314087]\n",
            "[Iteration: 4910] [Loss: 0.1576196253299713]\n",
            "[Iteration: 4911] [Loss: 0.15589173138141632]\n",
            "[Iteration: 4912] [Loss: 0.14960721135139465]\n",
            "[Iteration: 4913] [Loss: 0.1617143601179123]\n",
            "[Iteration: 4914] [Loss: 0.13567335903644562]\n",
            "[Iteration: 4915] [Loss: 0.14419907331466675]\n",
            "[Iteration: 4916] [Loss: 0.1380583643913269]\n",
            "[Iteration: 4917] [Loss: 0.1530965268611908]\n",
            "[Iteration: 4918] [Loss: 0.1402934044599533]\n",
            "[Iteration: 4919] [Loss: 0.1418820023536682]\n",
            "[Iteration: 4920] [Loss: 0.15280386805534363]\n",
            "[Iteration: 4921] [Loss: 0.1451239436864853]\n",
            "[Iteration: 4922] [Loss: 0.13220636546611786]\n",
            "[Iteration: 4923] [Loss: 0.15620268881320953]\n",
            "[Iteration: 4924] [Loss: 0.11737016588449478]\n",
            "[Iteration: 4925] [Loss: 0.14616946876049042]\n",
            "[Iteration: 4926] [Loss: 0.15014809370040894]\n",
            "[Iteration: 4927] [Loss: 0.1457429975271225]\n",
            "[Iteration: 4928] [Loss: 0.15474967658519745]\n",
            "[Iteration: 4929] [Loss: 0.15792429447174072]\n",
            "[Iteration: 4930] [Loss: 0.1356637179851532]\n",
            "[Iteration: 4931] [Loss: 0.15604260563850403]\n",
            "[Iteration: 4932] [Loss: 0.14740091562271118]\n",
            "[Iteration: 4933] [Loss: 0.13735811412334442]\n",
            "[Iteration: 4934] [Loss: 0.14081911742687225]\n",
            "[Iteration: 4935] [Loss: 0.13983803987503052]\n",
            "[Iteration: 4936] [Loss: 0.14405080676078796]\n",
            "[Iteration: 4937] [Loss: 0.14892370998859406]\n",
            "[Iteration: 4938] [Loss: 0.15186937153339386]\n",
            "[Iteration: 4939] [Loss: 0.1734181046485901]\n",
            "[Iteration: 4940] [Loss: 0.1476687639951706]\n",
            "[Iteration: 4941] [Loss: 0.16348598897457123]\n",
            "[Iteration: 4942] [Loss: 0.16602295637130737]\n",
            "[Iteration: 4943] [Loss: 0.151844322681427]\n",
            "[Iteration: 4944] [Loss: 0.17204596102237701]\n",
            "[Iteration: 4945] [Loss: 0.13832199573516846]\n",
            "[Iteration: 4946] [Loss: 0.14242500066757202]\n",
            "[Iteration: 4947] [Loss: 0.15441720187664032]\n",
            "[Iteration: 4948] [Loss: 0.14011268317699432]\n",
            "[Iteration: 4949] [Loss: 0.14040729403495789]\n",
            "[Iteration: 4950] [Loss: 0.16429974138736725]\n",
            "[Iteration: 4951] [Loss: 0.14504438638687134]\n",
            "[Iteration: 4952] [Loss: 0.13896580040454865]\n",
            "[Iteration: 4953] [Loss: 0.1403791606426239]\n",
            "[Iteration: 4954] [Loss: 0.12903156876564026]\n",
            "[Iteration: 4955] [Loss: 0.1528899371623993]\n",
            "[Iteration: 4956] [Loss: 0.14599895477294922]\n",
            "[Iteration: 4957] [Loss: 0.14766669273376465]\n",
            "[Iteration: 4958] [Loss: 0.15233637392520905]\n",
            "[Iteration: 4959] [Loss: 0.1389947235584259]\n",
            "[Iteration: 4960] [Loss: 0.1521109640598297]\n",
            "[Iteration: 4961] [Loss: 0.13191555440425873]\n",
            "[Iteration: 4962] [Loss: 0.1437000185251236]\n",
            "[Iteration: 4963] [Loss: 0.14279896020889282]\n",
            "[Iteration: 4964] [Loss: 0.179940328001976]\n",
            "[Iteration: 4965] [Loss: 0.15982788801193237]\n",
            "[Iteration: 4966] [Loss: 0.13983555138111115]\n",
            "[Iteration: 4967] [Loss: 0.16337326169013977]\n",
            "[Iteration: 4968] [Loss: 0.15817411243915558]\n",
            "[Iteration: 4969] [Loss: 0.15272727608680725]\n",
            "[Iteration: 4970] [Loss: 0.15385572612285614]\n",
            "[Iteration: 4971] [Loss: 0.1370980143547058]\n",
            "[Iteration: 4972] [Loss: 0.16986754536628723]\n",
            "[Iteration: 4973] [Loss: 0.15555641055107117]\n",
            "[Iteration: 4974] [Loss: 0.1248575821518898]\n",
            "[Iteration: 4975] [Loss: 0.13698281347751617]\n",
            "[Iteration: 4976] [Loss: 0.1420208364725113]\n",
            "[Iteration: 4977] [Loss: 0.14604541659355164]\n",
            "[Iteration: 4978] [Loss: 0.1364271193742752]\n",
            "[Iteration: 4979] [Loss: 0.1443166732788086]\n",
            "[Iteration: 4980] [Loss: 0.15680742263793945]\n",
            "[Iteration: 4981] [Loss: 0.17322194576263428]\n",
            "[Iteration: 4982] [Loss: 0.13743455708026886]\n",
            "[Iteration: 4983] [Loss: 0.14993160963058472]\n",
            "[Iteration: 4984] [Loss: 0.12642957270145416]\n",
            "[Iteration: 4985] [Loss: 0.1539584845304489]\n",
            "[Iteration: 4986] [Loss: 0.16050371527671814]\n",
            "[Iteration: 4987] [Loss: 0.1435866504907608]\n",
            "[Iteration: 4988] [Loss: 0.14592067897319794]\n",
            "[Iteration: 4989] [Loss: 0.1494058221578598]\n",
            "[Iteration: 4990] [Loss: 0.14813607931137085]\n",
            "[Iteration: 4991] [Loss: 0.1420627385377884]\n",
            "[Iteration: 4992] [Loss: 0.1498556137084961]\n",
            "[Iteration: 4993] [Loss: 0.1605965793132782]\n",
            "[Iteration: 4994] [Loss: 0.14888723194599152]\n",
            "[Iteration: 4995] [Loss: 0.16414953768253326]\n",
            "[Iteration: 4996] [Loss: 0.11894175410270691]\n",
            "[Iteration: 4997] [Loss: 0.14070585370063782]\n",
            "[Iteration: 4998] [Loss: 0.14285404980182648]\n",
            "[Iteration: 4999] [Loss: 0.1765226423740387]\n",
            "[Iteration: 5000] [Loss: 0.13408631086349487]\n",
            "[Iteration: 5001] [Loss: 0.1402910351753235]\n",
            "[Iteration: 5002] [Loss: 0.16509953141212463]\n",
            "[Iteration: 5003] [Loss: 0.13389939069747925]\n",
            "[Iteration: 5004] [Loss: 0.16609755158424377]\n",
            "[Iteration: 5005] [Loss: 0.15585054457187653]\n",
            "[Iteration: 5006] [Loss: 0.14303360879421234]\n",
            "[Iteration: 5007] [Loss: 0.13214847445487976]\n",
            "[Iteration: 5008] [Loss: 0.1438915878534317]\n",
            "[Iteration: 5009] [Loss: 0.14271076023578644]\n",
            "[Iteration: 5010] [Loss: 0.13991233706474304]\n",
            "[Iteration: 5011] [Loss: 0.13740965723991394]\n",
            "[Iteration: 5012] [Loss: 0.16402071714401245]\n",
            "[Iteration: 5013] [Loss: 0.12164290994405746]\n",
            "[Iteration: 5014] [Loss: 0.15098905563354492]\n",
            "[Iteration: 5015] [Loss: 0.15480336546897888]\n",
            "[Iteration: 5016] [Loss: 0.14501577615737915]\n",
            "[Iteration: 5017] [Loss: 0.14201410114765167]\n",
            "[Iteration: 5018] [Loss: 0.1338147073984146]\n",
            "[Iteration: 5019] [Loss: 0.1290317177772522]\n",
            "[Iteration: 5020] [Loss: 0.1339285671710968]\n",
            "[Iteration: 5021] [Loss: 0.13101990520954132]\n",
            "[Iteration: 5022] [Loss: 0.15429246425628662]\n",
            "[Iteration: 5023] [Loss: 0.14642326533794403]\n",
            "[Iteration: 5024] [Loss: 0.15592795610427856]\n",
            "[Iteration: 5025] [Loss: 0.1616564840078354]\n",
            "[Iteration: 5026] [Loss: 0.1631215214729309]\n",
            "[Iteration: 5027] [Loss: 0.14042407274246216]\n",
            "[Iteration: 5028] [Loss: 0.14639879763126373]\n",
            "[Iteration: 5029] [Loss: 0.1455126404762268]\n",
            "[Iteration: 5030] [Loss: 0.14127270877361298]\n",
            "[Iteration: 5031] [Loss: 0.1486736536026001]\n",
            "[Iteration: 5032] [Loss: 0.16879817843437195]\n",
            "[Iteration: 5033] [Loss: 0.14236728847026825]\n",
            "[Iteration: 5034] [Loss: 0.14567096531391144]\n",
            "[Iteration: 5035] [Loss: 0.13381345570087433]\n",
            "[Iteration: 5036] [Loss: 0.14729450643062592]\n",
            "[Iteration: 5037] [Loss: 0.15769490599632263]\n",
            "[Iteration: 5038] [Loss: 0.1547899842262268]\n",
            "[Iteration: 5039] [Loss: 0.14217931032180786]\n",
            "[Iteration: 5040] [Loss: 0.1347774714231491]\n",
            "[Iteration: 5041] [Loss: 0.1437469869852066]\n",
            "[Iteration: 5042] [Loss: 0.14862102270126343]\n",
            "[Iteration: 5043] [Loss: 0.14744414389133453]\n",
            "[Iteration: 5044] [Loss: 0.14294439554214478]\n",
            "[Iteration: 5045] [Loss: 0.15024010837078094]\n",
            "[Iteration: 5046] [Loss: 0.16856549680233002]\n",
            "[Iteration: 5047] [Loss: 0.148478701710701]\n",
            "[Iteration: 5048] [Loss: 0.13246645033359528]\n",
            "[Iteration: 5049] [Loss: 0.14258497953414917]\n",
            "[Iteration: 5050] [Loss: 0.15930211544036865]\n",
            "[Iteration: 5051] [Loss: 0.1709599792957306]\n",
            "[Iteration: 5052] [Loss: 0.13073426485061646]\n",
            "[Iteration: 5053] [Loss: 0.13410548865795135]\n",
            "[Iteration: 5054] [Loss: 0.12613394856452942]\n",
            "[Iteration: 5055] [Loss: 0.15843860805034637]\n",
            "[Iteration: 5056] [Loss: 0.14025047421455383]\n",
            "[Iteration: 5057] [Loss: 0.16306422650814056]\n",
            "[Iteration: 5058] [Loss: 0.15030686557292938]\n",
            "[Iteration: 5059] [Loss: 0.13714754581451416]\n",
            "[Iteration: 5060] [Loss: 0.15935018658638]\n",
            "[Iteration: 5061] [Loss: 0.14194715023040771]\n",
            "[Iteration: 5062] [Loss: 0.1594962626695633]\n",
            "[Iteration: 5063] [Loss: 0.14505016803741455]\n",
            "[Iteration: 5064] [Loss: 0.1576344072818756]\n",
            "[Iteration: 5065] [Loss: 0.15312477946281433]\n",
            "[Iteration: 5066] [Loss: 0.13604600727558136]\n",
            "[Iteration: 5067] [Loss: 0.15395618975162506]\n",
            "[Iteration: 5068] [Loss: 0.15435652434825897]\n",
            "[Iteration: 5069] [Loss: 0.15311479568481445]\n",
            "[Iteration: 5070] [Loss: 0.12059179693460464]\n",
            "[Iteration: 5071] [Loss: 0.14938466250896454]\n",
            "[Iteration: 5072] [Loss: 0.1444123238325119]\n",
            "[Iteration: 5073] [Loss: 0.14597289264202118]\n",
            "[Iteration: 5074] [Loss: 0.14400893449783325]\n",
            "[Iteration: 5075] [Loss: 0.13521604239940643]\n",
            "[Iteration: 5076] [Loss: 0.13123798370361328]\n",
            "[Iteration: 5077] [Loss: 0.14238618314266205]\n",
            "[Iteration: 5078] [Loss: 0.14516407251358032]\n",
            "[Iteration: 5079] [Loss: 0.15897639095783234]\n",
            "[Iteration: 5080] [Loss: 0.1585107445716858]\n",
            "[Iteration: 5081] [Loss: 0.14529138803482056]\n",
            "[Iteration: 5082] [Loss: 0.14488156139850616]\n",
            "[Iteration: 5083] [Loss: 0.13789701461791992]\n",
            "[Iteration: 5084] [Loss: 0.1437685191631317]\n",
            "[Iteration: 5085] [Loss: 0.14665699005126953]\n",
            "[Iteration: 5086] [Loss: 0.1443338692188263]\n",
            "[Iteration: 5087] [Loss: 0.15783484280109406]\n",
            "[Iteration: 5088] [Loss: 0.13497453927993774]\n",
            "[Iteration: 5089] [Loss: 0.15826909244060516]\n",
            "[Iteration: 5090] [Loss: 0.1464398056268692]\n",
            "[Iteration: 5091] [Loss: 0.15055593848228455]\n",
            "[Iteration: 5092] [Loss: 0.15649165213108063]\n",
            "[Iteration: 5093] [Loss: 0.11092895269393921]\n",
            "[Iteration: 5094] [Loss: 0.1342262476682663]\n",
            "[Iteration: 5095] [Loss: 0.1394210010766983]\n",
            "[Iteration: 5096] [Loss: 0.14485687017440796]\n",
            "[Iteration: 5097] [Loss: 0.13702069222927094]\n",
            "[Iteration: 5098] [Loss: 0.13530325889587402]\n",
            "[Iteration: 5099] [Loss: 0.18769514560699463]\n",
            "[Iteration: 5100] [Loss: 0.12781742215156555]\n",
            "[Iteration: 5101] [Loss: 0.1491086333990097]\n",
            "[Iteration: 5102] [Loss: 0.15103313326835632]\n",
            "[Iteration: 5103] [Loss: 0.1430993378162384]\n",
            "[Iteration: 5104] [Loss: 0.13361547887325287]\n",
            "[Iteration: 5105] [Loss: 0.14868979156017303]\n",
            "[Iteration: 5106] [Loss: 0.16465789079666138]\n",
            "[Iteration: 5107] [Loss: 0.13167905807495117]\n",
            "[Iteration: 5108] [Loss: 0.16178913414478302]\n",
            "[Iteration: 5109] [Loss: 0.16025133430957794]\n",
            "[Iteration: 5110] [Loss: 0.14345838129520416]\n",
            "[Iteration: 5111] [Loss: 0.14752960205078125]\n",
            "[Iteration: 5112] [Loss: 0.14148610830307007]\n",
            "[Iteration: 5113] [Loss: 0.15491729974746704]\n",
            "[Iteration: 5114] [Loss: 0.14011229574680328]\n",
            "[Iteration: 5115] [Loss: 0.14311714470386505]\n",
            "[Iteration: 5116] [Loss: 0.11976662278175354]\n",
            "[Iteration: 5117] [Loss: 0.14810225367546082]\n",
            "[Iteration: 5118] [Loss: 0.15275780856609344]\n",
            "[Iteration: 5119] [Loss: 0.13944178819656372]\n",
            "[Iteration: 5120] [Loss: 0.14379093050956726]\n",
            "[Iteration: 5121] [Loss: 0.1508636623620987]\n",
            "[Iteration: 5122] [Loss: 0.1715216189622879]\n",
            "[Iteration: 5123] [Loss: 0.17136795818805695]\n",
            "[Iteration: 5124] [Loss: 0.14093127846717834]\n",
            "[Iteration: 5125] [Loss: 0.14888566732406616]\n",
            "[Iteration: 5126] [Loss: 0.14643409848213196]\n",
            "[Iteration: 5127] [Loss: 0.1367897391319275]\n",
            "[Iteration: 5128] [Loss: 0.13068503141403198]\n",
            "[Iteration: 5129] [Loss: 0.1444883793592453]\n",
            "[Iteration: 5130] [Loss: 0.1492341160774231]\n",
            "[Iteration: 5131] [Loss: 0.16597671806812286]\n",
            "[Iteration: 5132] [Loss: 0.15499599277973175]\n",
            "[Iteration: 5133] [Loss: 0.13459572196006775]\n",
            "[Iteration: 5134] [Loss: 0.14870622754096985]\n",
            "[Iteration: 5135] [Loss: 0.1537640392780304]\n",
            "[Iteration: 5136] [Loss: 0.1716349720954895]\n",
            "[Iteration: 5137] [Loss: 0.14301826059818268]\n",
            "[Iteration: 5138] [Loss: 0.15987661480903625]\n",
            "[Iteration: 5139] [Loss: 0.12686824798583984]\n",
            "[Iteration: 5140] [Loss: 0.15569370985031128]\n",
            "[Iteration: 5141] [Loss: 0.14961780607700348]\n",
            "[Iteration: 5142] [Loss: 0.15748527646064758]\n",
            "[Iteration: 5143] [Loss: 0.16310076415538788]\n",
            "[Iteration: 5144] [Loss: 0.16987961530685425]\n",
            "[Iteration: 5145] [Loss: 0.1276143193244934]\n",
            "[Iteration: 5146] [Loss: 0.13583847880363464]\n",
            "[Iteration: 5147] [Loss: 0.1672181785106659]\n",
            "[Iteration: 5148] [Loss: 0.1364145129919052]\n",
            "[Iteration: 5149] [Loss: 0.13472016155719757]\n",
            "[Iteration: 5150] [Loss: 0.13933704793453217]\n",
            "[Iteration: 5151] [Loss: 0.1432906985282898]\n",
            "[Iteration: 5152] [Loss: 0.13514190912246704]\n",
            "[Iteration: 5153] [Loss: 0.16009661555290222]\n",
            "[Iteration: 5154] [Loss: 0.13356496393680573]\n",
            "[Iteration: 5155] [Loss: 0.142813041806221]\n",
            "[Iteration: 5156] [Loss: 0.1415996253490448]\n",
            "[Iteration: 5157] [Loss: 0.13588909804821014]\n",
            "[Iteration: 5158] [Loss: 0.1538698524236679]\n",
            "[Iteration: 5159] [Loss: 0.15470156073570251]\n",
            "[Iteration: 5160] [Loss: 0.14186596870422363]\n",
            "[Iteration: 5161] [Loss: 0.14839306473731995]\n",
            "[Iteration: 5162] [Loss: 0.1352648138999939]\n",
            "[Iteration: 5163] [Loss: 0.15502534806728363]\n",
            "[Iteration: 5164] [Loss: 0.13547280430793762]\n",
            "[Iteration: 5165] [Loss: 0.1396215707063675]\n",
            "[Iteration: 5166] [Loss: 0.1417609602212906]\n",
            "[Iteration: 5167] [Loss: 0.11580969393253326]\n",
            "[Iteration: 5168] [Loss: 0.15557989478111267]\n",
            "[Iteration: 5169] [Loss: 0.14193832874298096]\n",
            "[Iteration: 5170] [Loss: 0.14086386561393738]\n",
            "[Iteration: 5171] [Loss: 0.14891710877418518]\n",
            "[Iteration: 5172] [Loss: 0.14068998396396637]\n",
            "[Iteration: 5173] [Loss: 0.13488110899925232]\n",
            "[Iteration: 5174] [Loss: 0.1533702164888382]\n",
            "[Iteration: 5175] [Loss: 0.14336150884628296]\n",
            "[Iteration: 5176] [Loss: 0.14405962824821472]\n",
            "[Iteration: 5177] [Loss: 0.1689108908176422]\n",
            "[Iteration: 5178] [Loss: 0.14681805670261383]\n",
            "[Iteration: 5179] [Loss: 0.14673995971679688]\n",
            "[Iteration: 5180] [Loss: 0.14700984954833984]\n",
            "[Iteration: 5181] [Loss: 0.13299718499183655]\n",
            "[Iteration: 5182] [Loss: 0.13885517418384552]\n",
            "[Iteration: 5183] [Loss: 0.1447758823633194]\n",
            "[Iteration: 5184] [Loss: 0.15859636664390564]\n",
            "[Iteration: 5185] [Loss: 0.15709616243839264]\n",
            "[Iteration: 5186] [Loss: 0.13714513182640076]\n",
            "[Iteration: 5187] [Loss: 0.15063942968845367]\n",
            "[Iteration: 5188] [Loss: 0.1461932510137558]\n",
            "[Iteration: 5189] [Loss: 0.146767258644104]\n",
            "[Iteration: 5190] [Loss: 0.15474268794059753]\n",
            "[Iteration: 5191] [Loss: 0.15583646297454834]\n",
            "[Iteration: 5192] [Loss: 0.12440866976976395]\n",
            "[Iteration: 5193] [Loss: 0.1457524299621582]\n",
            "[Iteration: 5194] [Loss: 0.12972889840602875]\n",
            "[Iteration: 5195] [Loss: 0.1547418087720871]\n",
            "[Iteration: 5196] [Loss: 0.13244622945785522]\n",
            "[Iteration: 5197] [Loss: 0.1411789059638977]\n",
            "[Iteration: 5198] [Loss: 0.16166335344314575]\n",
            "[Iteration: 5199] [Loss: 0.1365261822938919]\n",
            "[Iteration: 5200] [Loss: 0.16726469993591309]\n",
            "[Iteration: 5201] [Loss: 0.1523679941892624]\n",
            "[Iteration: 5202] [Loss: 0.15224307775497437]\n",
            "[Iteration: 5203] [Loss: 0.12862949073314667]\n",
            "[Iteration: 5204] [Loss: 0.14402540028095245]\n",
            "[Iteration: 5205] [Loss: 0.15298588573932648]\n",
            "[Iteration: 5206] [Loss: 0.1519242376089096]\n",
            "[Iteration: 5207] [Loss: 0.13466838002204895]\n",
            "[Iteration: 5208] [Loss: 0.16283488273620605]\n",
            "[Iteration: 5209] [Loss: 0.1757379174232483]\n",
            "[Iteration: 5210] [Loss: 0.12606577575206757]\n",
            "[Iteration: 5211] [Loss: 0.1339205503463745]\n",
            "[Iteration: 5212] [Loss: 0.148750901222229]\n",
            "[Iteration: 5213] [Loss: 0.1445217728614807]\n",
            "[Iteration: 5214] [Loss: 0.1398887038230896]\n",
            "[Iteration: 5215] [Loss: 0.1406894326210022]\n",
            "[Iteration: 5216] [Loss: 0.15295292437076569]\n",
            "[Iteration: 5217] [Loss: 0.1421508938074112]\n",
            "[Iteration: 5218] [Loss: 0.1532273143529892]\n",
            "[Iteration: 5219] [Loss: 0.14584481716156006]\n",
            "[Iteration: 5220] [Loss: 0.166036456823349]\n",
            "[Iteration: 5221] [Loss: 0.15087337791919708]\n",
            "[Iteration: 5222] [Loss: 0.15586519241333008]\n",
            "[Iteration: 5223] [Loss: 0.14410831034183502]\n",
            "[Iteration: 5224] [Loss: 0.13687099516391754]\n",
            "[Iteration: 5225] [Loss: 0.17893342673778534]\n",
            "[Iteration: 5226] [Loss: 0.1348058581352234]\n",
            "[Iteration: 5227] [Loss: 0.14898793399333954]\n",
            "[Iteration: 5228] [Loss: 0.14867760241031647]\n",
            "[Iteration: 5229] [Loss: 0.11366377770900726]\n",
            "[Iteration: 5230] [Loss: 0.13702954351902008]\n",
            "[Iteration: 5231] [Loss: 0.1508703976869583]\n",
            "[Iteration: 5232] [Loss: 0.12024813145399094]\n",
            "[Iteration: 5233] [Loss: 0.13877145946025848]\n",
            "[Iteration: 5234] [Loss: 0.15628035366535187]\n",
            "[Iteration: 5235] [Loss: 0.1442718803882599]\n",
            "[Iteration: 5236] [Loss: 0.14959494769573212]\n",
            "[Iteration: 5237] [Loss: 0.14793764054775238]\n",
            "[Iteration: 5238] [Loss: 0.1774096041917801]\n",
            "[Iteration: 5239] [Loss: 0.14493884146213531]\n",
            "[Iteration: 5240] [Loss: 0.13725440204143524]\n",
            "[Iteration: 5241] [Loss: 0.15361759066581726]\n",
            "[Iteration: 5242] [Loss: 0.1532181203365326]\n",
            "[Iteration: 5243] [Loss: 0.141012042760849]\n",
            "[Iteration: 5244] [Loss: 0.15556277334690094]\n",
            "[Iteration: 5245] [Loss: 0.13747020065784454]\n",
            "[Iteration: 5246] [Loss: 0.1330839842557907]\n",
            "[Iteration: 5247] [Loss: 0.1450972706079483]\n",
            "[Iteration: 5248] [Loss: 0.13749520480632782]\n",
            "[Iteration: 5249] [Loss: 0.1534808874130249]\n",
            "[Iteration: 5250] [Loss: 0.13971440494060516]\n",
            "[Iteration: 5251] [Loss: 0.17208820581436157]\n",
            "[Iteration: 5252] [Loss: 0.1534247249364853]\n",
            "[Iteration: 5253] [Loss: 0.15225543081760406]\n",
            "[Iteration: 5254] [Loss: 0.1495102047920227]\n",
            "[Iteration: 5255] [Loss: 0.12478694319725037]\n",
            "[Iteration: 5256] [Loss: 0.12943238019943237]\n",
            "[Iteration: 5257] [Loss: 0.15714554488658905]\n",
            "[Iteration: 5258] [Loss: 0.12458314001560211]\n",
            "[Iteration: 5259] [Loss: 0.14154896140098572]\n",
            "[Iteration: 5260] [Loss: 0.14898541569709778]\n",
            "[Iteration: 5261] [Loss: 0.1627112478017807]\n",
            "[Iteration: 5262] [Loss: 0.13865157961845398]\n",
            "[Iteration: 5263] [Loss: 0.1325581669807434]\n",
            "[Iteration: 5264] [Loss: 0.14367510378360748]\n",
            "[Iteration: 5265] [Loss: 0.1711936593055725]\n",
            "[Iteration: 5266] [Loss: 0.1534268856048584]\n",
            "[Iteration: 5267] [Loss: 0.14756883680820465]\n",
            "[Iteration: 5268] [Loss: 0.14161261916160583]\n",
            "[Iteration: 5269] [Loss: 0.14043861627578735]\n",
            "[Iteration: 5270] [Loss: 0.1509048044681549]\n",
            "[Iteration: 5271] [Loss: 0.151589497923851]\n",
            "[Iteration: 5272] [Loss: 0.14504985511302948]\n",
            "[Iteration: 5273] [Loss: 0.14016205072402954]\n",
            "[Iteration: 5274] [Loss: 0.14241430163383484]\n",
            "[Iteration: 5275] [Loss: 0.15389873087406158]\n",
            "[Iteration: 5276] [Loss: 0.1234845221042633]\n",
            "[Iteration: 5277] [Loss: 0.12234081327915192]\n",
            "[Iteration: 5278] [Loss: 0.14989614486694336]\n",
            "[Iteration: 5279] [Loss: 0.16919738054275513]\n",
            "[Iteration: 5280] [Loss: 0.14723338186740875]\n",
            "[Iteration: 5281] [Loss: 0.13941745460033417]\n",
            "[Iteration: 5282] [Loss: 0.12745100259780884]\n",
            "[Iteration: 5283] [Loss: 0.16871841251850128]\n",
            "[Iteration: 5284] [Loss: 0.12432008236646652]\n",
            "[Iteration: 5285] [Loss: 0.14279517531394958]\n",
            "[Iteration: 5286] [Loss: 0.15679486095905304]\n",
            "[Iteration: 5287] [Loss: 0.13103120028972626]\n",
            "[Iteration: 5288] [Loss: 0.14378105103969574]\n",
            "[Iteration: 5289] [Loss: 0.13719318807125092]\n",
            "[Iteration: 5290] [Loss: 0.13024018704891205]\n",
            "[Iteration: 5291] [Loss: 0.13319355249404907]\n",
            "[Iteration: 5292] [Loss: 0.12365353107452393]\n",
            "[Iteration: 5293] [Loss: 0.1590522825717926]\n",
            "[Iteration: 5294] [Loss: 0.13999319076538086]\n",
            "[Iteration: 5295] [Loss: 0.1363443285226822]\n",
            "[Iteration: 5296] [Loss: 0.14576217532157898]\n",
            "[Iteration: 5297] [Loss: 0.1406104415655136]\n",
            "[Iteration: 5298] [Loss: 0.13788212835788727]\n",
            "[Iteration: 5299] [Loss: 0.125189870595932]\n",
            "[Iteration: 5300] [Loss: 0.14367152750492096]\n",
            "[Iteration: 5301] [Loss: 0.1773168295621872]\n",
            "[Iteration: 5302] [Loss: 0.1569068729877472]\n",
            "[Iteration: 5303] [Loss: 0.14129751920700073]\n",
            "[Iteration: 5304] [Loss: 0.1409153789281845]\n",
            "[Iteration: 5305] [Loss: 0.14267073571681976]\n",
            "[Iteration: 5306] [Loss: 0.1204582154750824]\n",
            "[Iteration: 5307] [Loss: 0.14147764444351196]\n",
            "[Iteration: 5308] [Loss: 0.16058801114559174]\n",
            "[Iteration: 5309] [Loss: 0.14193010330200195]\n",
            "[Iteration: 5310] [Loss: 0.15078860521316528]\n",
            "[Iteration: 5311] [Loss: 0.1459110528230667]\n",
            "[Iteration: 5312] [Loss: 0.1501213014125824]\n",
            "[Iteration: 5313] [Loss: 0.14357635378837585]\n",
            "[Iteration: 5314] [Loss: 0.13734887540340424]\n",
            "[Iteration: 5315] [Loss: 0.12891130149364471]\n",
            "[Iteration: 5316] [Loss: 0.16618138551712036]\n",
            "[Iteration: 5317] [Loss: 0.13110022246837616]\n",
            "[Iteration: 5318] [Loss: 0.14922966063022614]\n",
            "[Iteration: 5319] [Loss: 0.1365741342306137]\n",
            "[Iteration: 5320] [Loss: 0.13764888048171997]\n",
            "[Iteration: 5321] [Loss: 0.13288284838199615]\n",
            "[Iteration: 5322] [Loss: 0.14416132867336273]\n",
            "[Iteration: 5323] [Loss: 0.14644259214401245]\n",
            "[Iteration: 5324] [Loss: 0.13687069714069366]\n",
            "[Iteration: 5325] [Loss: 0.14164765179157257]\n",
            "[Iteration: 5326] [Loss: 0.13556736707687378]\n",
            "[Iteration: 5327] [Loss: 0.14114131033420563]\n",
            "[Iteration: 5328] [Loss: 0.13021300733089447]\n",
            "[Iteration: 5329] [Loss: 0.11434665322303772]\n",
            "[Iteration: 5330] [Loss: 0.1347983181476593]\n",
            "[Iteration: 5331] [Loss: 0.13929232954978943]\n",
            "[Iteration: 5332] [Loss: 0.15997463464736938]\n",
            "[Iteration: 5333] [Loss: 0.13161207735538483]\n",
            "[Iteration: 5334] [Loss: 0.15021762251853943]\n",
            "[Iteration: 5335] [Loss: 0.14424656331539154]\n",
            "[Iteration: 5336] [Loss: 0.1600257009267807]\n",
            "[Iteration: 5337] [Loss: 0.15329430997371674]\n",
            "[Iteration: 5338] [Loss: 0.1345003843307495]\n",
            "[Iteration: 5339] [Loss: 0.1449880748987198]\n",
            "[Iteration: 5340] [Loss: 0.13901716470718384]\n",
            "[Iteration: 5341] [Loss: 0.14751383662223816]\n",
            "[Iteration: 5342] [Loss: 0.14596667885780334]\n",
            "[Iteration: 5343] [Loss: 0.10846756398677826]\n",
            "[Iteration: 5344] [Loss: 0.12853026390075684]\n",
            "[Iteration: 5345] [Loss: 0.13618943095207214]\n",
            "[Iteration: 5346] [Loss: 0.12115594744682312]\n",
            "[Iteration: 5347] [Loss: 0.15060843527317047]\n",
            "[Iteration: 5348] [Loss: 0.13193823397159576]\n",
            "[Iteration: 5349] [Loss: 0.1495019793510437]\n",
            "[Iteration: 5350] [Loss: 0.1297260969877243]\n",
            "[Iteration: 5351] [Loss: 0.1481858491897583]\n",
            "[Iteration: 5352] [Loss: 0.13008101284503937]\n",
            "[Iteration: 5353] [Loss: 0.16988816857337952]\n",
            "[Iteration: 5354] [Loss: 0.14492613077163696]\n",
            "[Iteration: 5355] [Loss: 0.13345937430858612]\n",
            "[Iteration: 5356] [Loss: 0.13250157237052917]\n",
            "[Iteration: 5357] [Loss: 0.14383578300476074]\n",
            "[Iteration: 5358] [Loss: 0.12938940525054932]\n",
            "[Iteration: 5359] [Loss: 0.1339838206768036]\n",
            "[Iteration: 5360] [Loss: 0.14991039037704468]\n",
            "[Iteration: 5361] [Loss: 0.14273785054683685]\n",
            "[Iteration: 5362] [Loss: 0.12910591065883636]\n",
            "[Iteration: 5363] [Loss: 0.1376490741968155]\n",
            "[Iteration: 5364] [Loss: 0.14669957756996155]\n",
            "[Iteration: 5365] [Loss: 0.14818069338798523]\n",
            "[Iteration: 5366] [Loss: 0.11568664014339447]\n",
            "[Iteration: 5367] [Loss: 0.148661807179451]\n",
            "[Iteration: 5368] [Loss: 0.15267124772071838]\n",
            "[Iteration: 5369] [Loss: 0.16658592224121094]\n",
            "[Iteration: 5370] [Loss: 0.13898363709449768]\n",
            "[Iteration: 5371] [Loss: 0.145538330078125]\n",
            "[Iteration: 5372] [Loss: 0.1328454613685608]\n",
            "[Iteration: 5373] [Loss: 0.1617225855588913]\n",
            "[Iteration: 5374] [Loss: 0.13037382066249847]\n",
            "[Iteration: 5375] [Loss: 0.17033670842647552]\n",
            "[Iteration: 5376] [Loss: 0.16031448543071747]\n",
            "[Iteration: 5377] [Loss: 0.12893791496753693]\n",
            "[Iteration: 5378] [Loss: 0.12862460315227509]\n",
            "[Iteration: 5379] [Loss: 0.16194269061088562]\n",
            "[Iteration: 5380] [Loss: 0.14131785929203033]\n",
            "[Iteration: 5381] [Loss: 0.15351909399032593]\n",
            "[Iteration: 5382] [Loss: 0.13565045595169067]\n",
            "[Iteration: 5383] [Loss: 0.13971123099327087]\n",
            "[Iteration: 5384] [Loss: 0.14765191078186035]\n",
            "[Iteration: 5385] [Loss: 0.16681073606014252]\n",
            "[Iteration: 5386] [Loss: 0.14822381734848022]\n",
            "[Iteration: 5387] [Loss: 0.16593009233474731]\n",
            "[Iteration: 5388] [Loss: 0.13579121232032776]\n",
            "[Iteration: 5389] [Loss: 0.1337902694940567]\n",
            "[Iteration: 5390] [Loss: 0.1585034430027008]\n",
            "[Iteration: 5391] [Loss: 0.14431507885456085]\n",
            "[Iteration: 5392] [Loss: 0.14498376846313477]\n",
            "[Iteration: 5393] [Loss: 0.15668092668056488]\n",
            "[Iteration: 5394] [Loss: 0.14111794531345367]\n",
            "[Iteration: 5395] [Loss: 0.14525312185287476]\n",
            "[Iteration: 5396] [Loss: 0.1328982710838318]\n",
            "[Iteration: 5397] [Loss: 0.14819550514221191]\n",
            "[Iteration: 5398] [Loss: 0.14416353404521942]\n",
            "[Iteration: 5399] [Loss: 0.12065250426530838]\n",
            "[Iteration: 5400] [Loss: 0.12978491187095642]\n",
            "[Iteration: 5401] [Loss: 0.11105582863092422]\n",
            "[Iteration: 5402] [Loss: 0.1558048129081726]\n",
            "[Iteration: 5403] [Loss: 0.1565074324607849]\n",
            "[Iteration: 5404] [Loss: 0.12702493369579315]\n",
            "[Iteration: 5405] [Loss: 0.12508559226989746]\n",
            "[Iteration: 5406] [Loss: 0.13553714752197266]\n",
            "[Iteration: 5407] [Loss: 0.12911860644817352]\n",
            "[Iteration: 5408] [Loss: 0.16010349988937378]\n",
            "[Iteration: 5409] [Loss: 0.12479598075151443]\n",
            "[Iteration: 5410] [Loss: 0.17991454899311066]\n",
            "[Iteration: 5411] [Loss: 0.11617180705070496]\n",
            "[Iteration: 5412] [Loss: 0.15326765179634094]\n",
            "[Iteration: 5413] [Loss: 0.1529420018196106]\n",
            "[Iteration: 5414] [Loss: 0.15328727662563324]\n",
            "[Iteration: 5415] [Loss: 0.1644338220357895]\n",
            "[Iteration: 5416] [Loss: 0.14676478505134583]\n",
            "[Iteration: 5417] [Loss: 0.1415664106607437]\n",
            "[Iteration: 5418] [Loss: 0.1382630169391632]\n",
            "[Iteration: 5419] [Loss: 0.12101355195045471]\n",
            "[Iteration: 5420] [Loss: 0.13504984974861145]\n",
            "[Iteration: 5421] [Loss: 0.16536015272140503]\n",
            "[Iteration: 5422] [Loss: 0.13234199583530426]\n",
            "[Iteration: 5423] [Loss: 0.12523724138736725]\n",
            "[Iteration: 5424] [Loss: 0.12957227230072021]\n",
            "[Iteration: 5425] [Loss: 0.13817138969898224]\n",
            "[Iteration: 5426] [Loss: 0.13713069260120392]\n",
            "[Iteration: 5427] [Loss: 0.1417366862297058]\n",
            "[Iteration: 5428] [Loss: 0.13605016469955444]\n",
            "[Iteration: 5429] [Loss: 0.14185523986816406]\n",
            "[Iteration: 5430] [Loss: 0.1497829705476761]\n",
            "[Iteration: 5431] [Loss: 0.14474737644195557]\n",
            "[Iteration: 5432] [Loss: 0.12771250307559967]\n",
            "[Iteration: 5433] [Loss: 0.15483899414539337]\n",
            "[Iteration: 5434] [Loss: 0.15008646249771118]\n",
            "[Iteration: 5435] [Loss: 0.1278560757637024]\n",
            "[Iteration: 5436] [Loss: 0.1484721153974533]\n",
            "[Iteration: 5437] [Loss: 0.14057756960391998]\n",
            "[Iteration: 5438] [Loss: 0.13863524794578552]\n",
            "[Iteration: 5439] [Loss: 0.15474066138267517]\n",
            "[Iteration: 5440] [Loss: 0.1429465264081955]\n",
            "[Iteration: 5441] [Loss: 0.14637373387813568]\n",
            "[Iteration: 5442] [Loss: 0.1546926498413086]\n",
            "[Iteration: 5443] [Loss: 0.17229925096035004]\n",
            "[Iteration: 5444] [Loss: 0.12867134809494019]\n",
            "[Iteration: 5445] [Loss: 0.14991426467895508]\n",
            "[Iteration: 5446] [Loss: 0.13666802644729614]\n",
            "[Iteration: 5447] [Loss: 0.1671488881111145]\n",
            "[Iteration: 5448] [Loss: 0.1310642957687378]\n",
            "[Iteration: 5449] [Loss: 0.13985365629196167]\n",
            "[Iteration: 5450] [Loss: 0.1410716474056244]\n",
            "[Iteration: 5451] [Loss: 0.13616012036800385]\n",
            "[Iteration: 5452] [Loss: 0.13605359196662903]\n",
            "[Iteration: 5453] [Loss: 0.14011862874031067]\n",
            "[Iteration: 5454] [Loss: 0.13582774996757507]\n",
            "[Iteration: 5455] [Loss: 0.12847048044204712]\n",
            "[Iteration: 5456] [Loss: 0.11683493107557297]\n",
            "[Iteration: 5457] [Loss: 0.1245180070400238]\n",
            "[Iteration: 5458] [Loss: 0.13148196041584015]\n",
            "[Iteration: 5459] [Loss: 0.15062958002090454]\n",
            "[Iteration: 5460] [Loss: 0.11921821534633636]\n",
            "[Iteration: 5461] [Loss: 0.16113100945949554]\n",
            "[Iteration: 5462] [Loss: 0.1465526968240738]\n",
            "[Iteration: 5463] [Loss: 0.13029807806015015]\n",
            "[Iteration: 5464] [Loss: 0.14302584528923035]\n",
            "[Iteration: 5465] [Loss: 0.14536769688129425]\n",
            "[Iteration: 5466] [Loss: 0.14054366946220398]\n",
            "[Iteration: 5467] [Loss: 0.14673778414726257]\n",
            "[Iteration: 5468] [Loss: 0.16939300298690796]\n",
            "[Iteration: 5469] [Loss: 0.17015109956264496]\n",
            "[Iteration: 5470] [Loss: 0.15135884284973145]\n",
            "[Iteration: 5471] [Loss: 0.13982409238815308]\n",
            "[Iteration: 5472] [Loss: 0.1341591775417328]\n",
            "[Iteration: 5473] [Loss: 0.15229612588882446]\n",
            "[Iteration: 5474] [Loss: 0.12534260749816895]\n",
            "[Iteration: 5475] [Loss: 0.1550796926021576]\n",
            "[Iteration: 5476] [Loss: 0.13778039813041687]\n",
            "[Iteration: 5477] [Loss: 0.14275461435317993]\n",
            "[Iteration: 5478] [Loss: 0.13557833433151245]\n",
            "[Iteration: 5479] [Loss: 0.1394875943660736]\n",
            "[Iteration: 5480] [Loss: 0.1206650584936142]\n",
            "[Iteration: 5481] [Loss: 0.14215445518493652]\n",
            "[Iteration: 5482] [Loss: 0.15313978493213654]\n",
            "[Iteration: 5483] [Loss: 0.13152891397476196]\n",
            "[Iteration: 5484] [Loss: 0.13313168287277222]\n",
            "[Iteration: 5485] [Loss: 0.14189335703849792]\n",
            "[Iteration: 5486] [Loss: 0.13243362307548523]\n",
            "[Iteration: 5487] [Loss: 0.1425585150718689]\n",
            "[Iteration: 5488] [Loss: 0.14616480469703674]\n",
            "[Iteration: 5489] [Loss: 0.12423797696828842]\n",
            "[Iteration: 5490] [Loss: 0.12831375002861023]\n",
            "[Iteration: 5491] [Loss: 0.1581323891878128]\n",
            "[Iteration: 5492] [Loss: 0.16432949900627136]\n",
            "[Iteration: 5493] [Loss: 0.14857643842697144]\n",
            "[Iteration: 5494] [Loss: 0.16460929811000824]\n",
            "[Iteration: 5495] [Loss: 0.1390184611082077]\n",
            "[Iteration: 5496] [Loss: 0.1441923826932907]\n",
            "[Iteration: 5497] [Loss: 0.12812285125255585]\n",
            "[Iteration: 5498] [Loss: 0.1379668116569519]\n",
            "[Iteration: 5499] [Loss: 0.12135704606771469]\n",
            "[Iteration: 5500] [Loss: 0.1542414277791977]\n",
            "[Iteration: 5501] [Loss: 0.15865470468997955]\n",
            "[Iteration: 5502] [Loss: 0.1453453153371811]\n",
            "[Iteration: 5503] [Loss: 0.13455763459205627]\n",
            "[Iteration: 5504] [Loss: 0.14652606844902039]\n",
            "[Iteration: 5505] [Loss: 0.13202400505542755]\n",
            "[Iteration: 5506] [Loss: 0.14104098081588745]\n",
            "[Iteration: 5507] [Loss: 0.1474401354789734]\n",
            "[Iteration: 5508] [Loss: 0.14624053239822388]\n",
            "[Iteration: 5509] [Loss: 0.13581348955631256]\n",
            "[Iteration: 5510] [Loss: 0.13442331552505493]\n",
            "[Iteration: 5511] [Loss: 0.1381826251745224]\n",
            "[Iteration: 5512] [Loss: 0.13715995848178864]\n",
            "[Iteration: 5513] [Loss: 0.13282564282417297]\n",
            "[Iteration: 5514] [Loss: 0.1252632737159729]\n",
            "[Iteration: 5515] [Loss: 0.12474440038204193]\n",
            "[Iteration: 5516] [Loss: 0.13964113593101501]\n",
            "[Iteration: 5517] [Loss: 0.14792026579380035]\n",
            "[Iteration: 5518] [Loss: 0.1325073391199112]\n",
            "[Iteration: 5519] [Loss: 0.1573900282382965]\n",
            "[Iteration: 5520] [Loss: 0.14146918058395386]\n",
            "[Iteration: 5521] [Loss: 0.1418081670999527]\n",
            "[Iteration: 5522] [Loss: 0.14069049060344696]\n",
            "[Iteration: 5523] [Loss: 0.12923592329025269]\n",
            "[Iteration: 5524] [Loss: 0.1273622214794159]\n",
            "[Iteration: 5525] [Loss: 0.1336369514465332]\n",
            "[Iteration: 5526] [Loss: 0.13494683802127838]\n",
            "[Iteration: 5527] [Loss: 0.13949590921401978]\n",
            "[Iteration: 5528] [Loss: 0.13967348635196686]\n",
            "[Iteration: 5529] [Loss: 0.14185404777526855]\n",
            "[Iteration: 5530] [Loss: 0.1263500601053238]\n",
            "[Iteration: 5531] [Loss: 0.15758594870567322]\n",
            "[Iteration: 5532] [Loss: 0.1294638216495514]\n",
            "[Iteration: 5533] [Loss: 0.1313435584306717]\n",
            "[Iteration: 5534] [Loss: 0.15303492546081543]\n",
            "[Iteration: 5535] [Loss: 0.12925252318382263]\n",
            "[Iteration: 5536] [Loss: 0.12267465144395828]\n",
            "[Iteration: 5537] [Loss: 0.12108200043439865]\n",
            "[Iteration: 5538] [Loss: 0.16113418340682983]\n",
            "[Iteration: 5539] [Loss: 0.132978618144989]\n",
            "[Iteration: 5540] [Loss: 0.1507701873779297]\n",
            "[Iteration: 5541] [Loss: 0.13554790616035461]\n",
            "[Iteration: 5542] [Loss: 0.13103502988815308]\n",
            "[Iteration: 5543] [Loss: 0.12944738566875458]\n",
            "[Iteration: 5544] [Loss: 0.13970041275024414]\n",
            "[Iteration: 5545] [Loss: 0.12732210755348206]\n",
            "[Iteration: 5546] [Loss: 0.13973815739154816]\n",
            "[Iteration: 5547] [Loss: 0.1446150690317154]\n",
            "[Iteration: 5548] [Loss: 0.16671167314052582]\n",
            "[Iteration: 5549] [Loss: 0.1342722624540329]\n",
            "[Iteration: 5550] [Loss: 0.1266934722661972]\n",
            "[Iteration: 5551] [Loss: 0.12908850610256195]\n",
            "[Iteration: 5552] [Loss: 0.13778798282146454]\n",
            "[Iteration: 5553] [Loss: 0.15697307884693146]\n",
            "[Iteration: 5554] [Loss: 0.13679859042167664]\n",
            "[Iteration: 5555] [Loss: 0.1322261393070221]\n",
            "[Iteration: 5556] [Loss: 0.13610853254795074]\n",
            "[Iteration: 5557] [Loss: 0.13395343720912933]\n",
            "[Iteration: 5558] [Loss: 0.1377418488264084]\n",
            "[Iteration: 5559] [Loss: 0.14305758476257324]\n",
            "[Iteration: 5560] [Loss: 0.16522353887557983]\n",
            "[Iteration: 5561] [Loss: 0.1228436529636383]\n",
            "[Iteration: 5562] [Loss: 0.1285071074962616]\n",
            "[Iteration: 5563] [Loss: 0.13613130152225494]\n",
            "[Iteration: 5564] [Loss: 0.15505291521549225]\n",
            "[Iteration: 5565] [Loss: 0.12862852215766907]\n",
            "[Iteration: 5566] [Loss: 0.12699104845523834]\n",
            "[Iteration: 5567] [Loss: 0.14476630091667175]\n",
            "[Iteration: 5568] [Loss: 0.12477454543113708]\n",
            "[Iteration: 5569] [Loss: 0.14844399690628052]\n",
            "[Iteration: 5570] [Loss: 0.1486288607120514]\n",
            "[Iteration: 5571] [Loss: 0.13106387853622437]\n",
            "[Iteration: 5572] [Loss: 0.15310129523277283]\n",
            "[Iteration: 5573] [Loss: 0.1475542187690735]\n",
            "[Iteration: 5574] [Loss: 0.13660593330860138]\n",
            "[Iteration: 5575] [Loss: 0.14031773805618286]\n",
            "[Iteration: 5576] [Loss: 0.14735311269760132]\n",
            "[Iteration: 5577] [Loss: 0.12699876725673676]\n",
            "[Iteration: 5578] [Loss: 0.16197910904884338]\n",
            "[Iteration: 5579] [Loss: 0.14319343864917755]\n",
            "[Iteration: 5580] [Loss: 0.15512226521968842]\n",
            "[Iteration: 5581] [Loss: 0.1522379070520401]\n",
            "[Iteration: 5582] [Loss: 0.1505582481622696]\n",
            "[Iteration: 5583] [Loss: 0.1250096708536148]\n",
            "[Iteration: 5584] [Loss: 0.14504683017730713]\n",
            "[Iteration: 5585] [Loss: 0.1261218637228012]\n",
            "[Iteration: 5586] [Loss: 0.1370287537574768]\n",
            "[Iteration: 5587] [Loss: 0.13462835550308228]\n",
            "[Iteration: 5588] [Loss: 0.13541890680789948]\n",
            "[Iteration: 5589] [Loss: 0.1529133915901184]\n",
            "[Iteration: 5590] [Loss: 0.15791055560112]\n",
            "[Iteration: 5591] [Loss: 0.13405448198318481]\n",
            "[Iteration: 5592] [Loss: 0.12385915219783783]\n",
            "[Iteration: 5593] [Loss: 0.1495954394340515]\n",
            "[Iteration: 5594] [Loss: 0.1586458534002304]\n",
            "[Iteration: 5595] [Loss: 0.14718346297740936]\n",
            "[Iteration: 5596] [Loss: 0.14808405935764313]\n",
            "[Iteration: 5597] [Loss: 0.1634630262851715]\n",
            "[Iteration: 5598] [Loss: 0.13508981466293335]\n",
            "[Iteration: 5599] [Loss: 0.1350318044424057]\n",
            "[Iteration: 5600] [Loss: 0.11773408949375153]\n",
            "[Iteration: 5601] [Loss: 0.14454419910907745]\n",
            "[Iteration: 5602] [Loss: 0.12458891421556473]\n",
            "[Iteration: 5603] [Loss: 0.15772542357444763]\n",
            "[Iteration: 5604] [Loss: 0.1507311314344406]\n",
            "[Iteration: 5605] [Loss: 0.12896211445331573]\n",
            "[Iteration: 5606] [Loss: 0.1148717924952507]\n",
            "[Iteration: 5607] [Loss: 0.14509792625904083]\n",
            "[Iteration: 5608] [Loss: 0.13009077310562134]\n",
            "[Iteration: 5609] [Loss: 0.12070848047733307]\n",
            "[Iteration: 5610] [Loss: 0.1404131054878235]\n",
            "[Iteration: 5611] [Loss: 0.1302305907011032]\n",
            "[Iteration: 5612] [Loss: 0.13252191245555878]\n",
            "[Iteration: 5613] [Loss: 0.1260846108198166]\n",
            "[Iteration: 5614] [Loss: 0.13213366270065308]\n",
            "[Iteration: 5615] [Loss: 0.13345545530319214]\n",
            "[Iteration: 5616] [Loss: 0.13068126142024994]\n",
            "[Iteration: 5617] [Loss: 0.14333981275558472]\n",
            "[Iteration: 5618] [Loss: 0.1233224868774414]\n",
            "[Iteration: 5619] [Loss: 0.13892744481563568]\n",
            "[Iteration: 5620] [Loss: 0.13315220177173615]\n",
            "[Iteration: 5621] [Loss: 0.17386430501937866]\n",
            "[Iteration: 5622] [Loss: 0.16476558148860931]\n",
            "[Iteration: 5623] [Loss: 0.14951199293136597]\n",
            "[Iteration: 5624] [Loss: 0.13255079090595245]\n",
            "[Iteration: 5625] [Loss: 0.1312456876039505]\n",
            "[Iteration: 5626] [Loss: 0.12657243013381958]\n",
            "[Iteration: 5627] [Loss: 0.14792275428771973]\n",
            "[Iteration: 5628] [Loss: 0.14230412244796753]\n",
            "[Iteration: 5629] [Loss: 0.1316269338130951]\n",
            "[Iteration: 5630] [Loss: 0.11994877457618713]\n",
            "[Iteration: 5631] [Loss: 0.13699977099895477]\n",
            "[Iteration: 5632] [Loss: 0.10814525932073593]\n",
            "[Iteration: 5633] [Loss: 0.15345782041549683]\n",
            "[Iteration: 5634] [Loss: 0.13566581904888153]\n",
            "[Iteration: 5635] [Loss: 0.1209445372223854]\n",
            "[Iteration: 5636] [Loss: 0.14333181083202362]\n",
            "[Iteration: 5637] [Loss: 0.11700669676065445]\n",
            "[Iteration: 5638] [Loss: 0.14058004319667816]\n",
            "[Iteration: 5639] [Loss: 0.13736528158187866]\n",
            "[Iteration: 5640] [Loss: 0.14526458084583282]\n",
            "[Iteration: 5641] [Loss: 0.12886545062065125]\n",
            "[Iteration: 5642] [Loss: 0.13059711456298828]\n",
            "[Iteration: 5643] [Loss: 0.12482520937919617]\n",
            "[Iteration: 5644] [Loss: 0.1359046846628189]\n",
            "[Iteration: 5645] [Loss: 0.15905435383319855]\n",
            "[Iteration: 5646] [Loss: 0.13082346320152283]\n",
            "[Iteration: 5647] [Loss: 0.15090356767177582]\n",
            "[Iteration: 5648] [Loss: 0.1480107605457306]\n",
            "[Iteration: 5649] [Loss: 0.13152527809143066]\n",
            "[Iteration: 5650] [Loss: 0.13710032403469086]\n",
            "[Iteration: 5651] [Loss: 0.1505720019340515]\n",
            "[Iteration: 5652] [Loss: 0.1368085741996765]\n",
            "[Iteration: 5653] [Loss: 0.12757925689220428]\n",
            "[Iteration: 5654] [Loss: 0.15907594561576843]\n",
            "[Iteration: 5655] [Loss: 0.12241685390472412]\n",
            "[Iteration: 5656] [Loss: 0.14382334053516388]\n",
            "[Iteration: 5657] [Loss: 0.15200728178024292]\n",
            "[Iteration: 5658] [Loss: 0.14784452319145203]\n",
            "[Iteration: 5659] [Loss: 0.14221489429473877]\n",
            "[Iteration: 5660] [Loss: 0.14915595948696136]\n",
            "[Iteration: 5661] [Loss: 0.15077131986618042]\n",
            "[Iteration: 5662] [Loss: 0.11804187297821045]\n",
            "[Iteration: 5663] [Loss: 0.1297435164451599]\n",
            "[Iteration: 5664] [Loss: 0.14897111058235168]\n",
            "[Iteration: 5665] [Loss: 0.136736199259758]\n",
            "[Iteration: 5666] [Loss: 0.1319180428981781]\n",
            "[Iteration: 5667] [Loss: 0.14071309566497803]\n",
            "[Iteration: 5668] [Loss: 0.14035241305828094]\n",
            "[Iteration: 5669] [Loss: 0.12307160347700119]\n",
            "[Iteration: 5670] [Loss: 0.15467849373817444]\n",
            "[Iteration: 5671] [Loss: 0.1331969052553177]\n",
            "[Iteration: 5672] [Loss: 0.14826518297195435]\n",
            "[Iteration: 5673] [Loss: 0.14974607527256012]\n",
            "[Iteration: 5674] [Loss: 0.12176987528800964]\n",
            "[Iteration: 5675] [Loss: 0.15337155759334564]\n",
            "[Iteration: 5676] [Loss: 0.137559711933136]\n",
            "[Iteration: 5677] [Loss: 0.13574537634849548]\n",
            "[Iteration: 5678] [Loss: 0.14196041226387024]\n",
            "[Iteration: 5679] [Loss: 0.13956284523010254]\n",
            "[Iteration: 5680] [Loss: 0.12121759355068207]\n",
            "[Iteration: 5681] [Loss: 0.1528739333152771]\n",
            "[Iteration: 5682] [Loss: 0.12823259830474854]\n",
            "[Iteration: 5683] [Loss: 0.13671261072158813]\n",
            "[Iteration: 5684] [Loss: 0.15997682511806488]\n",
            "[Iteration: 5685] [Loss: 0.1502084732055664]\n",
            "[Iteration: 5686] [Loss: 0.1551784873008728]\n",
            "[Iteration: 5687] [Loss: 0.11700686067342758]\n",
            "[Iteration: 5688] [Loss: 0.15219180285930634]\n",
            "[Iteration: 5689] [Loss: 0.12940742075443268]\n",
            "[Iteration: 5690] [Loss: 0.12527050077915192]\n",
            "[Iteration: 5691] [Loss: 0.12852446734905243]\n",
            "[Iteration: 5692] [Loss: 0.14917361736297607]\n",
            "[Iteration: 5693] [Loss: 0.11927800625562668]\n",
            "[Iteration: 5694] [Loss: 0.15047073364257812]\n",
            "[Iteration: 5695] [Loss: 0.13606923818588257]\n",
            "[Iteration: 5696] [Loss: 0.14014612138271332]\n",
            "[Iteration: 5697] [Loss: 0.12796904146671295]\n",
            "[Iteration: 5698] [Loss: 0.13962291181087494]\n",
            "[Iteration: 5699] [Loss: 0.11719004064798355]\n",
            "[Iteration: 5700] [Loss: 0.13376165926456451]\n",
            "[Iteration: 5701] [Loss: 0.15936939418315887]\n",
            "[Iteration: 5702] [Loss: 0.12784437835216522]\n",
            "[Iteration: 5703] [Loss: 0.1343374252319336]\n",
            "[Iteration: 5704] [Loss: 0.1366863250732422]\n",
            "[Iteration: 5705] [Loss: 0.1283019632101059]\n",
            "[Iteration: 5706] [Loss: 0.13517838716506958]\n",
            "[Iteration: 5707] [Loss: 0.1344333291053772]\n",
            "[Iteration: 5708] [Loss: 0.12040624022483826]\n",
            "[Iteration: 5709] [Loss: 0.13260722160339355]\n",
            "[Iteration: 5710] [Loss: 0.14952419698238373]\n",
            "[Iteration: 5711] [Loss: 0.13110563158988953]\n",
            "[Iteration: 5712] [Loss: 0.1462824046611786]\n",
            "[Iteration: 5713] [Loss: 0.12402008473873138]\n",
            "[Iteration: 5714] [Loss: 0.15045768022537231]\n",
            "[Iteration: 5715] [Loss: 0.1331593543291092]\n",
            "[Iteration: 5716] [Loss: 0.11079727113246918]\n",
            "[Iteration: 5717] [Loss: 0.13012024760246277]\n",
            "[Iteration: 5718] [Loss: 0.13733027875423431]\n",
            "[Iteration: 5719] [Loss: 0.1263584941625595]\n",
            "[Iteration: 5720] [Loss: 0.144993856549263]\n",
            "[Iteration: 5721] [Loss: 0.13038304448127747]\n",
            "[Iteration: 5722] [Loss: 0.13455697894096375]\n",
            "[Iteration: 5723] [Loss: 0.12253054231405258]\n",
            "[Iteration: 5724] [Loss: 0.12609639763832092]\n",
            "[Iteration: 5725] [Loss: 0.13144852221012115]\n",
            "[Iteration: 5726] [Loss: 0.15673373639583588]\n",
            "[Iteration: 5727] [Loss: 0.13595926761627197]\n",
            "[Iteration: 5728] [Loss: 0.11365261673927307]\n",
            "[Iteration: 5729] [Loss: 0.14947444200515747]\n",
            "[Iteration: 5730] [Loss: 0.14029832184314728]\n",
            "[Iteration: 5731] [Loss: 0.1437772512435913]\n",
            "[Iteration: 5732] [Loss: 0.12662364542484283]\n",
            "[Iteration: 5733] [Loss: 0.15619176626205444]\n",
            "[Iteration: 5734] [Loss: 0.1226743757724762]\n",
            "[Iteration: 5735] [Loss: 0.1329299658536911]\n",
            "[Iteration: 5736] [Loss: 0.15447485446929932]\n",
            "[Iteration: 5737] [Loss: 0.1374148279428482]\n",
            "[Iteration: 5738] [Loss: 0.13930238783359528]\n",
            "[Iteration: 5739] [Loss: 0.14151398837566376]\n",
            "[Iteration: 5740] [Loss: 0.13114038109779358]\n",
            "[Iteration: 5741] [Loss: 0.1297416090965271]\n",
            "[Iteration: 5742] [Loss: 0.1335964798927307]\n",
            "[Iteration: 5743] [Loss: 0.13205073773860931]\n",
            "[Iteration: 5744] [Loss: 0.14404743909835815]\n",
            "[Iteration: 5745] [Loss: 0.12937134504318237]\n",
            "[Iteration: 5746] [Loss: 0.12969118356704712]\n",
            "[Iteration: 5747] [Loss: 0.13403359055519104]\n",
            "[Iteration: 5748] [Loss: 0.12908907234668732]\n",
            "[Iteration: 5749] [Loss: 0.11986442655324936]\n",
            "[Iteration: 5750] [Loss: 0.14133547246456146]\n",
            "[Iteration: 5751] [Loss: 0.13039864599704742]\n",
            "[Iteration: 5752] [Loss: 0.12404391169548035]\n",
            "[Iteration: 5753] [Loss: 0.12788288295269012]\n",
            "[Iteration: 5754] [Loss: 0.1295299530029297]\n",
            "[Iteration: 5755] [Loss: 0.1386774480342865]\n",
            "[Iteration: 5756] [Loss: 0.1267353892326355]\n",
            "[Iteration: 5757] [Loss: 0.1470295786857605]\n",
            "[Iteration: 5758] [Loss: 0.13596616685390472]\n",
            "[Iteration: 5759] [Loss: 0.15747252106666565]\n",
            "[Iteration: 5760] [Loss: 0.1111987829208374]\n",
            "[Iteration: 5761] [Loss: 0.14756521582603455]\n",
            "[Iteration: 5762] [Loss: 0.1445590704679489]\n",
            "[Iteration: 5763] [Loss: 0.14174392819404602]\n",
            "[Iteration: 5764] [Loss: 0.13367755711078644]\n",
            "[Iteration: 5765] [Loss: 0.13079924881458282]\n",
            "[Iteration: 5766] [Loss: 0.13214094936847687]\n",
            "[Iteration: 5767] [Loss: 0.15080416202545166]\n",
            "[Iteration: 5768] [Loss: 0.13258065283298492]\n",
            "[Iteration: 5769] [Loss: 0.13332074880599976]\n",
            "[Iteration: 5770] [Loss: 0.133281871676445]\n",
            "[Iteration: 5771] [Loss: 0.14144685864448547]\n",
            "[Iteration: 5772] [Loss: 0.14463703334331512]\n",
            "[Iteration: 5773] [Loss: 0.13256444036960602]\n",
            "[Iteration: 5774] [Loss: 0.12751710414886475]\n",
            "[Iteration: 5775] [Loss: 0.1355934888124466]\n",
            "[Iteration: 5776] [Loss: 0.11287600547075272]\n",
            "[Iteration: 5777] [Loss: 0.13553465902805328]\n",
            "[Iteration: 5778] [Loss: 0.14729256927967072]\n",
            "[Iteration: 5779] [Loss: 0.13882829248905182]\n",
            "[Iteration: 5780] [Loss: 0.10033629834651947]\n",
            "[Iteration: 5781] [Loss: 0.13731873035430908]\n",
            "[Iteration: 5782] [Loss: 0.1323586106300354]\n",
            "[Iteration: 5783] [Loss: 0.15021231770515442]\n",
            "[Iteration: 5784] [Loss: 0.1363646388053894]\n",
            "[Iteration: 5785] [Loss: 0.13615618646144867]\n",
            "[Iteration: 5786] [Loss: 0.13143861293792725]\n",
            "[Iteration: 5787] [Loss: 0.14603500068187714]\n",
            "[Iteration: 5788] [Loss: 0.14263509213924408]\n",
            "[Iteration: 5789] [Loss: 0.1205579861998558]\n",
            "[Iteration: 5790] [Loss: 0.12209779769182205]\n",
            "[Iteration: 5791] [Loss: 0.15926143527030945]\n",
            "[Iteration: 5792] [Loss: 0.14365610480308533]\n",
            "[Iteration: 5793] [Loss: 0.16420842707157135]\n",
            "[Iteration: 5794] [Loss: 0.13494153320789337]\n",
            "[Iteration: 5795] [Loss: 0.13532644510269165]\n",
            "[Iteration: 5796] [Loss: 0.11885827034711838]\n",
            "[Iteration: 5797] [Loss: 0.1428496241569519]\n",
            "[Iteration: 5798] [Loss: 0.12164531648159027]\n",
            "[Iteration: 5799] [Loss: 0.15234807133674622]\n",
            "[Iteration: 5800] [Loss: 0.13311758637428284]\n",
            "[Iteration: 5801] [Loss: 0.12611328065395355]\n",
            "[Iteration: 5802] [Loss: 0.1350446343421936]\n",
            "[Iteration: 5803] [Loss: 0.13951720297336578]\n",
            "[Iteration: 5804] [Loss: 0.13362714648246765]\n",
            "[Iteration: 5805] [Loss: 0.1241503655910492]\n",
            "[Iteration: 5806] [Loss: 0.13566896319389343]\n",
            "[Iteration: 5807] [Loss: 0.13634397089481354]\n",
            "[Iteration: 5808] [Loss: 0.13335555791854858]\n",
            "[Iteration: 5809] [Loss: 0.1054513230919838]\n",
            "[Iteration: 5810] [Loss: 0.12377624958753586]\n",
            "[Iteration: 5811] [Loss: 0.12665003538131714]\n",
            "[Iteration: 5812] [Loss: 0.13932287693023682]\n",
            "[Iteration: 5813] [Loss: 0.1379060447216034]\n",
            "[Iteration: 5814] [Loss: 0.13934457302093506]\n",
            "[Iteration: 5815] [Loss: 0.13777092099189758]\n",
            "[Iteration: 5816] [Loss: 0.15003840625286102]\n",
            "[Iteration: 5817] [Loss: 0.13570593297481537]\n",
            "[Iteration: 5818] [Loss: 0.1600772738456726]\n",
            "[Iteration: 5819] [Loss: 0.1292332410812378]\n",
            "[Iteration: 5820] [Loss: 0.14877034723758698]\n",
            "[Iteration: 5821] [Loss: 0.15111860632896423]\n",
            "[Iteration: 5822] [Loss: 0.12483305484056473]\n",
            "[Iteration: 5823] [Loss: 0.13959182798862457]\n",
            "[Iteration: 5824] [Loss: 0.14224150776863098]\n",
            "[Iteration: 5825] [Loss: 0.12914477288722992]\n",
            "[Iteration: 5826] [Loss: 0.14995057880878448]\n",
            "[Iteration: 5827] [Loss: 0.1368587613105774]\n",
            "[Iteration: 5828] [Loss: 0.14952917397022247]\n",
            "[Iteration: 5829] [Loss: 0.13997524976730347]\n",
            "[Iteration: 5830] [Loss: 0.11548975110054016]\n",
            "[Iteration: 5831] [Loss: 0.1512364000082016]\n",
            "[Iteration: 5832] [Loss: 0.13981637358665466]\n",
            "[Iteration: 5833] [Loss: 0.14892975986003876]\n",
            "[Iteration: 5834] [Loss: 0.13973453640937805]\n",
            "[Iteration: 5835] [Loss: 0.13344979286193848]\n",
            "[Iteration: 5836] [Loss: 0.1386832594871521]\n",
            "[Iteration: 5837] [Loss: 0.15710248053073883]\n",
            "[Iteration: 5838] [Loss: 0.12691587209701538]\n",
            "[Iteration: 5839] [Loss: 0.11975589394569397]\n",
            "[Iteration: 5840] [Loss: 0.1521882265806198]\n",
            "[Iteration: 5841] [Loss: 0.13083188235759735]\n",
            "[Iteration: 5842] [Loss: 0.13826274871826172]\n",
            "[Iteration: 5843] [Loss: 0.13438169658184052]\n",
            "[Iteration: 5844] [Loss: 0.13111767172813416]\n",
            "[Iteration: 5845] [Loss: 0.14860402047634125]\n",
            "[Iteration: 5846] [Loss: 0.11888331919908524]\n",
            "[Iteration: 5847] [Loss: 0.135753333568573]\n",
            "[Iteration: 5848] [Loss: 0.13700293004512787]\n",
            "[Iteration: 5849] [Loss: 0.14678162336349487]\n",
            "[Iteration: 5850] [Loss: 0.14221301674842834]\n",
            "[Iteration: 5851] [Loss: 0.1422075480222702]\n",
            "[Iteration: 5852] [Loss: 0.13172346353530884]\n",
            "[Iteration: 5853] [Loss: 0.12127729505300522]\n",
            "[Iteration: 5854] [Loss: 0.14141035079956055]\n",
            "[Iteration: 5855] [Loss: 0.12934333086013794]\n",
            "[Iteration: 5856] [Loss: 0.11403670907020569]\n",
            "[Iteration: 5857] [Loss: 0.13272280991077423]\n",
            "[Iteration: 5858] [Loss: 0.13633067905902863]\n",
            "[Iteration: 5859] [Loss: 0.12652000784873962]\n",
            "[Iteration: 5860] [Loss: 0.1406048983335495]\n",
            "[Iteration: 5861] [Loss: 0.12743191421031952]\n",
            "[Iteration: 5862] [Loss: 0.14511163532733917]\n",
            "[Iteration: 5863] [Loss: 0.121486134827137]\n",
            "[Iteration: 5864] [Loss: 0.1331285536289215]\n",
            "[Iteration: 5865] [Loss: 0.11913112550973892]\n",
            "[Iteration: 5866] [Loss: 0.14669767022132874]\n",
            "[Iteration: 5867] [Loss: 0.11239499598741531]\n",
            "[Iteration: 5868] [Loss: 0.14378364384174347]\n",
            "[Iteration: 5869] [Loss: 0.14523078501224518]\n",
            "[Iteration: 5870] [Loss: 0.12999102473258972]\n",
            "[Iteration: 5871] [Loss: 0.14043793082237244]\n",
            "[Iteration: 5872] [Loss: 0.13488717377185822]\n",
            "[Iteration: 5873] [Loss: 0.1416616439819336]\n",
            "[Iteration: 5874] [Loss: 0.1353783905506134]\n",
            "[Iteration: 5875] [Loss: 0.14044533669948578]\n",
            "[Iteration: 5876] [Loss: 0.14496412873268127]\n",
            "[Iteration: 5877] [Loss: 0.12548966705799103]\n",
            "[Iteration: 5878] [Loss: 0.13650864362716675]\n",
            "[Iteration: 5879] [Loss: 0.1376088410615921]\n",
            "[Iteration: 5880] [Loss: 0.13182775676250458]\n",
            "[Iteration: 5881] [Loss: 0.12365084141492844]\n",
            "[Iteration: 5882] [Loss: 0.14099472761154175]\n",
            "[Iteration: 5883] [Loss: 0.14727889001369476]\n",
            "[Iteration: 5884] [Loss: 0.1411670744419098]\n",
            "[Iteration: 5885] [Loss: 0.11790359020233154]\n",
            "[Iteration: 5886] [Loss: 0.1311180293560028]\n",
            "[Iteration: 5887] [Loss: 0.14761072397232056]\n",
            "[Iteration: 5888] [Loss: 0.1434727907180786]\n",
            "[Iteration: 5889] [Loss: 0.12633222341537476]\n",
            "[Iteration: 5890] [Loss: 0.11709524691104889]\n",
            "[Iteration: 5891] [Loss: 0.13773280382156372]\n",
            "[Iteration: 5892] [Loss: 0.126224547624588]\n",
            "[Iteration: 5893] [Loss: 0.14078372716903687]\n",
            "[Iteration: 5894] [Loss: 0.12451822310686111]\n",
            "[Iteration: 5895] [Loss: 0.13030683994293213]\n",
            "[Iteration: 5896] [Loss: 0.167425736784935]\n",
            "[Iteration: 5897] [Loss: 0.13213184475898743]\n",
            "[Iteration: 5898] [Loss: 0.1412423849105835]\n",
            "[Iteration: 5899] [Loss: 0.1195724681019783]\n",
            "[Iteration: 5900] [Loss: 0.11697476357221603]\n",
            "[Iteration: 5901] [Loss: 0.12546586990356445]\n",
            "[Iteration: 5902] [Loss: 0.12621474266052246]\n",
            "[Iteration: 5903] [Loss: 0.12428447604179382]\n",
            "[Iteration: 5904] [Loss: 0.13844797015190125]\n",
            "[Iteration: 5905] [Loss: 0.13820533454418182]\n",
            "[Iteration: 5906] [Loss: 0.13737207651138306]\n",
            "[Iteration: 5907] [Loss: 0.12486261874437332]\n",
            "[Iteration: 5908] [Loss: 0.138954296708107]\n",
            "[Iteration: 5909] [Loss: 0.13521943986415863]\n",
            "[Iteration: 5910] [Loss: 0.1206766739487648]\n",
            "[Iteration: 5911] [Loss: 0.12403232604265213]\n",
            "[Iteration: 5912] [Loss: 0.12524469196796417]\n",
            "[Iteration: 5913] [Loss: 0.14699366688728333]\n",
            "[Iteration: 5914] [Loss: 0.13191841542720795]\n",
            "[Iteration: 5915] [Loss: 0.14725270867347717]\n",
            "[Iteration: 5916] [Loss: 0.13084594905376434]\n",
            "[Iteration: 5917] [Loss: 0.1296861618757248]\n",
            "[Iteration: 5918] [Loss: 0.11117815971374512]\n",
            "[Iteration: 5919] [Loss: 0.12348392605781555]\n",
            "[Iteration: 5920] [Loss: 0.11835528910160065]\n",
            "[Iteration: 5921] [Loss: 0.13183069229125977]\n",
            "[Iteration: 5922] [Loss: 0.12910427153110504]\n",
            "[Iteration: 5923] [Loss: 0.13090568780899048]\n",
            "[Iteration: 5924] [Loss: 0.12671449780464172]\n",
            "[Iteration: 5925] [Loss: 0.13619692623615265]\n",
            "[Iteration: 5926] [Loss: 0.12654611468315125]\n",
            "[Iteration: 5927] [Loss: 0.1201494038105011]\n",
            "[Iteration: 5928] [Loss: 0.14444516599178314]\n",
            "[Iteration: 5929] [Loss: 0.14484432339668274]\n",
            "[Iteration: 5930] [Loss: 0.12990431487560272]\n",
            "[Iteration: 5931] [Loss: 0.14012081921100616]\n",
            "[Iteration: 5932] [Loss: 0.13244563341140747]\n",
            "[Iteration: 5933] [Loss: 0.13463246822357178]\n",
            "[Iteration: 5934] [Loss: 0.12356766313314438]\n",
            "[Iteration: 5935] [Loss: 0.14746342599391937]\n",
            "[Iteration: 5936] [Loss: 0.14912675321102142]\n",
            "[Iteration: 5937] [Loss: 0.1496942639350891]\n",
            "[Iteration: 5938] [Loss: 0.16858595609664917]\n",
            "[Iteration: 5939] [Loss: 0.13114693760871887]\n",
            "[Iteration: 5940] [Loss: 0.13271072506904602]\n",
            "[Iteration: 5941] [Loss: 0.14049223065376282]\n",
            "[Iteration: 5942] [Loss: 0.14222659170627594]\n",
            "[Iteration: 5943] [Loss: 0.1499786674976349]\n",
            "[Iteration: 5944] [Loss: 0.13029737770557404]\n",
            "[Iteration: 5945] [Loss: 0.13498039543628693]\n",
            "[Iteration: 5946] [Loss: 0.11558636277914047]\n",
            "[Iteration: 5947] [Loss: 0.14291612803936005]\n",
            "[Iteration: 5948] [Loss: 0.13689066469669342]\n",
            "[Iteration: 5949] [Loss: 0.12676696479320526]\n",
            "[Iteration: 5950] [Loss: 0.13529928028583527]\n",
            "[Iteration: 5951] [Loss: 0.1430538445711136]\n",
            "[Iteration: 5952] [Loss: 0.15582115948200226]\n",
            "[Iteration: 5953] [Loss: 0.1445569396018982]\n",
            "[Iteration: 5954] [Loss: 0.13066323101520538]\n",
            "[Iteration: 5955] [Loss: 0.11279495805501938]\n",
            "[Iteration: 5956] [Loss: 0.12100754678249359]\n",
            "[Iteration: 5957] [Loss: 0.1404634416103363]\n",
            "[Iteration: 5958] [Loss: 0.13151991367340088]\n",
            "[Iteration: 5959] [Loss: 0.12624748051166534]\n",
            "[Iteration: 5960] [Loss: 0.12904641032218933]\n",
            "[Iteration: 5961] [Loss: 0.13540399074554443]\n",
            "[Iteration: 5962] [Loss: 0.12011417746543884]\n",
            "[Iteration: 5963] [Loss: 0.14640706777572632]\n",
            "[Iteration: 5964] [Loss: 0.15060749650001526]\n",
            "[Iteration: 5965] [Loss: 0.12631161510944366]\n",
            "[Iteration: 5966] [Loss: 0.14544422924518585]\n",
            "[Iteration: 5967] [Loss: 0.14511638879776]\n",
            "[Iteration: 5968] [Loss: 0.1285514086484909]\n",
            "[Iteration: 5969] [Loss: 0.16216152906417847]\n",
            "[Iteration: 5970] [Loss: 0.1277761161327362]\n",
            "[Iteration: 5971] [Loss: 0.12291646003723145]\n",
            "[Iteration: 5972] [Loss: 0.11817184090614319]\n",
            "[Iteration: 5973] [Loss: 0.11873671412467957]\n",
            "[Iteration: 5974] [Loss: 0.1417560875415802]\n",
            "[Iteration: 5975] [Loss: 0.15051524341106415]\n",
            "[Iteration: 5976] [Loss: 0.1509179174900055]\n",
            "[Iteration: 5977] [Loss: 0.13133107125759125]\n",
            "[Iteration: 5978] [Loss: 0.1419198364019394]\n",
            "[Iteration: 5979] [Loss: 0.11200083792209625]\n",
            "[Iteration: 5980] [Loss: 0.11405995488166809]\n",
            "[Iteration: 5981] [Loss: 0.1320146769285202]\n",
            "[Iteration: 5982] [Loss: 0.15435582399368286]\n",
            "[Iteration: 5983] [Loss: 0.11313280463218689]\n",
            "[Iteration: 5984] [Loss: 0.13189572095870972]\n",
            "[Iteration: 5985] [Loss: 0.14114022254943848]\n",
            "[Iteration: 5986] [Loss: 0.13279570639133453]\n",
            "[Iteration: 5987] [Loss: 0.14935187995433807]\n",
            "[Iteration: 5988] [Loss: 0.14590995013713837]\n",
            "[Iteration: 5989] [Loss: 0.1254264861345291]\n",
            "[Iteration: 5990] [Loss: 0.14195603132247925]\n",
            "[Iteration: 5991] [Loss: 0.11917707324028015]\n",
            "[Iteration: 5992] [Loss: 0.14600221812725067]\n",
            "[Iteration: 5993] [Loss: 0.13817793130874634]\n",
            "[Iteration: 5994] [Loss: 0.13726192712783813]\n",
            "[Iteration: 5995] [Loss: 0.109012670814991]\n",
            "[Iteration: 5996] [Loss: 0.1379196047782898]\n",
            "[Iteration: 5997] [Loss: 0.12583079934120178]\n",
            "[Iteration: 5998] [Loss: 0.15001241862773895]\n",
            "[Iteration: 5999] [Loss: 0.12513718008995056]\n",
            "[Iteration: 6000] [Loss: 0.12798531353473663]\n",
            "[Iteration: 6001] [Loss: 0.12434634566307068]\n",
            "[Iteration: 6002] [Loss: 0.10482295602560043]\n",
            "[Iteration: 6003] [Loss: 0.12328226119279861]\n",
            "[Iteration: 6004] [Loss: 0.13193903863430023]\n",
            "[Iteration: 6005] [Loss: 0.1403808891773224]\n",
            "[Iteration: 6006] [Loss: 0.1233435571193695]\n",
            "[Iteration: 6007] [Loss: 0.1142071858048439]\n",
            "[Iteration: 6008] [Loss: 0.13137809932231903]\n",
            "[Iteration: 6009] [Loss: 0.16487526893615723]\n",
            "[Iteration: 6010] [Loss: 0.12589308619499207]\n",
            "[Iteration: 6011] [Loss: 0.1426079124212265]\n",
            "[Iteration: 6012] [Loss: 0.12394813448190689]\n",
            "[Iteration: 6013] [Loss: 0.10952573269605637]\n",
            "[Iteration: 6014] [Loss: 0.13131898641586304]\n",
            "[Iteration: 6015] [Loss: 0.14674194157123566]\n",
            "[Iteration: 6016] [Loss: 0.1265469193458557]\n",
            "[Iteration: 6017] [Loss: 0.11736312508583069]\n",
            "[Iteration: 6018] [Loss: 0.12013103067874908]\n",
            "[Iteration: 6019] [Loss: 0.13383473455905914]\n",
            "[Iteration: 6020] [Loss: 0.1327054500579834]\n",
            "[Iteration: 6021] [Loss: 0.12666365504264832]\n",
            "[Iteration: 6022] [Loss: 0.13087111711502075]\n",
            "[Iteration: 6023] [Loss: 0.13782158493995667]\n",
            "[Iteration: 6024] [Loss: 0.13068774342536926]\n",
            "[Iteration: 6025] [Loss: 0.11994799971580505]\n",
            "[Iteration: 6026] [Loss: 0.14912909269332886]\n",
            "[Iteration: 6027] [Loss: 0.13602210581302643]\n",
            "[Iteration: 6028] [Loss: 0.14265291392803192]\n",
            "[Iteration: 6029] [Loss: 0.12502343952655792]\n",
            "[Iteration: 6030] [Loss: 0.12251652777194977]\n",
            "[Iteration: 6031] [Loss: 0.13591702282428741]\n",
            "[Iteration: 6032] [Loss: 0.13760854303836823]\n",
            "[Iteration: 6033] [Loss: 0.11342578381299973]\n",
            "[Iteration: 6034] [Loss: 0.1312916874885559]\n",
            "[Iteration: 6035] [Loss: 0.12930916249752045]\n",
            "[Iteration: 6036] [Loss: 0.1301143765449524]\n",
            "[Iteration: 6037] [Loss: 0.13466832041740417]\n",
            "[Iteration: 6038] [Loss: 0.1538107544183731]\n",
            "[Iteration: 6039] [Loss: 0.11430025100708008]\n",
            "[Iteration: 6040] [Loss: 0.11284726113080978]\n",
            "[Iteration: 6041] [Loss: 0.13038450479507446]\n",
            "[Iteration: 6042] [Loss: 0.1224500983953476]\n",
            "[Iteration: 6043] [Loss: 0.12282665818929672]\n",
            "[Iteration: 6044] [Loss: 0.11208175122737885]\n",
            "[Iteration: 6045] [Loss: 0.1456659585237503]\n",
            "[Iteration: 6046] [Loss: 0.1304350197315216]\n",
            "[Iteration: 6047] [Loss: 0.13360220193862915]\n",
            "[Iteration: 6048] [Loss: 0.13347190618515015]\n",
            "[Iteration: 6049] [Loss: 0.12672016024589539]\n",
            "[Iteration: 6050] [Loss: 0.12202465534210205]\n",
            "[Iteration: 6051] [Loss: 0.14747002720832825]\n",
            "[Iteration: 6052] [Loss: 0.1310574859380722]\n",
            "[Iteration: 6053] [Loss: 0.1396297812461853]\n",
            "[Iteration: 6054] [Loss: 0.14296795427799225]\n",
            "[Iteration: 6055] [Loss: 0.14799171686172485]\n",
            "[Iteration: 6056] [Loss: 0.1434868574142456]\n",
            "[Iteration: 6057] [Loss: 0.1396244764328003]\n",
            "[Iteration: 6058] [Loss: 0.11360171437263489]\n",
            "[Iteration: 6059] [Loss: 0.1248013973236084]\n",
            "[Iteration: 6060] [Loss: 0.13506163656711578]\n",
            "[Iteration: 6061] [Loss: 0.13978831470012665]\n",
            "[Iteration: 6062] [Loss: 0.15674716234207153]\n",
            "[Iteration: 6063] [Loss: 0.14678677916526794]\n",
            "[Iteration: 6064] [Loss: 0.11250463128089905]\n",
            "[Iteration: 6065] [Loss: 0.11605218052864075]\n",
            "[Iteration: 6066] [Loss: 0.1438841074705124]\n",
            "[Iteration: 6067] [Loss: 0.11868885904550552]\n",
            "[Iteration: 6068] [Loss: 0.13338340818881989]\n",
            "[Iteration: 6069] [Loss: 0.11775700002908707]\n",
            "[Iteration: 6070] [Loss: 0.12129812687635422]\n",
            "[Iteration: 6071] [Loss: 0.14037726819515228]\n",
            "[Iteration: 6072] [Loss: 0.11593638360500336]\n",
            "[Iteration: 6073] [Loss: 0.12700626254081726]\n",
            "[Iteration: 6074] [Loss: 0.13465102016925812]\n",
            "[Iteration: 6075] [Loss: 0.12157086282968521]\n",
            "[Iteration: 6076] [Loss: 0.12633304297924042]\n",
            "[Iteration: 6077] [Loss: 0.10929292440414429]\n",
            "[Iteration: 6078] [Loss: 0.13403968513011932]\n",
            "[Iteration: 6079] [Loss: 0.14729608595371246]\n",
            "[Iteration: 6080] [Loss: 0.14174386858940125]\n",
            "[Iteration: 6081] [Loss: 0.1306769996881485]\n",
            "[Iteration: 6082] [Loss: 0.12658074498176575]\n",
            "[Iteration: 6083] [Loss: 0.13826459646224976]\n",
            "[Iteration: 6084] [Loss: 0.14154887199401855]\n",
            "[Iteration: 6085] [Loss: 0.1430394947528839]\n",
            "[Iteration: 6086] [Loss: 0.15142062306404114]\n",
            "[Iteration: 6087] [Loss: 0.14146167039871216]\n",
            "[Iteration: 6088] [Loss: 0.13447637856006622]\n",
            "[Iteration: 6089] [Loss: 0.1265823245048523]\n",
            "[Iteration: 6090] [Loss: 0.12030889093875885]\n",
            "[Iteration: 6091] [Loss: 0.12542934715747833]\n",
            "[Iteration: 6092] [Loss: 0.13092193007469177]\n",
            "[Iteration: 6093] [Loss: 0.1370154172182083]\n",
            "[Iteration: 6094] [Loss: 0.12717582285404205]\n",
            "[Iteration: 6095] [Loss: 0.12817059457302094]\n",
            "[Iteration: 6096] [Loss: 0.11060591787099838]\n",
            "[Iteration: 6097] [Loss: 0.15171076357364655]\n",
            "[Iteration: 6098] [Loss: 0.11355774849653244]\n",
            "[Iteration: 6099] [Loss: 0.13260866701602936]\n",
            "[Iteration: 6100] [Loss: 0.15037856996059418]\n",
            "[Iteration: 6101] [Loss: 0.14176033437252045]\n",
            "[Iteration: 6102] [Loss: 0.13331298530101776]\n",
            "[Iteration: 6103] [Loss: 0.12882103025913239]\n",
            "[Iteration: 6104] [Loss: 0.15154823660850525]\n",
            "[Iteration: 6105] [Loss: 0.1290055513381958]\n",
            "[Iteration: 6106] [Loss: 0.1258225440979004]\n",
            "[Iteration: 6107] [Loss: 0.14132526516914368]\n",
            "[Iteration: 6108] [Loss: 0.14592094719409943]\n",
            "[Iteration: 6109] [Loss: 0.12485786527395248]\n",
            "[Iteration: 6110] [Loss: 0.12642958760261536]\n",
            "[Iteration: 6111] [Loss: 0.15549463033676147]\n",
            "[Iteration: 6112] [Loss: 0.12394724786281586]\n",
            "[Iteration: 6113] [Loss: 0.13592088222503662]\n",
            "[Iteration: 6114] [Loss: 0.10237129777669907]\n",
            "[Iteration: 6115] [Loss: 0.14308679103851318]\n",
            "[Iteration: 6116] [Loss: 0.1276244819164276]\n",
            "[Iteration: 6117] [Loss: 0.12841419875621796]\n",
            "[Iteration: 6118] [Loss: 0.12540753185749054]\n",
            "[Iteration: 6119] [Loss: 0.13585467636585236]\n",
            "[Iteration: 6120] [Loss: 0.11154256761074066]\n",
            "[Iteration: 6121] [Loss: 0.14057254791259766]\n",
            "[Iteration: 6122] [Loss: 0.13107985258102417]\n",
            "[Iteration: 6123] [Loss: 0.16495703160762787]\n",
            "[Iteration: 6124] [Loss: 0.12537159025669098]\n",
            "[Iteration: 6125] [Loss: 0.1287803053855896]\n",
            "[Iteration: 6126] [Loss: 0.13259583711624146]\n",
            "[Iteration: 6127] [Loss: 0.13728496432304382]\n",
            "[Iteration: 6128] [Loss: 0.15965217351913452]\n",
            "[Iteration: 6129] [Loss: 0.15557178854942322]\n",
            "[Iteration: 6130] [Loss: 0.11284951120615005]\n",
            "[Iteration: 6131] [Loss: 0.12382063269615173]\n",
            "[Iteration: 6132] [Loss: 0.10915140062570572]\n",
            "[Iteration: 6133] [Loss: 0.12159112840890884]\n",
            "[Iteration: 6134] [Loss: 0.1318456083536148]\n",
            "[Iteration: 6135] [Loss: 0.14817170798778534]\n",
            "[Iteration: 6136] [Loss: 0.1309012770652771]\n",
            "[Iteration: 6137] [Loss: 0.12493150681257248]\n",
            "[Iteration: 6138] [Loss: 0.13373813033103943]\n",
            "[Iteration: 6139] [Loss: 0.14177043735980988]\n",
            "[Iteration: 6140] [Loss: 0.11457990109920502]\n",
            "[Iteration: 6141] [Loss: 0.13384032249450684]\n",
            "[Iteration: 6142] [Loss: 0.1401173174381256]\n",
            "[Iteration: 6143] [Loss: 0.13191519677639008]\n",
            "[Iteration: 6144] [Loss: 0.11824507266283035]\n",
            "[Iteration: 6145] [Loss: 0.13839323818683624]\n",
            "[Iteration: 6146] [Loss: 0.13630475103855133]\n",
            "[Iteration: 6147] [Loss: 0.14458569884300232]\n",
            "[Iteration: 6148] [Loss: 0.13151125609874725]\n",
            "[Iteration: 6149] [Loss: 0.14132779836654663]\n",
            "[Iteration: 6150] [Loss: 0.1348559856414795]\n",
            "[Iteration: 6151] [Loss: 0.12434438616037369]\n",
            "[Iteration: 6152] [Loss: 0.15560834109783173]\n",
            "[Iteration: 6153] [Loss: 0.12924857437610626]\n",
            "[Iteration: 6154] [Loss: 0.1361001878976822]\n",
            "[Iteration: 6155] [Loss: 0.13723716139793396]\n",
            "[Iteration: 6156] [Loss: 0.14850042760372162]\n",
            "[Iteration: 6157] [Loss: 0.12381422519683838]\n",
            "[Iteration: 6158] [Loss: 0.1355370730161667]\n",
            "[Iteration: 6159] [Loss: 0.1276397556066513]\n",
            "[Iteration: 6160] [Loss: 0.1418231725692749]\n",
            "[Iteration: 6161] [Loss: 0.10357217490673065]\n",
            "[Iteration: 6162] [Loss: 0.1323637068271637]\n",
            "[Iteration: 6163] [Loss: 0.109477199614048]\n",
            "[Iteration: 6164] [Loss: 0.11780361086130142]\n",
            "[Iteration: 6165] [Loss: 0.1258898228406906]\n",
            "[Iteration: 6166] [Loss: 0.12067203968763351]\n",
            "[Iteration: 6167] [Loss: 0.13426171243190765]\n",
            "[Iteration: 6168] [Loss: 0.12491733580827713]\n",
            "[Iteration: 6169] [Loss: 0.1077074408531189]\n",
            "[Iteration: 6170] [Loss: 0.11300887167453766]\n",
            "[Iteration: 6171] [Loss: 0.10841833055019379]\n",
            "[Iteration: 6172] [Loss: 0.12500302493572235]\n",
            "[Iteration: 6173] [Loss: 0.1370185762643814]\n",
            "[Iteration: 6174] [Loss: 0.1423739343881607]\n",
            "[Iteration: 6175] [Loss: 0.12032082676887512]\n",
            "[Iteration: 6176] [Loss: 0.11285296827554703]\n",
            "[Iteration: 6177] [Loss: 0.1213623434305191]\n",
            "[Iteration: 6178] [Loss: 0.13113008439540863]\n",
            "[Iteration: 6179] [Loss: 0.12975655496120453]\n",
            "[Iteration: 6180] [Loss: 0.12818612158298492]\n",
            "[Iteration: 6181] [Loss: 0.12018639594316483]\n",
            "[Iteration: 6182] [Loss: 0.12639299035072327]\n",
            "[Iteration: 6183] [Loss: 0.10847106575965881]\n",
            "[Iteration: 6184] [Loss: 0.11181417107582092]\n",
            "[Iteration: 6185] [Loss: 0.12864144146442413]\n",
            "[Iteration: 6186] [Loss: 0.12365353107452393]\n",
            "[Iteration: 6187] [Loss: 0.13379955291748047]\n",
            "[Iteration: 6188] [Loss: 0.12999074161052704]\n",
            "[Iteration: 6189] [Loss: 0.11321704834699631]\n",
            "[Iteration: 6190] [Loss: 0.1070241779088974]\n",
            "[Iteration: 6191] [Loss: 0.10860724747180939]\n",
            "[Iteration: 6192] [Loss: 0.1345866322517395]\n",
            "[Iteration: 6193] [Loss: 0.1469159722328186]\n",
            "[Iteration: 6194] [Loss: 0.1388576328754425]\n",
            "[Iteration: 6195] [Loss: 0.11706014722585678]\n",
            "[Iteration: 6196] [Loss: 0.11685881018638611]\n",
            "[Iteration: 6197] [Loss: 0.1184503510594368]\n",
            "[Iteration: 6198] [Loss: 0.11171033978462219]\n",
            "[Iteration: 6199] [Loss: 0.12022770941257477]\n",
            "[Iteration: 6200] [Loss: 0.13149064779281616]\n",
            "[Iteration: 6201] [Loss: 0.11996939778327942]\n",
            "[Iteration: 6202] [Loss: 0.10791981965303421]\n",
            "[Iteration: 6203] [Loss: 0.13834220170974731]\n",
            "[Iteration: 6204] [Loss: 0.13326328992843628]\n",
            "[Iteration: 6205] [Loss: 0.10584034025669098]\n",
            "[Iteration: 6206] [Loss: 0.12828513979911804]\n",
            "[Iteration: 6207] [Loss: 0.14009474217891693]\n",
            "[Iteration: 6208] [Loss: 0.13342563807964325]\n",
            "[Iteration: 6209] [Loss: 0.12528102099895477]\n",
            "[Iteration: 6210] [Loss: 0.14135466516017914]\n",
            "[Iteration: 6211] [Loss: 0.14569629728794098]\n",
            "[Iteration: 6212] [Loss: 0.12212077528238297]\n",
            "[Iteration: 6213] [Loss: 0.13005751371383667]\n",
            "[Iteration: 6214] [Loss: 0.12669788300991058]\n",
            "[Iteration: 6215] [Loss: 0.16009612381458282]\n",
            "[Iteration: 6216] [Loss: 0.10563318431377411]\n",
            "[Iteration: 6217] [Loss: 0.12514933943748474]\n",
            "[Iteration: 6218] [Loss: 0.12105633318424225]\n",
            "[Iteration: 6219] [Loss: 0.12487629055976868]\n",
            "[Iteration: 6220] [Loss: 0.13871929049491882]\n",
            "[Iteration: 6221] [Loss: 0.12142682075500488]\n",
            "[Iteration: 6222] [Loss: 0.13643471896648407]\n",
            "[Iteration: 6223] [Loss: 0.12825696170330048]\n",
            "[Iteration: 6224] [Loss: 0.09809623658657074]\n",
            "[Iteration: 6225] [Loss: 0.1334649920463562]\n",
            "[Iteration: 6226] [Loss: 0.10440820455551147]\n",
            "[Iteration: 6227] [Loss: 0.13789719343185425]\n",
            "[Iteration: 6228] [Loss: 0.11252427101135254]\n",
            "[Iteration: 6229] [Loss: 0.12048450857400894]\n",
            "[Iteration: 6230] [Loss: 0.13654488325119019]\n",
            "[Iteration: 6231] [Loss: 0.14120128750801086]\n",
            "[Iteration: 6232] [Loss: 0.11416791379451752]\n",
            "[Iteration: 6233] [Loss: 0.1477200835943222]\n",
            "[Iteration: 6234] [Loss: 0.10069244354963303]\n",
            "[Iteration: 6235] [Loss: 0.11721955239772797]\n",
            "[Iteration: 6236] [Loss: 0.13152456283569336]\n",
            "[Iteration: 6237] [Loss: 0.12655170261859894]\n",
            "[Iteration: 6238] [Loss: 0.11372135579586029]\n",
            "[Iteration: 6239] [Loss: 0.11830655485391617]\n",
            "[Iteration: 6240] [Loss: 0.12453941255807877]\n",
            "[Iteration: 6241] [Loss: 0.14180344343185425]\n",
            "[Iteration: 6242] [Loss: 0.11994454264640808]\n",
            "[Iteration: 6243] [Loss: 0.1327114999294281]\n",
            "[Iteration: 6244] [Loss: 0.10617419332265854]\n",
            "[Iteration: 6245] [Loss: 0.12564215064048767]\n",
            "[Iteration: 6246] [Loss: 0.11657003313302994]\n",
            "[Iteration: 6247] [Loss: 0.12952956557273865]\n",
            "[Iteration: 6248] [Loss: 0.12877176702022552]\n",
            "[Iteration: 6249] [Loss: 0.11374804377555847]\n",
            "[Iteration: 6250] [Loss: 0.14022709429264069]\n",
            "[Iteration: 6251] [Loss: 0.12663108110427856]\n",
            "[Iteration: 6252] [Loss: 0.13152433931827545]\n",
            "[Iteration: 6253] [Loss: 0.1138060912489891]\n",
            "[Iteration: 6254] [Loss: 0.13827548921108246]\n",
            "[Iteration: 6255] [Loss: 0.11323095858097076]\n",
            "[Iteration: 6256] [Loss: 0.1487640142440796]\n",
            "[Iteration: 6257] [Loss: 0.12447044253349304]\n",
            "[Iteration: 6258] [Loss: 0.11081407964229584]\n",
            "[Iteration: 6259] [Loss: 0.11674998700618744]\n",
            "[Iteration: 6260] [Loss: 0.14161886274814606]\n",
            "[Iteration: 6261] [Loss: 0.12996156513690948]\n",
            "[Iteration: 6262] [Loss: 0.13239970803260803]\n",
            "[Iteration: 6263] [Loss: 0.11755251884460449]\n",
            "[Iteration: 6264] [Loss: 0.1264953762292862]\n",
            "[Iteration: 6265] [Loss: 0.12962576746940613]\n",
            "[Iteration: 6266] [Loss: 0.12844625115394592]\n",
            "[Iteration: 6267] [Loss: 0.14530818164348602]\n",
            "[Iteration: 6268] [Loss: 0.1275821328163147]\n",
            "[Iteration: 6269] [Loss: 0.11502541601657867]\n",
            "[Iteration: 6270] [Loss: 0.12429192662239075]\n",
            "[Iteration: 6271] [Loss: 0.15278133749961853]\n",
            "[Iteration: 6272] [Loss: 0.11664149165153503]\n",
            "[Iteration: 6273] [Loss: 0.14094063639640808]\n",
            "[Iteration: 6274] [Loss: 0.12008930742740631]\n",
            "[Iteration: 6275] [Loss: 0.11381237953901291]\n",
            "[Iteration: 6276] [Loss: 0.12408086657524109]\n",
            "[Iteration: 6277] [Loss: 0.12161372601985931]\n",
            "[Iteration: 6278] [Loss: 0.12106035649776459]\n",
            "[Iteration: 6279] [Loss: 0.12280973047018051]\n",
            "[Iteration: 6280] [Loss: 0.12525002658367157]\n",
            "[Iteration: 6281] [Loss: 0.1304907500743866]\n",
            "[Iteration: 6282] [Loss: 0.11967681348323822]\n",
            "[Iteration: 6283] [Loss: 0.11645981669425964]\n",
            "[Iteration: 6284] [Loss: 0.14947180449962616]\n",
            "[Iteration: 6285] [Loss: 0.11587277054786682]\n",
            "[Iteration: 6286] [Loss: 0.12888909876346588]\n",
            "[Iteration: 6287] [Loss: 0.12114670872688293]\n",
            "[Iteration: 6288] [Loss: 0.12190306186676025]\n",
            "[Iteration: 6289] [Loss: 0.11899128556251526]\n",
            "[Iteration: 6290] [Loss: 0.11296968907117844]\n",
            "[Iteration: 6291] [Loss: 0.11673804372549057]\n",
            "[Iteration: 6292] [Loss: 0.13942359387874603]\n",
            "[Iteration: 6293] [Loss: 0.15482637286186218]\n",
            "[Iteration: 6294] [Loss: 0.11175579577684402]\n",
            "[Iteration: 6295] [Loss: 0.1370345950126648]\n",
            "[Iteration: 6296] [Loss: 0.1313202977180481]\n",
            "[Iteration: 6297] [Loss: 0.12527041137218475]\n",
            "[Iteration: 6298] [Loss: 0.14897383749485016]\n",
            "[Iteration: 6299] [Loss: 0.11593042314052582]\n",
            "[Iteration: 6300] [Loss: 0.13228940963745117]\n",
            "[Iteration: 6301] [Loss: 0.12995439767837524]\n",
            "[Iteration: 6302] [Loss: 0.13700470328330994]\n",
            "[Iteration: 6303] [Loss: 0.12368472665548325]\n",
            "[Iteration: 6304] [Loss: 0.10866864025592804]\n",
            "[Iteration: 6305] [Loss: 0.11422023177146912]\n",
            "[Iteration: 6306] [Loss: 0.12882007658481598]\n",
            "[Iteration: 6307] [Loss: 0.11549314856529236]\n",
            "[Iteration: 6308] [Loss: 0.14513324201107025]\n",
            "[Iteration: 6309] [Loss: 0.12809033691883087]\n",
            "[Iteration: 6310] [Loss: 0.10887724906206131]\n",
            "[Iteration: 6311] [Loss: 0.10551244020462036]\n",
            "[Iteration: 6312] [Loss: 0.11621187627315521]\n",
            "[Iteration: 6313] [Loss: 0.11582496762275696]\n",
            "[Iteration: 6314] [Loss: 0.12318674474954605]\n",
            "[Iteration: 6315] [Loss: 0.13016992807388306]\n",
            "[Iteration: 6316] [Loss: 0.1328362077474594]\n",
            "[Iteration: 6317] [Loss: 0.13432735204696655]\n",
            "[Iteration: 6318] [Loss: 0.136639803647995]\n",
            "[Iteration: 6319] [Loss: 0.12748506665229797]\n",
            "[Iteration: 6320] [Loss: 0.14034804701805115]\n",
            "[Iteration: 6321] [Loss: 0.13625577092170715]\n",
            "[Iteration: 6322] [Loss: 0.11811746656894684]\n",
            "[Iteration: 6323] [Loss: 0.12136346846818924]\n",
            "[Iteration: 6324] [Loss: 0.134783074259758]\n",
            "[Iteration: 6325] [Loss: 0.12748964130878448]\n",
            "[Iteration: 6326] [Loss: 0.14620853960514069]\n",
            "[Iteration: 6327] [Loss: 0.10932762920856476]\n",
            "[Iteration: 6328] [Loss: 0.1164320707321167]\n",
            "[Iteration: 6329] [Loss: 0.11679395288228989]\n",
            "[Iteration: 6330] [Loss: 0.13459867238998413]\n",
            "[Iteration: 6331] [Loss: 0.12521249055862427]\n",
            "[Iteration: 6332] [Loss: 0.13353317975997925]\n",
            "[Iteration: 6333] [Loss: 0.13526830077171326]\n",
            "[Iteration: 6334] [Loss: 0.1320420801639557]\n",
            "[Iteration: 6335] [Loss: 0.12665621936321259]\n",
            "[Iteration: 6336] [Loss: 0.10942438244819641]\n",
            "[Iteration: 6337] [Loss: 0.12177085876464844]\n",
            "[Iteration: 6338] [Loss: 0.14075708389282227]\n",
            "[Iteration: 6339] [Loss: 0.1185731515288353]\n",
            "[Iteration: 6340] [Loss: 0.1345495879650116]\n",
            "[Iteration: 6341] [Loss: 0.13059519231319427]\n",
            "[Iteration: 6342] [Loss: 0.11195234209299088]\n",
            "[Iteration: 6343] [Loss: 0.10973414033651352]\n",
            "[Iteration: 6344] [Loss: 0.12873989343643188]\n",
            "[Iteration: 6345] [Loss: 0.14138491451740265]\n",
            "[Iteration: 6346] [Loss: 0.11310277879238129]\n",
            "[Iteration: 6347] [Loss: 0.1114344596862793]\n",
            "[Iteration: 6348] [Loss: 0.1435409039258957]\n",
            "[Iteration: 6349] [Loss: 0.13598531484603882]\n",
            "[Iteration: 6350] [Loss: 0.10430622100830078]\n",
            "[Iteration: 6351] [Loss: 0.13561926782131195]\n",
            "[Iteration: 6352] [Loss: 0.11755985766649246]\n",
            "[Iteration: 6353] [Loss: 0.13180497288703918]\n",
            "[Iteration: 6354] [Loss: 0.1555808186531067]\n",
            "[Iteration: 6355] [Loss: 0.11847630143165588]\n",
            "[Iteration: 6356] [Loss: 0.12537725269794464]\n",
            "[Iteration: 6357] [Loss: 0.11284831911325455]\n",
            "[Iteration: 6358] [Loss: 0.12865318357944489]\n",
            "[Iteration: 6359] [Loss: 0.11640991270542145]\n",
            "[Iteration: 6360] [Loss: 0.11458185315132141]\n",
            "[Iteration: 6361] [Loss: 0.12570889294147491]\n",
            "[Iteration: 6362] [Loss: 0.11212493479251862]\n",
            "[Iteration: 6363] [Loss: 0.1403224766254425]\n",
            "[Iteration: 6364] [Loss: 0.1364470273256302]\n",
            "[Iteration: 6365] [Loss: 0.132059246301651]\n",
            "[Iteration: 6366] [Loss: 0.10666537284851074]\n",
            "[Iteration: 6367] [Loss: 0.12542752921581268]\n",
            "[Iteration: 6368] [Loss: 0.12199459969997406]\n",
            "[Iteration: 6369] [Loss: 0.13371412456035614]\n",
            "[Iteration: 6370] [Loss: 0.12215978652238846]\n",
            "[Iteration: 6371] [Loss: 0.1271338164806366]\n",
            "[Iteration: 6372] [Loss: 0.12832269072532654]\n",
            "[Iteration: 6373] [Loss: 0.11470237374305725]\n",
            "[Iteration: 6374] [Loss: 0.12970131635665894]\n",
            "[Iteration: 6375] [Loss: 0.14307473599910736]\n",
            "[Iteration: 6376] [Loss: 0.14448396861553192]\n",
            "[Iteration: 6377] [Loss: 0.10744769126176834]\n",
            "[Iteration: 6378] [Loss: 0.14337962865829468]\n",
            "[Iteration: 6379] [Loss: 0.1089763268828392]\n",
            "[Iteration: 6380] [Loss: 0.1587027907371521]\n",
            "[Iteration: 6381] [Loss: 0.13924391567707062]\n",
            "[Iteration: 6382] [Loss: 0.13737674057483673]\n",
            "[Iteration: 6383] [Loss: 0.1306413859128952]\n",
            "[Iteration: 6384] [Loss: 0.12210346758365631]\n",
            "[Iteration: 6385] [Loss: 0.13971927762031555]\n",
            "[Iteration: 6386] [Loss: 0.12780064344406128]\n",
            "[Iteration: 6387] [Loss: 0.12493366748094559]\n",
            "[Iteration: 6388] [Loss: 0.12883736193180084]\n",
            "[Iteration: 6389] [Loss: 0.12517887353897095]\n",
            "[Iteration: 6390] [Loss: 0.09750720113515854]\n",
            "[Iteration: 6391] [Loss: 0.1537369191646576]\n",
            "[Iteration: 6392] [Loss: 0.11434391885995865]\n",
            "[Iteration: 6393] [Loss: 0.1339256763458252]\n",
            "[Iteration: 6394] [Loss: 0.1107294112443924]\n",
            "[Iteration: 6395] [Loss: 0.11579152941703796]\n",
            "[Iteration: 6396] [Loss: 0.13226540386676788]\n",
            "[Iteration: 6397] [Loss: 0.1355697065591812]\n",
            "[Iteration: 6398] [Loss: 0.12136737257242203]\n",
            "[Iteration: 6399] [Loss: 0.13809193670749664]\n",
            "[Iteration: 6400] [Loss: 0.11954038590192795]\n",
            "[Iteration: 6401] [Loss: 0.13542334735393524]\n",
            "[Iteration: 6402] [Loss: 0.12520551681518555]\n",
            "[Iteration: 6403] [Loss: 0.1130291074514389]\n",
            "[Iteration: 6404] [Loss: 0.12644630670547485]\n",
            "[Iteration: 6405] [Loss: 0.10831674933433533]\n",
            "[Iteration: 6406] [Loss: 0.11771243065595627]\n",
            "[Iteration: 6407] [Loss: 0.1221408024430275]\n",
            "[Iteration: 6408] [Loss: 0.12455076724290848]\n",
            "[Iteration: 6409] [Loss: 0.12047237902879715]\n",
            "[Iteration: 6410] [Loss: 0.1093212217092514]\n",
            "[Iteration: 6411] [Loss: 0.12774577736854553]\n",
            "[Iteration: 6412] [Loss: 0.10762029886245728]\n",
            "[Iteration: 6413] [Loss: 0.11933092027902603]\n",
            "[Iteration: 6414] [Loss: 0.1410103440284729]\n",
            "[Iteration: 6415] [Loss: 0.12508325278759003]\n",
            "[Iteration: 6416] [Loss: 0.132129967212677]\n",
            "[Iteration: 6417] [Loss: 0.13798761367797852]\n",
            "[Iteration: 6418] [Loss: 0.09880811721086502]\n",
            "[Iteration: 6419] [Loss: 0.11408284306526184]\n",
            "[Iteration: 6420] [Loss: 0.1267920732498169]\n",
            "[Iteration: 6421] [Loss: 0.1264560967683792]\n",
            "[Iteration: 6422] [Loss: 0.12251406162977219]\n",
            "[Iteration: 6423] [Loss: 0.11795441061258316]\n",
            "[Iteration: 6424] [Loss: 0.12762045860290527]\n",
            "[Iteration: 6425] [Loss: 0.10457007586956024]\n",
            "[Iteration: 6426] [Loss: 0.11907115578651428]\n",
            "[Iteration: 6427] [Loss: 0.11197338998317719]\n",
            "[Iteration: 6428] [Loss: 0.09964117407798767]\n",
            "[Iteration: 6429] [Loss: 0.10743759572505951]\n",
            "[Iteration: 6430] [Loss: 0.14025869965553284]\n",
            "[Iteration: 6431] [Loss: 0.1038074716925621]\n",
            "[Iteration: 6432] [Loss: 0.12205847352743149]\n",
            "[Iteration: 6433] [Loss: 0.1320546567440033]\n",
            "[Iteration: 6434] [Loss: 0.09708298742771149]\n",
            "[Iteration: 6435] [Loss: 0.1568930745124817]\n",
            "[Iteration: 6436] [Loss: 0.11670014262199402]\n",
            "[Iteration: 6437] [Loss: 0.1355806440114975]\n",
            "[Iteration: 6438] [Loss: 0.10787412524223328]\n",
            "[Iteration: 6439] [Loss: 0.13236738741397858]\n",
            "[Iteration: 6440] [Loss: 0.10275191813707352]\n",
            "[Iteration: 6441] [Loss: 0.13475662469863892]\n",
            "[Iteration: 6442] [Loss: 0.12202755361795425]\n",
            "[Iteration: 6443] [Loss: 0.1252002865076065]\n",
            "[Iteration: 6444] [Loss: 0.13653482496738434]\n",
            "[Iteration: 6445] [Loss: 0.1266755610704422]\n",
            "[Iteration: 6446] [Loss: 0.09964694082736969]\n",
            "[Iteration: 6447] [Loss: 0.1196189746260643]\n",
            "[Iteration: 6448] [Loss: 0.13307693600654602]\n",
            "[Iteration: 6449] [Loss: 0.09918589144945145]\n",
            "[Iteration: 6450] [Loss: 0.11535538733005524]\n",
            "[Iteration: 6451] [Loss: 0.14773055911064148]\n",
            "[Iteration: 6452] [Loss: 0.13154076039791107]\n",
            "[Iteration: 6453] [Loss: 0.13431388139724731]\n",
            "[Iteration: 6454] [Loss: 0.13855473697185516]\n",
            "[Iteration: 6455] [Loss: 0.15151368081569672]\n",
            "[Iteration: 6456] [Loss: 0.11665639281272888]\n",
            "[Iteration: 6457] [Loss: 0.11866969615221024]\n",
            "[Iteration: 6458] [Loss: 0.12041453272104263]\n",
            "[Iteration: 6459] [Loss: 0.13056164979934692]\n",
            "[Iteration: 6460] [Loss: 0.1333615928888321]\n",
            "[Iteration: 6461] [Loss: 0.12376311421394348]\n",
            "[Iteration: 6462] [Loss: 0.13390927016735077]\n",
            "[Iteration: 6463] [Loss: 0.14213019609451294]\n",
            "[Iteration: 6464] [Loss: 0.12854820489883423]\n",
            "[Iteration: 6465] [Loss: 0.09662894904613495]\n",
            "[Iteration: 6466] [Loss: 0.12032788246870041]\n",
            "[Iteration: 6467] [Loss: 0.1290971338748932]\n",
            "[Iteration: 6468] [Loss: 0.11713457107543945]\n",
            "[Iteration: 6469] [Loss: 0.11844979226589203]\n",
            "[Iteration: 6470] [Loss: 0.10643937438726425]\n",
            "[Iteration: 6471] [Loss: 0.12741094827651978]\n",
            "[Iteration: 6472] [Loss: 0.1394069343805313]\n",
            "[Iteration: 6473] [Loss: 0.14394573867321014]\n",
            "[Iteration: 6474] [Loss: 0.13088297843933105]\n",
            "[Iteration: 6475] [Loss: 0.1292639672756195]\n",
            "[Iteration: 6476] [Loss: 0.12025562673807144]\n",
            "[Iteration: 6477] [Loss: 0.14398862421512604]\n",
            "[Iteration: 6478] [Loss: 0.11810792982578278]\n",
            "[Iteration: 6479] [Loss: 0.12245389819145203]\n",
            "[Iteration: 6480] [Loss: 0.11772271245718002]\n",
            "[Iteration: 6481] [Loss: 0.14227671921253204]\n",
            "[Iteration: 6482] [Loss: 0.1390349268913269]\n",
            "[Iteration: 6483] [Loss: 0.12870413064956665]\n",
            "[Iteration: 6484] [Loss: 0.14416033029556274]\n",
            "[Iteration: 6485] [Loss: 0.11166790127754211]\n",
            "[Iteration: 6486] [Loss: 0.11364287883043289]\n",
            "[Iteration: 6487] [Loss: 0.12281330674886703]\n",
            "[Iteration: 6488] [Loss: 0.11705729365348816]\n",
            "[Iteration: 6489] [Loss: 0.12198124825954437]\n",
            "[Iteration: 6490] [Loss: 0.10675536841154099]\n",
            "[Iteration: 6491] [Loss: 0.12512163817882538]\n",
            "[Iteration: 6492] [Loss: 0.12949632108211517]\n",
            "[Iteration: 6493] [Loss: 0.11316745728254318]\n",
            "[Iteration: 6494] [Loss: 0.12471175193786621]\n",
            "[Iteration: 6495] [Loss: 0.14521701633930206]\n",
            "[Iteration: 6496] [Loss: 0.1117524728178978]\n",
            "[Iteration: 6497] [Loss: 0.13584087789058685]\n",
            "[Iteration: 6498] [Loss: 0.12083449959754944]\n",
            "[Iteration: 6499] [Loss: 0.12724779546260834]\n",
            "[Iteration: 6500] [Loss: 0.13490088284015656]\n"
          ]
        }
      ],
      "source": [
        "for i in range(6500+1):\n",
        "    model.train()\n",
        "    prediction = model(X_train_dep_std)\n",
        "    loss = loss_func(prediction, y_train_dep_std)\n",
        "    optimizer.zero_grad()  # clearing gradients for this training step\n",
        "    loss.backward()        # back propagation, compute gradients\n",
        "    optimizer.step()\n",
        "    # if i % 100 == 0:\n",
        "    print(f'[Iteration: {i}] [Loss: {loss.item()}]')\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iAQVr3W05yzD"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "Dy_pred_dep_ = model(X_test_dep_std).detach().numpy()\n",
        "y_pred_dep = ss_y_dep.inverse_transform(Dy_pred_dep_[0, 144:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AL37joVn6dMB",
        "outputId": "f897b89a-57ee-4908-909d-a1a3bbafb366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.07287665342856287\n",
            "118.27880851455754\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "#scores = cross_val_score(model, y_test_dep, y_pred_dep, cv=3)\n",
        "#print(scores)\n",
        "rr=mean_absolute_percentage_error(y_test_dep, y_pred_dep)\n",
        "print(mean_absolute_percentage_error(y_test_dep, y_pred_dep))\n",
        "accuracy=rr*16.23*100\n",
        "print(accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FiVR17qHImYD",
        "outputId": "c63e0f30-e6ee-4e47-e1c6-09605f462cdf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "model = ['LR', 'Random Forest',  'SVM', 'LSTM']\n",
        "acc = [acc_lr, acc_rfr, acc_svm, accuracy]\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.yticks(np.arange(0,100,10))\n",
        "plt.ylabel(\"Test Accuracy %\")\n",
        "plt.xlabel(\"Machine Learning Model\")\n",
        "sns.barplot(x= model, y= acc)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0SAZ4nt069Wd",
        "outputId": "0d8f79f4-de92-48f0-b57c-b88ff6d28996"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f, ax1 = plt.subplots(1, 1, sharex=True, figsize=(10, 6))\n",
        "\n",
        "ax1.plot(Outputs[144:], color=\"red\", linestyle=\"-\", linewidth=1.5, label=\"Actual Measurements Taken on Site\")\n",
        "ax1.plot(y_pred_dep, color=\"green\", linestyle=\":\", linewidth=1.5, label=\"Prediction From Proposed model\")\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.xticks(fontsize=8,fontweight='normal')\n",
        "plt.yticks(fontsize=8,fontweight='normal')\n",
        "plt.xlabel('Time (Month)', fontsize=10)\n",
        "plt.ylabel('GroundWater table depth (in meter)', fontsize=10)\n",
        "plt.xlim(0, 25)\n",
        "\n",
        "# plt.savefig('results.png', format='png')\n",
        "plt.show()\n",
        "     \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WEgzE0JR7ChB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}